{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "   div#notebook-container    { width: 95%; }\n",
       "   div#menubar-container     { width: 65%; }\n",
       "   div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "   div#notebook-container    { width: 95%; }\n",
    "   div#menubar-container     { width: 65%; }\n",
    "   div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\") # Adds higher directory to python modules path.\n",
    "from utilities import aggregate_feature_calculators\n",
    "from utilities import aggregate_feature_calculators_setting as aggcal\n",
    "from utilities.parallel import Parallel\n",
    "from utilities.dfdb import DFDB\n",
    "\n",
    "from utilities.process.pqueue import *\n",
    "from utilities.process.pnode import *\n",
    "from utilities.process.putilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import copy\n",
    "import gc\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "import optuna\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold,TimeSeriesSplit, GroupKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_folder =  '../../data/input'\n",
    "file_folder =  '../../data/feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_PARAMS = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.2,\n",
    "    'num_leaves': 256,\n",
    "    'min_child_samples': 79,\n",
    "    'max_depth': 9,\n",
    "    'subsample_freq': 1,\n",
    "    'subsample': 0.9,\n",
    "    'bagging_seed': 11,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.3,\n",
    "    'colsample_bytree': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [0,1,2,3,4,5,6,7]:\n",
    "#     df_train2 = pd.read_pickle(f'{file_folder}/df_train2.gzde', compression='gzip')\n",
    "#     df_train2_plus = pd.read_pickle(f'{file_folder}/df_train2_plus.gzde', compression='gzip')\n",
    "#     df_train2_plus = df_train2_plus.rename(columns={'id':'index'})\n",
    "\n",
    "#     df_train2 = df_train2[df_train2['type']==i]\n",
    "#     df_train2 = pd.merge(df_train2, df_train2_plus, how='left', on='index')\n",
    "#     df_train2 = df_train2.fillna(0)\n",
    "    \n",
    "#     columns = df_train2.columns.drop(['index', 'group', 'scalar_coupling_constant', 'fc', 'sd','pso','dso'])\n",
    "\n",
    "#     X_data = df_train2.drop(['index', 'group', 'scalar_coupling_constant', 'fc', 'sd','pso','dso'], axis=1).values.astype('float32')\n",
    "#     y_data = df_train2['fc'].values.astype('float32')\n",
    "\n",
    "#     group_kfold = GroupKFold(n_splits=8)\n",
    "#     splits = group_kfold.split(X_data, y_data, df_train2.group)\n",
    "#     for train_index, test_index in splits:\n",
    "#         break\n",
    "#     X_train, X_val, y_train, y_val = X_data[train_index], X_data[test_index], y_data[train_index], y_data[test_index]\n",
    "\n",
    "#     model = lgb.LGBMRegressor(**LGB_PARAMS, n_estimators=1500, n_jobs = -1)\n",
    "#     model.fit(X_train, y_train,  eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric='mae', verbose=False, early_stopping_rounds=200)\n",
    "#     y_pred = model.predict(X_val)\n",
    "#     y_pred_train = model.predict(X_train)\n",
    "#     error = np.log(mean_absolute_error(y_val, y_pred))\n",
    "#     error_train = np.log(mean_absolute_error(y_train, y_pred_train))\n",
    "#     print('init', i, error, error_train)\n",
    "\n",
    "#     perm = PermutationImportance(model, random_state=42).fit(X_val, y_val)\n",
    "#     df_feature_importances_i2 = eli5.explain_weights_dfs(perm)['feature_importances']\n",
    "#     df_feature_importances_i2['feature2'] = df_feature_importances_i2['feature'].apply(lambda x : columns[int(x.replace('x',''))])\n",
    "#     df_feature_importances_i2 = df_feature_importances_i2.sort_values(by=['weight'], ascending=False)\n",
    "#     df_feature_importances_i2 = df_feature_importances_i2.reset_index(drop=True)\n",
    "    \n",
    "#     columns_comb =[]\n",
    "#     best_error = 999\n",
    "#     his = []\n",
    "#     for col in df_feature_importances_i2.feature2.tolist():\n",
    "\n",
    "#         X_data = df_train2[[col]+columns_comb].values.astype('float32')\n",
    "#         y_data = df_train2['scalar_coupling_constant'].values.astype('float32')\n",
    "\n",
    "#         group_kfold = GroupKFold(n_splits=8)\n",
    "#         splits = group_kfold.split(X_data, y_data, df_train2.group)\n",
    "#         for train_index, test_index in splits:\n",
    "#             break\n",
    "#         X_train, X_val, y_train, y_val = X_data[train_index], X_data[test_index], y_data[train_index], y_data[test_index]\n",
    "\n",
    "#         model = lgb.LGBMRegressor(**LGB_PARAMS, n_estimators=1500, n_jobs = -1)\n",
    "#         model.fit(X_train, y_train,  eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric='mae', verbose=False, early_stopping_rounds=200)\n",
    "#         y_pred = model.predict(X_val)\n",
    "#         y_pred_train = model.predict(X_train)\n",
    "#         error = np.log(mean_absolute_error(y_val, y_pred))\n",
    "#         error_train = np.log(mean_absolute_error(y_train, y_pred_train))\n",
    "#         print('col', col, len(columns_comb), 'error', error, 'error_train', error_train)\n",
    "#         his.append({'col':[col]+columns_comb, 'error':error, 'error_train':error_train})\n",
    "\n",
    "#         if error < best_error:\n",
    "#             best_error = error\n",
    "#             columns_comb += [col]\n",
    "#             j = 0\n",
    "#         else:\n",
    "#             j += 1\n",
    "\n",
    "#         if (len(columns_comb)>=70) or (j>=100):\n",
    "#             print(columns_comb)\n",
    "#             break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "type_columns = [['tertiary_angle_0', 'inv_dist1R', 'd_4_3', 'yukawa_H.y', 'mulliken_atom_0', 'dist_to_type_mean', 'dist_O_0_x', 'atom_1_n_bonds', 'dist_to_type_1_mean', 'atom_1_bond_lengths_mean', 'dist_xyz', 'dist_C_0_y', 'd_3_2', 'atom_index_1_ hybridization', 'atom_index_1_cycle_size_mean', 'dist_O_0_y', 'eem_1', 'inv_distPE', 'd_4_2', 'inv_distPR', 'dist_no_bond_min_y', 'dist_H_2_x', 'dist_H_1_x', 'tertiary_distance_2', 'dist_C_3_x', 'dist_O_1_x', 'atom_1_bond_lengths_std', 'dist_C_2_y', 'dist_C_2_x', 'mulliken_atom_1', 'cos_center1', 'dist_O_1_y', 'tertiary_angle_3', 'dist_H_2_y', 'dist_N_0_y', 'dist_C_1_y', 'inv_dist1E', 'distance_y', 'tertiary_angle_2', 'dist_N_0_x', 'd_2_1', 'molecule_atom_index_0_dist_max_div', 'adC1', 'adN1', 'd_4_0', 'dist_C_3_y', 'atom_3', 'distC0', 'tertiary_distance_4', 'tertiary_angle_5', 'd_5_1', 'molecule_atom_index_1_dist_min_diff', 'dist_C_4_y', 'dist_H_0_y', 'cos_f0', 'd_5_0', 'tertiary_distance_3', 'd_5_2', 'tertiary_atom_1', 'dist_C_4_x', 'cos_c0_f0', 'atom_index_0_sv_3', 'rc_C', 'cos_f1', 'tertiary_angle_8', 'dist_O_2_y', 'max_molecule_atom_1_dist_xyz', 'dist_F_0_y', 'atom_index_1_ aromatic', 'tertiary_angle_26', 'type_0'],\n",
    "['dist_H_0_y', 'd_3_2', 'dist_C_0_y', 'atom_index_1_ aromatic', 'atom_1_bond_lengths_mean', 'bond_atom', 'inv_dist1R', 'd_3_1', 'mulliken_atom_0', 'dist_H_0_x', 'dist_O_0_y', 'dist_C_1_x', 'tertiary_angle_0', 'dist_C_1_y', 'vander_C.y', 'dist_H_1_y', 'mulliken_atom_1', 'inv_dist0R', 'd_1_0', 'tertiary_distance_0', 'tertiary_angle_2', 'atom_index_1_explicit_valence', 'dist_N_0_y', 'inv_distPR', 'dist_C_2_x', 'vander_H.x', 'd_4_2', 'atom_index_0_eigv_max', 'tertiary_distance_2', 'dist_H_1_x', 'dist_N_1_x', 'dist_C_3_x', 'cos_f0', 'atom_index_1_sv_2', 'max_molecule_atom_0_dist_xyz', 'd_2_1'],\n",
    "['tertiary_atom_0', 'inv_dist0', 'dist_no_bond_min_x', 'atom_index_1_ hybridization', 'tertiary_angle_0', 'tertiary_angle_1', 'dist_O_0_x', 'cos_c0', 'd_5_2', 'tertiary_atom_1', 'cos_f0', 'dist_H_0_x', 'd_3_1', 'atom_index_1_degree', 'dist_C_0_y', 'adC2', 'dist_C_3_x', 'vander_O.y', 'mulliken_atom_1', 'atom_7', 'tertiary_angle_2', 'd_2_1', 'atom_3', 'd_5_1', 'd_6_2', 'd_4_1', 'tertiary_atom_2', 'molecule_atom_index_1_dist_min_diff', 'd_4_2', 'dist_C_2_x', 'cos_c0_f0', 'd_6_0', 'dist_O_0_y', 'd_4_3', 'd_3_0', 'd_7_0', 'd_3_2', 'inv_dist0R', 'atom_8', 'dist_C_1_x', 'd_6_1', 'd_2_0', 'd_8_1', 'mulliken_atom_0', 'dist_N_0_x', 'atom_4', 'tertiary_distance_2', 'd_7_2', 'dist_C_0_x', 'atom_1_bond_lengths_mean', 'dist_C_1_y', 'bond_atom', 'd_7_1', 'd_4_0', 'distC0', 'atom_index_1_cycle_size_mean', 'cos_c0_c1', 'tertiary_angle_3', 'dist_O_1_x', 'atom_index_1_n_cycle', 'max_molecule_atom_0_dist_xyz', 'molecule_atom_index_0_dist_max_div', 'atom_5', 'gap', 'cos_c1', 'dist_N_0_y', 'd_6_3', 'dist_C_3_y', 'inv_distP', 'dist_C_4_y'],\n",
    "['cos_c0', 'd_4_3', 'cos_c0_c1', 'molecule_atom_index_0_dist_min_diff', 'tertiary_atom_1', 'd_3_2', 'd_1_0', 'dist_H_0_y', 'mulliken_atom_0', 'mulliken_atom_1', 'dist_N_0_x', 'link0', 'tertiary_atom_2', 'dist_C_1_y', 'dist_C_1_x', 'cos_f0', 'dist_C_0_y', 'cos_f1', 'd_3_1', 'tertiary_distance_1', 'dist_O_0_y', 'cos_f0_f1', 'adC1', 'd_5_3', 'inv_distP', 'edge_4', 'd_6_2', 'dist_N_0_y', 'tertiary_distance_2', 'dist_O_0_x', 'cos_c1_f1', 'd_3_0', 'd_5_2', 'dist_C_0_x', 'adN1', 'cos_c0_f0', 'd_4_1', 'max_distance_y', 'dist_C_2_y', 'atom_5', 'adC3', 'dist_to_type_1_mean', 'vander_H.x', 'dist_C_3_y', 'dist_H_3_x', 'molecule_atom_index_0_dist_max_div', 'atom_7', 'dist_C_3_x', 'd_5_1', 'dist_H_3_y', 'atom_index_0_eigv_max', 'atom_6', 'dist_H_2_x', 'atom_index_1_sv_0', 'molecule_atom_index_1_dist_std_div', 'link1'],\n",
    "['d_3_1', 'dist_H_1_x', 'd_5_0', 'd_4_0', 'yukawa_H.x', 'inv_dist0', 'd_6_0', 'd_4_1', 'cos_c0', 'atom_3', 'dist_C_0_y', 'molecule_atom_index_0_dist_std_div', 'cos_c0_c1', 'd_4_2', 'min_molecule_atom_0_dist_xyz', 'sd_molecule_atom_0_dist_xyz', 'd_2_1', 'adC2', 'd_3_0', 'dist_C_1_y', 'd_4_3', 'dist_H_0_x', 'vander_C.x', 'd_5_3', 'dist_H_1_y', 'tertiary_distance_3', 'd_2_0', 'dist_O_0_x', 'd_5_1', 'dist_O_0_y', 'adC3', 'inv_dist0R', 'dist_C_3_y', 'atom_index_1_ hybridization', 'cos_f0', 'dist_C_2_x', 'd_5_2', 'd_6_1', 'dist_C_0_x', 'atom_1_bond_lengths_min', 'mulliken_atom_1', 'distance_farthest_0', 'tertiary_distance_1', 'min_molecule_atom_1_dist_xyz', 'yukawa_O.y', 'atom_0_bond_lengths_max'],\n",
    "['tertiary_angle_0', 'd_2_1', 'cos_c0', 'atom_1_bond_lengths_mean', 'd_3_1', 'd_2_0', 'tertiary_distance_1', 'd_3_2', 'tertiary_angle_1', 'cos_f0', 'tertiary_distance_2', 'dist_C_0_x', 'dist_H_0_x', 'dist_C_2_x', 'dist_O_0_y', 'd_4_1', 'd_4_3', 'atom_index_1_cycle_size_mean', 'molecule_atom_index_0_dist_min_diff', 'tertiary_atom_2', 'atom_4', 'cos_c0_f0', 'tertiary_distance_3', 'd_3_0', 'dist_median_bond_y', 'd_5_2', 'adC3', 'atom_5', 'dist_H_1_x', 'molecule_atom_index_0_dist_min_div', 'gap', 'molecule_atom_index_1_dist_min_div', 'dist_O_0_x', 'cos_c1', 'dist_C_0_y', 'd_5_1', 'dist_N_0_y', 'dist_C_3_y', 'dist_no_bond_min_y', 'd_4_0', 'dist_N_0_x', 'd_4_2', 'max_molecule_atom_0_dist_xyz', 'cos_c0_c1', 'adC2', 'atom_index_1_n_cycle', 'd_5_0', 'd_6_1', 'dist_C_4_y', 'dist_O_1_y', 'd_7_2', 'tertiary_angle_2', 'd_6_2', 'mulliken_atom_1', 'atom_6', 'd_7_3', 'dist_O_1_x'],\n",
    "['cos_c0_c1', 'atom_4', 'atom_5', 'molecule_atom_index_0_dist_min_diff', 'cos_c1', 'max_molecule_atom_1_dist_xyz', 'dist_to_type_std', 'd_3_2', 'cos_c0', 'dist_O_0_x', 'd_4_3', 'atom_6', 'dist_O_0_y', 'tertiary_atom_1', 'dist_C_2_y', 'd_4_2', 'dist_C_1_y', 'atom_7', 'tertiary_angle_1', 'dist_H_0_y', 'dist_no_bond_min_y', 'distance_c1', 'dist_C_2_x', 'linkM0', 'd_6_2', 'dist_C_0_y', 'd_5_2', 'd_7_2', 'dist_C_3_y', 'd_6_0', 'dihedral', 'max_molecule_atom_0_dist_xyz', 'd_7_3', 'd_6_1', 'dist_H_1_y', 'tertiary_atom_2', 'd_4_0', 'tertiary_atom_0', 'tertiary_angle_3', 'dist_C_0_x', 'dist_to_type_0_mean', 'dist_N_0_y', 'd_4_1', 'cos_c1_f1', 'cos_f0', 'dist_xyz', 'adC2', 'd_5_3', 'cos_f0_f1', 'gap', 'd_7_0', 'cos_f1', 'tertiary_distance_1', 'molecule_atom_index_0_dist_max_diff', 'd_2_1'],\n",
    "['cos_c0', 'tertiary_distance_1', 'cos_c1', 'd_3_2', 'tertiary_angle_1', 'tertiary_angle_0', 'atom_1_n_bonds', 'tertiary_distance_2', 'd_2_1', 'tertiary_angle_2', 'd_4_0', 'molecule_atom_index_0_dist_min_div', 'd_2_0', 'dist_H_0_x', 'd_3_1', 'cos_c0_c1', 'mulliken_atom_1', 'd_8_3', 'd_4_1', 'dist_C_0_y', 'd_3_0', 'atom_index_1_cycle_size_mean', 'dist_C_1_x', 'dist_C_2_x', 'adC2', 'adC1', 'atom_1_bond_lengths_std', 'atom_index_1_n_cycle', 'd_4_2', 'cos_f0', 'd_5_2', 'dist_to_type_0_mean', 'dist_O_0_x', 'molecule_atom_index_0_dist_std_diff', 'd_5_1', 'tertiary_angle_3', 'd_6_2', 'd_7_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cols = []\n",
    "for cols in type_columns:\n",
    "    unique_cols += cols\n",
    "unique_cols = list(set(unique_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_cols = pd.read_pickle(f'{file_folder}/df_train2_plus.gzde', compression='gzip').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cols_plus = [col for col in unique_cols if col in plus_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cols_data2 = list(set(unique_cols) - set(unique_cols_plus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 48)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_cols_data2), len(unique_cols_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2 = pd.read_pickle(f'{file_folder}/df_train2.gzde', compression='gzip')[['index', 'type', 'group', 'scalar_coupling_constant', 'fc', 'sd','pso','dso']+unique_cols_data2]\n",
    "df_train2_plus = pd.read_pickle(f'{file_folder}/df_train2_plus.gzde', compression='gzip')[['id']+unique_cols_plus]\n",
    "df_train2_plus = df_train2_plus.rename(columns={'id':'index'})\n",
    "df_train2 = pd.merge(df_train2, df_train2_plus, how='left', on='index')\n",
    "df_train2 = df_train2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2 = pd.read_pickle(f'{file_folder}/df_test2.gzde', compression='gzip')[['index', 'type', 'group']+unique_cols_data2]\n",
    "df_test2_plus = pd.read_pickle(f'{file_folder}/df_test2_plus.gzde', compression='gzip')[['id']+unique_cols_plus]\n",
    "df_test2_plus = df_test2_plus.rename(columns={'id':'index'})\n",
    "df_test2 = pd.merge(df_test2, df_test2_plus, how='left', on='index')\n",
    "df_test2 = df_test2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "for f in [f for f in os.listdir('./') if f.startswith('oof')][:]:\n",
    "    \n",
    "    if 'train' in f:\n",
    "        df_i = pd.read_pickle(f, compression='gzip')\n",
    "        df_train[f'{f}'.replace('_train', '')] = df_i.predict\n",
    "        if 'index' not in df_train.columns:\n",
    "            df_train['index'] = df_i['index']\n",
    "        \n",
    "    if 'test' in f:\n",
    "        df_i = pd.read_pickle(f, compression='gzip')\n",
    "        df_test[f'{f}'.replace('_test', '')] = df_i.drop(columns=['index']).mean(axis=1)\n",
    "        if 'index' not in df_test.columns:\n",
    "            df_test['index'] = df_i['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mpl_scalar_coupling_constant = pd.read_pickle('../MLP/mpl_scalar_coupling_constant_df_his', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mlp_oof = pd.DataFrame()\n",
    "df_test_mlp_oof = pd.DataFrame()\n",
    "\n",
    "for c, g in df_train_mpl_scalar_coupling_constant.groupby(by='type'):\n",
    "    df_test_i = df_test2[df_test2['type']==c][['index', 'type']]\n",
    "    typ_i_test_pred = np.mean(np.array([g['test_predict'].values[i].reshape(-1) for i in np.arange(8)]), axis=0)\n",
    "    df_test_i['pred'] = typ_i_test_pred\n",
    "    df_test_mlp_oof = pd.concat([df_test_mlp_oof, df_test_i], axis=0)\n",
    "    \n",
    "    df_train_i = df_train2[df_train2['type']==c][['index', 'type']]\n",
    "    df_train_i2 = pd.DataFrame()\n",
    "    for idx, row in g.iterrows():\n",
    "        df_train_i2_i = pd.DataFrame({'cv_predict':row['cv_predict'].reshape(-1), 'cv_index':row['cv_index']})\n",
    "        df_train_i2 = pd.concat([df_train_i2, df_train_i2_i], axis=0)\n",
    "    df_train_i2 = df_train_i2.sort_values(by=['cv_index']).reset_index(drop=True)\n",
    "    df_train_i['pred'] = df_train_i2['cv_predict'].values\n",
    "    df_train_mlp_oof = pd.concat([df_train_mlp_oof, df_train_i], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mlp_oof = df_train_mlp_oof.sort_values(by=['index']).reset_index(drop=True)\n",
    "df_test_mlp_oof = df_test_mlp_oof.sort_values(by=['index']).reset_index(drop=True)\n",
    "df_train = pd.merge(df_train, df_train_mlp_oof[['index','pred']], how='left', on='index')\n",
    "df_test = pd.merge(df_test, df_test_mlp_oof[['index','pred']], how='left', on='index')\n",
    "df_train = df_train.rename(columns={'pred':'mlp_oof_scalar_coupling_constant'})\n",
    "df_test = df_test.rename(columns={'pred':'mlp_oof_scalar_coupling_constant'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mpl_scalar_coupling_constant = pd.read_pickle('../MLP/mpl_cf_df_his', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mlp_oof = pd.DataFrame()\n",
    "df_test_mlp_oof = pd.DataFrame()\n",
    "\n",
    "for c, g in df_train_mpl_scalar_coupling_constant.groupby(by='type'):\n",
    "    df_test_i = df_test2[df_test2['type']==c][['index', 'type']]\n",
    "    typ_i_test_pred = np.mean(np.array([g['test_predict'].values[i].reshape(-1) for i in np.arange(8)]), axis=0)\n",
    "    df_test_i['pred'] = typ_i_test_pred\n",
    "    df_test_mlp_oof = pd.concat([df_test_mlp_oof, df_test_i], axis=0)\n",
    "    \n",
    "    df_train_i = df_train2[df_train2['type']==c][['index', 'type']]\n",
    "    df_train_i2 = pd.DataFrame()\n",
    "    for idx, row in g.iterrows():\n",
    "        df_train_i2_i = pd.DataFrame({'cv_predict':row['cv_predict'].reshape(-1), 'cv_index':row['cv_index']})\n",
    "        df_train_i2 = pd.concat([df_train_i2, df_train_i2_i], axis=0)\n",
    "    df_train_i2 = df_train_i2.sort_values(by=['cv_index']).reset_index(drop=True)\n",
    "    df_train_i['pred'] = df_train_i2['cv_predict'].values\n",
    "    df_train_mlp_oof = pd.concat([df_train_mlp_oof, df_train_i], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mlp_oof = df_train_mlp_oof.sort_values(by=['index']).reset_index(drop=True)\n",
    "df_test_mlp_oof = df_test_mlp_oof.sort_values(by=['index']).reset_index(drop=True)\n",
    "df_train = pd.merge(df_train, df_train_mlp_oof[['index','pred']], how='left', on='index')\n",
    "df_test = pd.merge(df_test, df_test_mlp_oof[['index','pred']], how='left', on='index')\n",
    "df_train = df_train.rename(columns={'pred':'mlp_oof_fc'})\n",
    "df_test = df_test.rename(columns={'pred':'mlp_oof_fc'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oof_dso</th>\n",
       "      <th>index</th>\n",
       "      <th>oof_sd</th>\n",
       "      <th>oof_fc</th>\n",
       "      <th>oof_scalar_coupling_constant</th>\n",
       "      <th>oof_pso</th>\n",
       "      <th>mlp_oof_scalar_coupling_constant</th>\n",
       "      <th>mlp_oof_fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.583821</td>\n",
       "      <td>0</td>\n",
       "      <td>0.189274</td>\n",
       "      <td>90.224008</td>\n",
       "      <td>91.493771</td>\n",
       "      <td>0.926091</td>\n",
       "      <td>100.168930</td>\n",
       "      <td>46.492760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.915633</td>\n",
       "      <td>1</td>\n",
       "      <td>0.363588</td>\n",
       "      <td>-8.397441</td>\n",
       "      <td>-8.084382</td>\n",
       "      <td>2.523980</td>\n",
       "      <td>-8.027070</td>\n",
       "      <td>-9.531610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.915028</td>\n",
       "      <td>2</td>\n",
       "      <td>0.364233</td>\n",
       "      <td>-8.391713</td>\n",
       "      <td>-8.178881</td>\n",
       "      <td>2.527034</td>\n",
       "      <td>-8.632926</td>\n",
       "      <td>-9.488376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.846344</td>\n",
       "      <td>3</td>\n",
       "      <td>0.362805</td>\n",
       "      <td>-8.487367</td>\n",
       "      <td>-8.160519</td>\n",
       "      <td>2.555150</td>\n",
       "      <td>-8.263496</td>\n",
       "      <td>-9.535721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.584647</td>\n",
       "      <td>4</td>\n",
       "      <td>0.193071</td>\n",
       "      <td>90.240412</td>\n",
       "      <td>90.075054</td>\n",
       "      <td>0.937775</td>\n",
       "      <td>99.038750</td>\n",
       "      <td>46.013512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    oof_dso  index    oof_sd     oof_fc  oof_scalar_coupling_constant  \\\n",
       "0  0.583821      0  0.189274  90.224008                     91.493771   \n",
       "1 -2.915633      1  0.363588  -8.397441                     -8.084382   \n",
       "2 -2.915028      2  0.364233  -8.391713                     -8.178881   \n",
       "3 -2.846344      3  0.362805  -8.487367                     -8.160519   \n",
       "4  0.584647      4  0.193071  90.240412                     90.075054   \n",
       "\n",
       "    oof_pso  mlp_oof_scalar_coupling_constant  mlp_oof_fc  \n",
       "0  0.926091                        100.168930   46.492760  \n",
       "1  2.523980                         -8.027070   -9.531610  \n",
       "2  2.527034                         -8.632926   -9.488376  \n",
       "3  2.555150                         -8.263496   -9.535721  \n",
       "4  0.937775                         99.038750   46.013512  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'scalar_coupling_constant', 'fc', 'sd','pso','dso'\n",
    "\n",
    "df_train = pd.merge(df_train2[['index', 'type', 'group', 'scalar_coupling_constant', 'fc', 'sd','pso','dso']+unique_cols], df_train, how='left', on='index')\n",
    "df_train['y'] = df_train2['scalar_coupling_constant']\n",
    "df_test = pd.merge(df_test2[['index', 'type', 'group']+unique_cols], df_test, how='left', on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_param = {'columns': [], 'cv': {'cls': 'GroupKFold', 'init': {'n_splits': 8}}, 'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}}, 'model': {'cls': 'lgb.LGBMRegressor', 'init': {\n",
    "        'learning_rate': 0.2,\n",
    "    'num_leaves': 128,\n",
    "    'min_child_samples': 79,\n",
    "    'max_depth': 9,\n",
    "    'subsample_freq': 1,\n",
    "    'subsample': 0.9,\n",
    "    'bagging_seed': 11,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.3,\n",
    "    'colsample_bytree': 1.0, 'n_estimators':6000, 'n_jobs': 16}, 'fit': {}}, 'metric': 'mean_absolute_error'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_cols = ['oof_dso', 'oof_fc', 'oof_pso', 'oof_scalar_coupling_constant', 'oof_sd', 'mlp_oof_scalar_coupling_constant', 'mlp_oof_fc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_columns = [oof_cols+['tertiary_angle_0', 'inv_dist1R', 'd_4_3', 'yukawa_H.y', 'mulliken_atom_0', 'dist_to_type_mean', 'dist_O_0_x', 'atom_1_n_bonds', 'dist_to_type_1_mean', 'atom_1_bond_lengths_mean', 'dist_xyz', 'dist_C_0_y', 'd_3_2', 'atom_index_1_ hybridization', 'atom_index_1_cycle_size_mean', 'dist_O_0_y', 'eem_1', 'inv_distPE', 'd_4_2', 'inv_distPR', 'dist_no_bond_min_y', 'dist_H_2_x', 'dist_H_1_x', 'tertiary_distance_2', 'dist_C_3_x', 'dist_O_1_x', 'atom_1_bond_lengths_std', 'dist_C_2_y', 'dist_C_2_x', 'mulliken_atom_1', 'cos_center1', 'dist_O_1_y', 'tertiary_angle_3', 'dist_H_2_y', 'dist_N_0_y', 'dist_C_1_y', 'inv_dist1E', 'distance_y', 'tertiary_angle_2', 'dist_N_0_x', 'd_2_1', 'molecule_atom_index_0_dist_max_div', 'adC1', 'adN1', 'd_4_0', 'dist_C_3_y', 'atom_3', 'distC0', 'tertiary_distance_4', 'tertiary_angle_5', 'd_5_1', 'molecule_atom_index_1_dist_min_diff', 'dist_C_4_y', 'dist_H_0_y', 'cos_f0', 'd_5_0', 'tertiary_distance_3', 'd_5_2', 'tertiary_atom_1', 'dist_C_4_x', 'cos_c0_f0', 'atom_index_0_sv_3', 'rc_C', 'cos_f1', 'tertiary_angle_8', 'dist_O_2_y', 'max_molecule_atom_1_dist_xyz', 'dist_F_0_y', 'atom_index_1_ aromatic', 'tertiary_angle_26', 'type_0'],\n",
    "oof_cols+['dist_H_0_y', 'd_3_2', 'dist_C_0_y', 'atom_index_1_ aromatic', 'atom_1_bond_lengths_mean', 'bond_atom', 'inv_dist1R', 'd_3_1', 'mulliken_atom_0', 'dist_H_0_x', 'dist_O_0_y', 'dist_C_1_x', 'tertiary_angle_0', 'dist_C_1_y', 'vander_C.y', 'dist_H_1_y', 'mulliken_atom_1', 'inv_dist0R', 'd_1_0', 'tertiary_distance_0', 'tertiary_angle_2', 'atom_index_1_explicit_valence', 'dist_N_0_y', 'inv_distPR', 'dist_C_2_x', 'vander_H.x', 'd_4_2', 'atom_index_0_eigv_max', 'tertiary_distance_2', 'dist_H_1_x', 'dist_N_1_x', 'dist_C_3_x', 'cos_f0', 'atom_index_1_sv_2', 'max_molecule_atom_0_dist_xyz', 'd_2_1'],\n",
    "oof_cols+['tertiary_atom_0', 'inv_dist0', 'dist_no_bond_min_x', 'atom_index_1_ hybridization', 'tertiary_angle_0', 'tertiary_angle_1', 'dist_O_0_x', 'cos_c0', 'd_5_2', 'tertiary_atom_1', 'cos_f0', 'dist_H_0_x', 'd_3_1', 'atom_index_1_degree', 'dist_C_0_y', 'adC2', 'dist_C_3_x', 'vander_O.y', 'mulliken_atom_1', 'atom_7', 'tertiary_angle_2', 'd_2_1', 'atom_3', 'd_5_1', 'd_6_2', 'd_4_1', 'tertiary_atom_2', 'molecule_atom_index_1_dist_min_diff', 'd_4_2', 'dist_C_2_x', 'cos_c0_f0', 'd_6_0', 'dist_O_0_y', 'd_4_3', 'd_3_0', 'd_7_0', 'd_3_2', 'inv_dist0R', 'atom_8', 'dist_C_1_x', 'd_6_1', 'd_2_0', 'd_8_1', 'mulliken_atom_0', 'dist_N_0_x', 'atom_4', 'tertiary_distance_2', 'd_7_2', 'dist_C_0_x', 'atom_1_bond_lengths_mean', 'dist_C_1_y', 'bond_atom', 'd_7_1', 'd_4_0', 'distC0', 'atom_index_1_cycle_size_mean', 'cos_c0_c1', 'tertiary_angle_3', 'dist_O_1_x', 'atom_index_1_n_cycle', 'max_molecule_atom_0_dist_xyz', 'molecule_atom_index_0_dist_max_div', 'atom_5', 'gap', 'cos_c1', 'dist_N_0_y', 'd_6_3', 'dist_C_3_y', 'inv_distP', 'dist_C_4_y'],\n",
    "oof_cols+['cos_c0', 'd_4_3', 'cos_c0_c1', 'molecule_atom_index_0_dist_min_diff', 'tertiary_atom_1', 'd_3_2', 'd_1_0', 'dist_H_0_y', 'mulliken_atom_0', 'mulliken_atom_1', 'dist_N_0_x', 'link0', 'tertiary_atom_2', 'dist_C_1_y', 'dist_C_1_x', 'cos_f0', 'dist_C_0_y', 'cos_f1', 'd_3_1', 'tertiary_distance_1', 'dist_O_0_y', 'cos_f0_f1', 'adC1', 'd_5_3', 'inv_distP', 'edge_4', 'd_6_2', 'dist_N_0_y', 'tertiary_distance_2', 'dist_O_0_x', 'cos_c1_f1', 'd_3_0', 'd_5_2', 'dist_C_0_x', 'adN1', 'cos_c0_f0', 'd_4_1', 'max_distance_y', 'dist_C_2_y', 'atom_5', 'adC3', 'dist_to_type_1_mean', 'vander_H.x', 'dist_C_3_y', 'dist_H_3_x', 'molecule_atom_index_0_dist_max_div', 'atom_7', 'dist_C_3_x', 'd_5_1', 'dist_H_3_y', 'atom_index_0_eigv_max', 'atom_6', 'dist_H_2_x', 'atom_index_1_sv_0', 'molecule_atom_index_1_dist_std_div', 'link1'],\n",
    "oof_cols+['d_3_1', 'dist_H_1_x', 'd_5_0', 'd_4_0', 'yukawa_H.x', 'inv_dist0', 'd_6_0', 'd_4_1', 'cos_c0', 'atom_3', 'dist_C_0_y', 'molecule_atom_index_0_dist_std_div', 'cos_c0_c1', 'd_4_2', 'min_molecule_atom_0_dist_xyz', 'sd_molecule_atom_0_dist_xyz', 'd_2_1', 'adC2', 'd_3_0', 'dist_C_1_y', 'd_4_3', 'dist_H_0_x', 'vander_C.x', 'd_5_3', 'dist_H_1_y', 'tertiary_distance_3', 'd_2_0', 'dist_O_0_x', 'd_5_1', 'dist_O_0_y', 'adC3', 'inv_dist0R', 'dist_C_3_y', 'atom_index_1_ hybridization', 'cos_f0', 'dist_C_2_x', 'd_5_2', 'd_6_1', 'dist_C_0_x', 'atom_1_bond_lengths_min', 'mulliken_atom_1', 'distance_farthest_0', 'tertiary_distance_1', 'min_molecule_atom_1_dist_xyz', 'yukawa_O.y', 'atom_0_bond_lengths_max'],\n",
    "oof_cols+['tertiary_angle_0', 'd_2_1', 'cos_c0', 'atom_1_bond_lengths_mean', 'd_3_1', 'd_2_0', 'tertiary_distance_1', 'd_3_2', 'tertiary_angle_1', 'cos_f0', 'tertiary_distance_2', 'dist_C_0_x', 'dist_H_0_x', 'dist_C_2_x', 'dist_O_0_y', 'd_4_1', 'd_4_3', 'atom_index_1_cycle_size_mean', 'molecule_atom_index_0_dist_min_diff', 'tertiary_atom_2', 'atom_4', 'cos_c0_f0', 'tertiary_distance_3', 'd_3_0', 'dist_median_bond_y', 'd_5_2', 'adC3', 'atom_5', 'dist_H_1_x', 'molecule_atom_index_0_dist_min_div', 'gap', 'molecule_atom_index_1_dist_min_div', 'dist_O_0_x', 'cos_c1', 'dist_C_0_y', 'd_5_1', 'dist_N_0_y', 'dist_C_3_y', 'dist_no_bond_min_y', 'd_4_0', 'dist_N_0_x', 'd_4_2', 'max_molecule_atom_0_dist_xyz', 'cos_c0_c1', 'adC2', 'atom_index_1_n_cycle', 'd_5_0', 'd_6_1', 'dist_C_4_y', 'dist_O_1_y', 'd_7_2', 'tertiary_angle_2', 'd_6_2', 'mulliken_atom_1', 'atom_6', 'd_7_3', 'dist_O_1_x'],\n",
    "oof_cols+['cos_c0_c1', 'atom_4', 'atom_5', 'molecule_atom_index_0_dist_min_diff', 'cos_c1', 'max_molecule_atom_1_dist_xyz', 'dist_to_type_std', 'd_3_2', 'cos_c0', 'dist_O_0_x', 'd_4_3', 'atom_6', 'dist_O_0_y', 'tertiary_atom_1', 'dist_C_2_y', 'd_4_2', 'dist_C_1_y', 'atom_7', 'tertiary_angle_1', 'dist_H_0_y', 'dist_no_bond_min_y', 'distance_c1', 'dist_C_2_x', 'linkM0', 'd_6_2', 'dist_C_0_y', 'd_5_2', 'd_7_2', 'dist_C_3_y', 'd_6_0', 'dihedral', 'max_molecule_atom_0_dist_xyz', 'd_7_3', 'd_6_1', 'dist_H_1_y', 'tertiary_atom_2', 'd_4_0', 'tertiary_atom_0', 'tertiary_angle_3', 'dist_C_0_x', 'dist_to_type_0_mean', 'dist_N_0_y', 'd_4_1', 'cos_c1_f1', 'cos_f0', 'dist_xyz', 'adC2', 'd_5_3', 'cos_f0_f1', 'gap', 'd_7_0', 'cos_f1', 'tertiary_distance_1', 'molecule_atom_index_0_dist_max_diff', 'd_2_1'],\n",
    "oof_cols+['cos_c0', 'tertiary_distance_1', 'cos_c1', 'd_3_2', 'tertiary_angle_1', 'tertiary_angle_0', 'atom_1_n_bonds', 'tertiary_distance_2', 'd_2_1', 'tertiary_angle_2', 'd_4_0', 'molecule_atom_index_0_dist_min_div', 'd_2_0', 'dist_H_0_x', 'd_3_1', 'cos_c0_c1', 'mulliken_atom_1', 'd_8_3', 'd_4_1', 'dist_C_0_y', 'd_3_0', 'atom_index_1_cycle_size_mean', 'dist_C_1_x', 'dist_C_2_x', 'adC2', 'adC1', 'atom_1_bond_lengths_std', 'atom_index_1_n_cycle', 'd_4_2', 'cos_f0', 'd_5_2', 'dist_to_type_0_mean', 'dist_O_0_x', 'molecule_atom_index_0_dist_std_diff', 'd_5_1', 'tertiary_angle_3', 'd_6_2', 'd_7_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytrial=[]\n",
    "df_his, df_feature_importances, df_valid_pred, df_test_pred = pd.DataFrame(), pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "for t in  df_train.type.unique().tolist():\n",
    "    \n",
    "    param = base_param.copy()\n",
    "    param['columns'] = type_columns[t]\n",
    "    \n",
    "    df_his_i, df_feature_importances_i, df_valid_pred_i, df_test_pred_i =  sk_process(df_train[df_train['type']==t].reset_index(drop=True), param, f'modeling for {t}', df_test=df_test[df_test['type']==t].reset_index(drop=True), trial=mytrial, is_output_feature_importance=False, trial_level=1)\n",
    "    df_his = pd.concat([df_his, df_his_i], axis=0)\n",
    "    df_feature_importances = pd.concat([df_feature_importances, df_feature_importances_i], axis=0)\n",
    "    df_valid_pred = pd.concat([df_valid_pred, df_valid_pred_i], axis=0)\n",
    "    df_test_pred = pd.concat([df_test_pred, df_test_pred_i], axis=0)\n",
    "    \n",
    "\n",
    "df_valid_pred = df_valid_pred.sort_values(by=['index']).reset_index(drop=True)\n",
    "df_test_pred = df_test_pred.sort_values(by=['index']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19680933129062264\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>message</th>\n",
       "      <th>nfeatures</th>\n",
       "      <th>train_metric_mean</th>\n",
       "      <th>val_metric_mean</th>\n",
       "      <th>trn_val_metric_diff</th>\n",
       "      <th>trn_val_metric_diff_rate</th>\n",
       "      <th>message</th>\n",
       "      <th>log_val_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-27 23:57:55.553803</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>78</td>\n",
       "      <td>0.111997</td>\n",
       "      <td>0.440295</td>\n",
       "      <td>0.328298</td>\n",
       "      <td>2.931300</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>-0.820309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-28 00:19:00.719956</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>63</td>\n",
       "      <td>0.012134</td>\n",
       "      <td>0.083802</td>\n",
       "      <td>0.071668</td>\n",
       "      <td>5.906349</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>-2.479297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-28 00:22:00.175246</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>43</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.231584</td>\n",
       "      <td>0.227878</td>\n",
       "      <td>61.501173</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>-1.462814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-28 00:29:36.688909</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>53</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>0.104345</td>\n",
       "      <td>0.099040</td>\n",
       "      <td>18.669680</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>-2.260051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-28 01:28:20.251117</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>77</td>\n",
       "      <td>0.064873</td>\n",
       "      <td>0.175557</td>\n",
       "      <td>0.110684</td>\n",
       "      <td>1.706164</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>-1.739793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-08-28 02:00:45.284028</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>62</td>\n",
       "      <td>0.023494</td>\n",
       "      <td>0.108866</td>\n",
       "      <td>0.085372</td>\n",
       "      <td>3.633800</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>-2.217634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-28 03:12:50.420029</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.077909</td>\n",
       "      <td>0.179805</td>\n",
       "      <td>0.101897</td>\n",
       "      <td>1.307903</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>-1.715880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-28 03:23:05.128924</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>45</td>\n",
       "      <td>0.005605</td>\n",
       "      <td>0.084868</td>\n",
       "      <td>0.079263</td>\n",
       "      <td>14.141634</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>-2.466664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime         message  nfeatures  train_metric_mean  \\\n",
       "0 2019-08-27 23:57:55.553803  modeling for 0         78           0.111997   \n",
       "1 2019-08-28 00:19:00.719956  modeling for 3         63           0.012134   \n",
       "2 2019-08-28 00:22:00.175246  modeling for 1         43           0.003705   \n",
       "3 2019-08-28 00:29:36.688909  modeling for 4         53           0.005305   \n",
       "4 2019-08-28 01:28:20.251117  modeling for 2         77           0.064873   \n",
       "5 2019-08-28 02:00:45.284028  modeling for 6         62           0.023494   \n",
       "6 2019-08-28 03:12:50.420029  modeling for 5         64           0.077909   \n",
       "7 2019-08-28 03:23:05.128924  modeling for 7         45           0.005605   \n",
       "\n",
       "   val_metric_mean  trn_val_metric_diff  trn_val_metric_diff_rate  \\\n",
       "0         0.440295             0.328298                  2.931300   \n",
       "1         0.083802             0.071668                  5.906349   \n",
       "2         0.231584             0.227878                 61.501173   \n",
       "3         0.104345             0.099040                 18.669680   \n",
       "4         0.175557             0.110684                  1.706164   \n",
       "5         0.108866             0.085372                  3.633800   \n",
       "6         0.179805             0.101897                  1.307903   \n",
       "7         0.084868             0.079263                 14.141634   \n",
       "\n",
       "          message  log_val_mae  \n",
       "0  modeling for 0    -0.820309  \n",
       "1  modeling for 3    -2.479297  \n",
       "2  modeling for 1    -1.462814  \n",
       "3  modeling for 4    -2.260051  \n",
       "4  modeling for 2    -1.739793  \n",
       "5  modeling for 6    -2.217634  \n",
       "6  modeling for 5    -1.715880  \n",
       "7  modeling for 7    -2.466664  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#oof 6000+mlp_oof\n",
    "df_trial = pd.DataFrame(mytrial)\n",
    "df_trial['trn_val_metric_diff_rate'] = df_trial['trn_val_metric_diff'] / df_trial['train_metric_mean']\n",
    "df_trial['log_val_mae'] = df_trial['val_metric_mean'].apply(lambda x : np.log(x))\n",
    "print(mean_absolute_error(df_valid_pred.sort_values(by=['index']).reset_index(drop=True).predict.values, df_train.reset_index(drop=True).y.values))\n",
    "df_trial[['datetime', 'message', 'nfeatures', 'train_metric_mean', 'val_metric_mean', 'trn_val_metric_diff', 'trn_val_metric_diff_rate', 'message', 'log_val_mae']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0.19\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit['scalar_coupling_constant'] = np.mean(df_test_pred.drop(columns=['index']).values, axis=1)\n",
    "df_submit['id'] = df_test_pred['index']\n",
    "df_submit.to_csv('../../data/submission/submission_lgbm_{}.csv'.format(idx), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22349775220910345\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>message</th>\n",
       "      <th>nfeatures</th>\n",
       "      <th>train_metric_mean</th>\n",
       "      <th>val_metric_mean</th>\n",
       "      <th>trn_val_metric_diff</th>\n",
       "      <th>trn_val_metric_diff_rate</th>\n",
       "      <th>message</th>\n",
       "      <th>log_val_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-24 03:04:02.557188</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>76</td>\n",
       "      <td>0.122242</td>\n",
       "      <td>0.494106</td>\n",
       "      <td>0.371864</td>\n",
       "      <td>3.042028</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>-0.705005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-24 03:26:31.057298</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>61</td>\n",
       "      <td>0.013033</td>\n",
       "      <td>0.099362</td>\n",
       "      <td>0.086329</td>\n",
       "      <td>6.623861</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>-2.308984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-24 03:29:30.339839</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.269747</td>\n",
       "      <td>0.265873</td>\n",
       "      <td>68.626022</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>-1.310269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-24 03:37:12.837841</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>51</td>\n",
       "      <td>0.005427</td>\n",
       "      <td>0.119825</td>\n",
       "      <td>0.114398</td>\n",
       "      <td>21.078802</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>-2.121720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-24 04:41:55.586265</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>75</td>\n",
       "      <td>0.073074</td>\n",
       "      <td>0.198792</td>\n",
       "      <td>0.125718</td>\n",
       "      <td>1.720405</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>-1.615496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-08-24 05:15:34.995034</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>60</td>\n",
       "      <td>0.026436</td>\n",
       "      <td>0.121113</td>\n",
       "      <td>0.094676</td>\n",
       "      <td>3.581289</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>-2.111035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-24 06:27:49.172977</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>62</td>\n",
       "      <td>0.092379</td>\n",
       "      <td>0.207396</td>\n",
       "      <td>0.115017</td>\n",
       "      <td>1.245049</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>-1.573126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-24 06:38:12.840323</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>43</td>\n",
       "      <td>0.005931</td>\n",
       "      <td>0.092995</td>\n",
       "      <td>0.087064</td>\n",
       "      <td>14.679514</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>-2.375209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime         message  nfeatures  train_metric_mean  \\\n",
       "0 2019-08-24 03:04:02.557188  modeling for 0         76           0.122242   \n",
       "1 2019-08-24 03:26:31.057298  modeling for 3         61           0.013033   \n",
       "2 2019-08-24 03:29:30.339839  modeling for 1         41           0.003874   \n",
       "3 2019-08-24 03:37:12.837841  modeling for 4         51           0.005427   \n",
       "4 2019-08-24 04:41:55.586265  modeling for 2         75           0.073074   \n",
       "5 2019-08-24 05:15:34.995034  modeling for 6         60           0.026436   \n",
       "6 2019-08-24 06:27:49.172977  modeling for 5         62           0.092379   \n",
       "7 2019-08-24 06:38:12.840323  modeling for 7         43           0.005931   \n",
       "\n",
       "   val_metric_mean  trn_val_metric_diff  trn_val_metric_diff_rate  \\\n",
       "0         0.494106             0.371864                  3.042028   \n",
       "1         0.099362             0.086329                  6.623861   \n",
       "2         0.269747             0.265873                 68.626022   \n",
       "3         0.119825             0.114398                 21.078802   \n",
       "4         0.198792             0.125718                  1.720405   \n",
       "5         0.121113             0.094676                  3.581289   \n",
       "6         0.207396             0.115017                  1.245049   \n",
       "7         0.092995             0.087064                 14.679514   \n",
       "\n",
       "          message  log_val_mae  \n",
       "0  modeling for 0    -0.705005  \n",
       "1  modeling for 3    -2.308984  \n",
       "2  modeling for 1    -1.310269  \n",
       "3  modeling for 4    -2.121720  \n",
       "4  modeling for 2    -1.615496  \n",
       "5  modeling for 6    -2.111035  \n",
       "6  modeling for 5    -1.573126  \n",
       "7  modeling for 7    -2.375209  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#oof 6000\n",
    "df_trial = pd.DataFrame(mytrial)\n",
    "df_trial['trn_val_metric_diff_rate'] = df_trial['trn_val_metric_diff'] / df_trial['train_metric_mean']\n",
    "df_trial['log_val_mae'] = df_trial['val_metric_mean'].apply(lambda x : np.log(x))\n",
    "print(mean_absolute_error(df_valid_pred.sort_values(by=['index']).reset_index(drop=True).predict.values, df_train.reset_index(drop=True).y.values))\n",
    "df_trial[['datetime', 'message', 'nfeatures', 'train_metric_mean', 'val_metric_mean', 'trn_val_metric_diff', 'trn_val_metric_diff_rate', 'message', 'log_val_mae']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0.22\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit['scalar_coupling_constant'] = np.mean(df_test_pred.drop(columns=['index']).values, axis=1)\n",
    "df_submit['id'] = df_test_pred['index']\n",
    "df_submit.to_csv('../../data/submission/submission_lgbm_{}.csv'.format(idx), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23163372536444632\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>message</th>\n",
       "      <th>nfeatures</th>\n",
       "      <th>train_metric_mean</th>\n",
       "      <th>val_metric_mean</th>\n",
       "      <th>trn_val_metric_diff</th>\n",
       "      <th>trn_val_metric_diff_rate</th>\n",
       "      <th>message</th>\n",
       "      <th>log_val_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-24 00:40:46.668080</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>76</td>\n",
       "      <td>0.227997</td>\n",
       "      <td>0.509482</td>\n",
       "      <td>0.281484</td>\n",
       "      <td>1.234594</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>-0.674362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-24 00:48:21.574991</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>61</td>\n",
       "      <td>0.030568</td>\n",
       "      <td>0.102422</td>\n",
       "      <td>0.071854</td>\n",
       "      <td>2.350616</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>-2.278657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-24 00:49:22.455050</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.017915</td>\n",
       "      <td>0.271283</td>\n",
       "      <td>0.253368</td>\n",
       "      <td>14.142476</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>-1.304591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-24 00:51:55.256397</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>51</td>\n",
       "      <td>0.016785</td>\n",
       "      <td>0.121361</td>\n",
       "      <td>0.104575</td>\n",
       "      <td>6.230165</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>-2.108989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-24 01:15:55.821767</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>75</td>\n",
       "      <td>0.115857</td>\n",
       "      <td>0.207057</td>\n",
       "      <td>0.091199</td>\n",
       "      <td>0.787170</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>-1.574762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-08-24 01:27:31.552372</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>60</td>\n",
       "      <td>0.050388</td>\n",
       "      <td>0.124560</td>\n",
       "      <td>0.074172</td>\n",
       "      <td>1.471996</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>-2.082967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-24 01:55:06.608500</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>62</td>\n",
       "      <td>0.136360</td>\n",
       "      <td>0.216603</td>\n",
       "      <td>0.080243</td>\n",
       "      <td>0.588462</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>-1.529688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-24 01:58:09.234091</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>43</td>\n",
       "      <td>0.015689</td>\n",
       "      <td>0.094285</td>\n",
       "      <td>0.078596</td>\n",
       "      <td>5.009643</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>-2.361438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime         message  nfeatures  train_metric_mean  \\\n",
       "0 2019-08-24 00:40:46.668080  modeling for 0         76           0.227997   \n",
       "1 2019-08-24 00:48:21.574991  modeling for 3         61           0.030568   \n",
       "2 2019-08-24 00:49:22.455050  modeling for 1         41           0.017915   \n",
       "3 2019-08-24 00:51:55.256397  modeling for 4         51           0.016785   \n",
       "4 2019-08-24 01:15:55.821767  modeling for 2         75           0.115857   \n",
       "5 2019-08-24 01:27:31.552372  modeling for 6         60           0.050388   \n",
       "6 2019-08-24 01:55:06.608500  modeling for 5         62           0.136360   \n",
       "7 2019-08-24 01:58:09.234091  modeling for 7         43           0.015689   \n",
       "\n",
       "   val_metric_mean  trn_val_metric_diff  trn_val_metric_diff_rate  \\\n",
       "0         0.509482             0.281484                  1.234594   \n",
       "1         0.102422             0.071854                  2.350616   \n",
       "2         0.271283             0.253368                 14.142476   \n",
       "3         0.121361             0.104575                  6.230165   \n",
       "4         0.207057             0.091199                  0.787170   \n",
       "5         0.124560             0.074172                  1.471996   \n",
       "6         0.216603             0.080243                  0.588462   \n",
       "7         0.094285             0.078596                  5.009643   \n",
       "\n",
       "          message  log_val_mae  \n",
       "0  modeling for 0    -0.674362  \n",
       "1  modeling for 3    -2.278657  \n",
       "2  modeling for 1    -1.304591  \n",
       "3  modeling for 4    -2.108989  \n",
       "4  modeling for 2    -1.574762  \n",
       "5  modeling for 6    -2.082967  \n",
       "6  modeling for 5    -1.529688  \n",
       "7  modeling for 7    -2.361438  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#oof\n",
    "df_trial = pd.DataFrame(mytrial)\n",
    "df_trial['trn_val_metric_diff_rate'] = df_trial['trn_val_metric_diff'] / df_trial['train_metric_mean']\n",
    "df_trial['log_val_mae'] = df_trial['val_metric_mean'].apply(lambda x : np.log(x))\n",
    "print(mean_absolute_error(df_valid_pred.sort_values(by=['index']).reset_index(drop=True).predict.values, df_train.reset_index(drop=True).y.values))\n",
    "df_trial[['datetime', 'message', 'nfeatures', 'train_metric_mean', 'val_metric_mean', 'trn_val_metric_diff', 'trn_val_metric_diff_rate', 'message', 'log_val_mae']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0.23\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit['scalar_coupling_constant'] = np.mean(df_test_pred.drop(columns=['index']).values, axis=1)\n",
    "df_submit['id'] = df_test_pred['index']\n",
    "df_submit.to_csv('../../data/submission/submission_lgbm_{}.csv'.format(idx), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009578546187112865\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>message</th>\n",
       "      <th>nfeatures</th>\n",
       "      <th>train_metric_mean</th>\n",
       "      <th>val_metric_mean</th>\n",
       "      <th>trn_val_metric_diff</th>\n",
       "      <th>trn_val_metric_diff_rate</th>\n",
       "      <th>message</th>\n",
       "      <th>log_val_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-22 23:05:23.638616</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.005019</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>1.054147</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>-5.294546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-22 23:15:29.229261</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>56</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>0.019578</td>\n",
       "      <td>0.012839</td>\n",
       "      <td>1.905245</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>-3.933369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-22 23:16:34.822741</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>1.062602</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>-6.200042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-22 23:20:31.127484</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>46</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>1.174550</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>-6.167180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-22 23:52:02.889524</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>70</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.006896</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.630461</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>-4.976877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-08-23 00:06:18.011585</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>55</td>\n",
       "      <td>0.011482</td>\n",
       "      <td>0.025552</td>\n",
       "      <td>0.014070</td>\n",
       "      <td>1.225338</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>-3.667049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-23 01:07:02.009842</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>57</td>\n",
       "      <td>0.004459</td>\n",
       "      <td>0.006610</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.482295</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>-5.019133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-23 01:12:36.323113</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>38</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>1.062423</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>-6.087522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime         message  nfeatures  train_metric_mean  \\\n",
       "0 2019-08-22 23:05:23.638616  modeling for 0         71           0.002443   \n",
       "1 2019-08-22 23:15:29.229261  modeling for 3         56           0.006739   \n",
       "2 2019-08-22 23:16:34.822741  modeling for 1         36           0.000984   \n",
       "3 2019-08-22 23:20:31.127484  modeling for 4         46           0.000964   \n",
       "4 2019-08-22 23:52:02.889524  modeling for 2         70           0.004229   \n",
       "5 2019-08-23 00:06:18.011585  modeling for 6         55           0.011482   \n",
       "6 2019-08-23 01:07:02.009842  modeling for 5         57           0.004459   \n",
       "7 2019-08-23 01:12:36.323113  modeling for 7         38           0.001101   \n",
       "\n",
       "   val_metric_mean  trn_val_metric_diff  trn_val_metric_diff_rate  \\\n",
       "0         0.005019             0.002576                  1.054147   \n",
       "1         0.019578             0.012839                  1.905245   \n",
       "2         0.002029             0.001045                  1.062602   \n",
       "3         0.002097             0.001133                  1.174550   \n",
       "4         0.006896             0.002666                  0.630461   \n",
       "5         0.025552             0.014070                  1.225338   \n",
       "6         0.006610             0.002151                  0.482295   \n",
       "7         0.002271             0.001170                  1.062423   \n",
       "\n",
       "          message  log_val_mae  \n",
       "0  modeling for 0    -5.294546  \n",
       "1  modeling for 3    -3.933369  \n",
       "2  modeling for 1    -6.200042  \n",
       "3  modeling for 4    -6.167180  \n",
       "4  modeling for 2    -4.976877  \n",
       "5  modeling for 6    -3.667049  \n",
       "6  modeling for 5    -5.019133  \n",
       "7  modeling for 7    -6.087522  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dso\n",
    "df_trial = pd.DataFrame(mytrial)\n",
    "df_trial['trn_val_metric_diff_rate'] = df_trial['trn_val_metric_diff'] / df_trial['train_metric_mean']\n",
    "df_trial['log_val_mae'] = df_trial['val_metric_mean'].apply(lambda x : np.log(x))\n",
    "print(mean_absolute_error(df_valid_pred.sort_values(by=['index']).reset_index(drop=True).predict.values, df_train.reset_index(drop=True).y.values))\n",
    "df_trial[['datetime', 'message', 'nfeatures', 'train_metric_mean', 'val_metric_mean', 'trn_val_metric_diff', 'trn_val_metric_diff_rate', 'message', 'log_val_mae']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_pred.to_pickle('oof_dso_train', compression='gzip')\n",
    "df_test_pred.to_pickle('oof_dso_test', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011634202386808\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>message</th>\n",
       "      <th>nfeatures</th>\n",
       "      <th>train_metric_mean</th>\n",
       "      <th>val_metric_mean</th>\n",
       "      <th>trn_val_metric_diff</th>\n",
       "      <th>trn_val_metric_diff_rate</th>\n",
       "      <th>message</th>\n",
       "      <th>log_val_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-22 11:05:06.608505</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.011852</td>\n",
       "      <td>0.006558</td>\n",
       "      <td>1.238966</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>-4.435266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-22 11:14:44.376738</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>56</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.015228</td>\n",
       "      <td>0.009124</td>\n",
       "      <td>1.494666</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>-4.184588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-22 11:17:04.068932</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.016369</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>6.547536</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>-4.112381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-22 11:21:24.964886</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>46</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>2.603808</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>-4.908289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-22 11:51:17.266337</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>70</td>\n",
       "      <td>0.006749</td>\n",
       "      <td>0.011612</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>0.720579</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>-4.455688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-08-22 12:05:40.948671</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>55</td>\n",
       "      <td>0.009028</td>\n",
       "      <td>0.019892</td>\n",
       "      <td>0.010864</td>\n",
       "      <td>1.203308</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>-3.917415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-22 12:37:59.231928</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>57</td>\n",
       "      <td>0.005449</td>\n",
       "      <td>0.008289</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.521266</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>-4.792837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-22 12:43:58.550884</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>38</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.005555</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>2.173226</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>-5.192982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime         message  nfeatures  train_metric_mean  \\\n",
       "0 2019-08-22 11:05:06.608505  modeling for 0         71           0.005293   \n",
       "1 2019-08-22 11:14:44.376738  modeling for 3         56           0.006104   \n",
       "2 2019-08-22 11:17:04.068932  modeling for 1         36           0.002169   \n",
       "3 2019-08-22 11:21:24.964886  modeling for 4         46           0.002049   \n",
       "4 2019-08-22 11:51:17.266337  modeling for 2         70           0.006749   \n",
       "5 2019-08-22 12:05:40.948671  modeling for 6         55           0.009028   \n",
       "6 2019-08-22 12:37:59.231928  modeling for 5         57           0.005449   \n",
       "7 2019-08-22 12:43:58.550884  modeling for 7         38           0.001751   \n",
       "\n",
       "   val_metric_mean  trn_val_metric_diff  trn_val_metric_diff_rate  \\\n",
       "0         0.011852             0.006558                  1.238966   \n",
       "1         0.015228             0.009124                  1.494666   \n",
       "2         0.016369             0.014200                  6.547536   \n",
       "3         0.007385             0.005336                  2.603808   \n",
       "4         0.011612             0.004863                  0.720579   \n",
       "5         0.019892             0.010864                  1.203308   \n",
       "6         0.008289             0.002840                  0.521266   \n",
       "7         0.005555             0.003805                  2.173226   \n",
       "\n",
       "          message  log_val_mae  \n",
       "0  modeling for 0    -4.435266  \n",
       "1  modeling for 3    -4.184588  \n",
       "2  modeling for 1    -4.112381  \n",
       "3  modeling for 4    -4.908289  \n",
       "4  modeling for 2    -4.455688  \n",
       "5  modeling for 6    -3.917415  \n",
       "6  modeling for 5    -4.792837  \n",
       "7  modeling for 7    -5.192982  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pso\n",
    "df_trial = pd.DataFrame(mytrial)\n",
    "df_trial['trn_val_metric_diff_rate'] = df_trial['trn_val_metric_diff'] / df_trial['train_metric_mean']\n",
    "df_trial['log_val_mae'] = df_trial['val_metric_mean'].apply(lambda x : np.log(x))\n",
    "print(mean_absolute_error(df_valid_pred.sort_values(by=['index']).reset_index(drop=True).predict.values, df_train.reset_index(drop=True).y.values))\n",
    "df_trial[['datetime', 'message', 'nfeatures', 'train_metric_mean', 'val_metric_mean', 'trn_val_metric_diff', 'trn_val_metric_diff_rate', 'message', 'log_val_mae']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_pred.to_pickle('oof_pso_train', compression='gzip')\n",
    "df_test_pred.to_pickle('oof_pso_test', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0028518626968526977\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>message</th>\n",
       "      <th>nfeatures</th>\n",
       "      <th>train_metric_mean</th>\n",
       "      <th>val_metric_mean</th>\n",
       "      <th>trn_val_metric_diff</th>\n",
       "      <th>trn_val_metric_diff_rate</th>\n",
       "      <th>message</th>\n",
       "      <th>log_val_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-22 08:21:13.910285</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.964784</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>-5.790894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-22 08:32:59.340831</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>56</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.901471</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>-6.604683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-22 08:34:32.338182</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>1.781626</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>-5.800066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-22 08:38:34.840061</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>46</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>1.433867</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>-6.060733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-22 09:09:57.985913</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>70</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>0.713786</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>-5.533958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-08-22 09:26:40.087047</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.001593</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.752539</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>-6.442167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-22 10:00:30.385933</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>57</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.541210</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>-5.841431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-22 10:06:01.179879</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>38</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>1.353585</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>-6.131662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime         message  nfeatures  train_metric_mean  \\\n",
       "0 2019-08-22 08:21:13.910285  modeling for 0         71           0.001555   \n",
       "1 2019-08-22 08:32:59.340831  modeling for 3         56           0.000712   \n",
       "2 2019-08-22 08:34:32.338182  modeling for 1         36           0.001088   \n",
       "3 2019-08-22 08:38:34.840061  modeling for 4         46           0.000958   \n",
       "4 2019-08-22 09:09:57.985913  modeling for 2         70           0.002305   \n",
       "5 2019-08-22 09:26:40.087047  modeling for 6         55           0.000909   \n",
       "6 2019-08-22 10:00:30.385933  modeling for 5         57           0.001885   \n",
       "7 2019-08-22 10:06:01.179879  modeling for 7         38           0.000923   \n",
       "\n",
       "   val_metric_mean  trn_val_metric_diff  trn_val_metric_diff_rate  \\\n",
       "0         0.003055             0.001500                  0.964784   \n",
       "1         0.001354             0.000642                  0.901471   \n",
       "2         0.003027             0.001939                  1.781626   \n",
       "3         0.002333             0.001374                  1.433867   \n",
       "4         0.003950             0.001645                  0.713786   \n",
       "5         0.001593             0.000684                  0.752539   \n",
       "6         0.002905             0.001020                  0.541210   \n",
       "7         0.002173             0.001250                  1.353585   \n",
       "\n",
       "          message  log_val_mae  \n",
       "0  modeling for 0    -5.790894  \n",
       "1  modeling for 3    -6.604683  \n",
       "2  modeling for 1    -5.800066  \n",
       "3  modeling for 4    -6.060733  \n",
       "4  modeling for 2    -5.533958  \n",
       "5  modeling for 6    -6.442167  \n",
       "6  modeling for 5    -5.841431  \n",
       "7  modeling for 7    -6.131662  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sd\n",
    "df_trial = pd.DataFrame(mytrial)\n",
    "df_trial['trn_val_metric_diff_rate'] = df_trial['trn_val_metric_diff'] / df_trial['train_metric_mean']\n",
    "df_trial['log_val_mae'] = df_trial['val_metric_mean'].apply(lambda x : np.log(x))\n",
    "print(mean_absolute_error(df_valid_pred.sort_values(by=['index']).reset_index(drop=True).predict.values, df_train.reset_index(drop=True).y.values))\n",
    "df_trial[['datetime', 'message', 'nfeatures', 'train_metric_mean', 'val_metric_mean', 'trn_val_metric_diff', 'trn_val_metric_diff_rate', 'message', 'log_val_mae']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_pred.to_pickle('oof_sd_train', compression='gzip')\n",
    "df_test_pred.to_pickle('oof_sd_test', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2642068948259309\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>message</th>\n",
       "      <th>nfeatures</th>\n",
       "      <th>train_metric_mean</th>\n",
       "      <th>val_metric_mean</th>\n",
       "      <th>trn_val_metric_diff</th>\n",
       "      <th>trn_val_metric_diff_rate</th>\n",
       "      <th>message</th>\n",
       "      <th>log_val_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-22 05:56:13.671091</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.249396</td>\n",
       "      <td>0.580054</td>\n",
       "      <td>0.330657</td>\n",
       "      <td>1.325831</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>-0.544634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-22 06:06:05.635389</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>56</td>\n",
       "      <td>0.036385</td>\n",
       "      <td>0.121778</td>\n",
       "      <td>0.085393</td>\n",
       "      <td>2.346925</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>-2.105557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-22 06:07:45.058639</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.029229</td>\n",
       "      <td>0.295462</td>\n",
       "      <td>0.266233</td>\n",
       "      <td>9.108602</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>-1.219215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-22 06:11:35.146473</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>46</td>\n",
       "      <td>0.022341</td>\n",
       "      <td>0.140886</td>\n",
       "      <td>0.118545</td>\n",
       "      <td>5.306092</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>-1.959806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-22 06:41:24.878131</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>70</td>\n",
       "      <td>0.129866</td>\n",
       "      <td>0.235691</td>\n",
       "      <td>0.105825</td>\n",
       "      <td>0.814880</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>-1.445235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-08-22 06:56:02.611189</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>55</td>\n",
       "      <td>0.055249</td>\n",
       "      <td>0.137021</td>\n",
       "      <td>0.081772</td>\n",
       "      <td>1.480057</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>-1.987623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-22 07:28:25.500155</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>57</td>\n",
       "      <td>0.157494</td>\n",
       "      <td>0.249594</td>\n",
       "      <td>0.092100</td>\n",
       "      <td>0.584784</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>-1.387919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-22 07:33:32.002615</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>38</td>\n",
       "      <td>0.018684</td>\n",
       "      <td>0.101022</td>\n",
       "      <td>0.082337</td>\n",
       "      <td>4.406766</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>-2.292422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime         message  nfeatures  train_metric_mean  \\\n",
       "0 2019-08-22 05:56:13.671091  modeling for 0         71           0.249396   \n",
       "1 2019-08-22 06:06:05.635389  modeling for 3         56           0.036385   \n",
       "2 2019-08-22 06:07:45.058639  modeling for 1         36           0.029229   \n",
       "3 2019-08-22 06:11:35.146473  modeling for 4         46           0.022341   \n",
       "4 2019-08-22 06:41:24.878131  modeling for 2         70           0.129866   \n",
       "5 2019-08-22 06:56:02.611189  modeling for 6         55           0.055249   \n",
       "6 2019-08-22 07:28:25.500155  modeling for 5         57           0.157494   \n",
       "7 2019-08-22 07:33:32.002615  modeling for 7         38           0.018684   \n",
       "\n",
       "   val_metric_mean  trn_val_metric_diff  trn_val_metric_diff_rate  \\\n",
       "0         0.580054             0.330657                  1.325831   \n",
       "1         0.121778             0.085393                  2.346925   \n",
       "2         0.295462             0.266233                  9.108602   \n",
       "3         0.140886             0.118545                  5.306092   \n",
       "4         0.235691             0.105825                  0.814880   \n",
       "5         0.137021             0.081772                  1.480057   \n",
       "6         0.249594             0.092100                  0.584784   \n",
       "7         0.101022             0.082337                  4.406766   \n",
       "\n",
       "          message  log_val_mae  \n",
       "0  modeling for 0    -0.544634  \n",
       "1  modeling for 3    -2.105557  \n",
       "2  modeling for 1    -1.219215  \n",
       "3  modeling for 4    -1.959806  \n",
       "4  modeling for 2    -1.445235  \n",
       "5  modeling for 6    -1.987623  \n",
       "6  modeling for 5    -1.387919  \n",
       "7  modeling for 7    -2.292422  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fc\n",
    "df_trial = pd.DataFrame(mytrial)\n",
    "df_trial['trn_val_metric_diff_rate'] = df_trial['trn_val_metric_diff'] / df_trial['train_metric_mean']\n",
    "df_trial['log_val_mae'] = df_trial['val_metric_mean'].apply(lambda x : np.log(x))\n",
    "print(mean_absolute_error(df_valid_pred.sort_values(by=['index']).reset_index(drop=True).predict.values, df_train.reset_index(drop=True).y.values))\n",
    "df_trial[['datetime', 'message', 'nfeatures', 'train_metric_mean', 'val_metric_mean', 'trn_val_metric_diff', 'trn_val_metric_diff_rate', 'message', 'log_val_mae']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_pred.to_pickle('oof_fc_train', compression='gzip')\n",
    "df_test_pred.to_pickle('oof_fc_test', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx=0.26\n",
    "# # df_test_pred = df_trial.loc[idx]['df_test_pred']\n",
    "# df_submit = pd.DataFrame()\n",
    "# df_submit['scalar_coupling_constant'] = np.mean(df_test_pred.drop(columns=['index']).values, axis=1)\n",
    "# df_submit['id'] = df_test_pred['index']\n",
    "# df_submit.to_csv('../../data/submission/submission_lgbm_{}.csv'.format(idx), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2762095859176849\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>message</th>\n",
       "      <th>nfeatures</th>\n",
       "      <th>train_metric_mean</th>\n",
       "      <th>val_metric_mean</th>\n",
       "      <th>trn_val_metric_diff</th>\n",
       "      <th>trn_val_metric_diff_rate</th>\n",
       "      <th>message</th>\n",
       "      <th>log_val_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-21 23:29:24.455487</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.330755</td>\n",
       "      <td>0.607331</td>\n",
       "      <td>0.276576</td>\n",
       "      <td>0.836197</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>-0.498681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-21 23:34:08.670000</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>56</td>\n",
       "      <td>0.059156</td>\n",
       "      <td>0.128804</td>\n",
       "      <td>0.069648</td>\n",
       "      <td>1.177351</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>-2.049465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-21 23:34:48.456152</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.090381</td>\n",
       "      <td>0.303577</td>\n",
       "      <td>0.213197</td>\n",
       "      <td>2.358870</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>-1.192119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-21 23:36:35.320959</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>46</td>\n",
       "      <td>0.047605</td>\n",
       "      <td>0.147608</td>\n",
       "      <td>0.100003</td>\n",
       "      <td>2.100688</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>-1.913197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-21 23:54:11.117995</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>70</td>\n",
       "      <td>0.156557</td>\n",
       "      <td>0.246093</td>\n",
       "      <td>0.089536</td>\n",
       "      <td>0.571904</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>-1.402047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-08-22 00:02:07.567450</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>55</td>\n",
       "      <td>0.075828</td>\n",
       "      <td>0.144828</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.909958</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>-1.932209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-22 00:22:32.144051</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>57</td>\n",
       "      <td>0.178458</td>\n",
       "      <td>0.259814</td>\n",
       "      <td>0.081356</td>\n",
       "      <td>0.455885</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>-1.347790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-22 00:24:53.931302</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>38</td>\n",
       "      <td>0.036759</td>\n",
       "      <td>0.106056</td>\n",
       "      <td>0.069297</td>\n",
       "      <td>1.885185</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>-2.243784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime         message  nfeatures  train_metric_mean  \\\n",
       "0 2019-08-21 23:29:24.455487  modeling for 0         71           0.330755   \n",
       "1 2019-08-21 23:34:08.670000  modeling for 3         56           0.059156   \n",
       "2 2019-08-21 23:34:48.456152  modeling for 1         36           0.090381   \n",
       "3 2019-08-21 23:36:35.320959  modeling for 4         46           0.047605   \n",
       "4 2019-08-21 23:54:11.117995  modeling for 2         70           0.156557   \n",
       "5 2019-08-22 00:02:07.567450  modeling for 6         55           0.075828   \n",
       "6 2019-08-22 00:22:32.144051  modeling for 5         57           0.178458   \n",
       "7 2019-08-22 00:24:53.931302  modeling for 7         38           0.036759   \n",
       "\n",
       "   val_metric_mean  trn_val_metric_diff  trn_val_metric_diff_rate  \\\n",
       "0         0.607331             0.276576                  0.836197   \n",
       "1         0.128804             0.069648                  1.177351   \n",
       "2         0.303577             0.213197                  2.358870   \n",
       "3         0.147608             0.100003                  2.100688   \n",
       "4         0.246093             0.089536                  0.571904   \n",
       "5         0.144828             0.069000                  0.909958   \n",
       "6         0.259814             0.081356                  0.455885   \n",
       "7         0.106056             0.069297                  1.885185   \n",
       "\n",
       "          message  log_val_mae  \n",
       "0  modeling for 0    -0.498681  \n",
       "1  modeling for 3    -2.049465  \n",
       "2  modeling for 1    -1.192119  \n",
       "3  modeling for 4    -1.913197  \n",
       "4  modeling for 2    -1.402047  \n",
       "5  modeling for 6    -1.932209  \n",
       "6  modeling for 5    -1.347790  \n",
       "7  modeling for 7    -2.243784  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trial = pd.DataFrame(mytrial)\n",
    "df_trial['trn_val_metric_diff_rate'] = df_trial['trn_val_metric_diff'] / df_trial['train_metric_mean']\n",
    "df_trial['log_val_mae'] = df_trial['val_metric_mean'].apply(lambda x : np.log(x))\n",
    "print(mean_absolute_error(df_valid_pred.sort_values(by=['index']).reset_index(drop=True).predict.values, df_train.reset_index(drop=True).y.values))\n",
    "df_trial[['datetime', 'message', 'nfeatures', 'train_metric_mean', 'val_metric_mean', 'trn_val_metric_diff', 'trn_val_metric_diff_rate', 'message', 'log_val_mae']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oof_dso_train',\n",
       " 'oof_sd_test',\n",
       " 'oof_fc_test',\n",
       " 'oof_pso_test',\n",
       " 'oof_fc_train',\n",
       " 'oof_pso_train',\n",
       " 'oof_scalar_coupling_constant_test',\n",
       " 'oof_scalar_coupling_constant_train',\n",
       " 'oof_sd_train',\n",
       " 'oof_dso_test']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f for f in os.listdir('./') if f.startswith('oof')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "for f in [f for f in os.listdir('./') if f.startswith('oof')][:]:\n",
    "    \n",
    "    if 'train' in f:\n",
    "        df_i = pd.read_pickle(f, compression='gzip')\n",
    "        df_train[f'{f}'.replace('_train', '')] = df_i.predict\n",
    "        if 'index' not in df_train.columns:\n",
    "            df_train['index'] = df_i['index']\n",
    "        \n",
    "    if 'test' in f:\n",
    "        df_i = pd.read_pickle(f, compression='gzip')\n",
    "        df_test[f'{f}'.replace('_test', '')] = df_i.drop(columns=['index']).mean(axis=1)\n",
    "        if 'index' not in df_test.columns:\n",
    "            df_test['index'] = df_i['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['oof_dso', 'index', 'oof_fc', 'oof_pso', 'oof_scalar_coupling_constant',\n",
       "        'oof_sd'],\n",
       "       dtype='object'), (4658147, 6))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns, df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['oof_sd', 'index', 'oof_fc', 'oof_pso', 'oof_scalar_coupling_constant',\n",
       "        'oof_dso'],\n",
       "       dtype='object'), (2505542, 6))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
