{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "   div#notebook-container    { width: 95%; }\n",
       "   div#menubar-container     { width: 65%; }\n",
       "   div#maintoolbar-container { width: 99%; }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "   div#notebook-container    { width: 95%; }\n",
    "   div#menubar-container     { width: 65%; }\n",
    "   div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\") # Adds higher directory to python modules path.\n",
    "from utilities import aggregate_feature_calculators\n",
    "from utilities import aggregate_feature_calculators_setting as aggcal\n",
    "from utilities.parallel import Parallel\n",
    "from utilities.dfdb import DFDB\n",
    "\n",
    "from utilities.process.pqueue import *\n",
    "from utilities.process.pnode import *\n",
    "from utilities.process.putilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import copy\n",
    "import gc\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "import optuna\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold,TimeSeriesSplit, GroupKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv',\n",
       " 'magnetic_shielding_tensors.csv',\n",
       " 'potential_energy.csv',\n",
       " 'scalar_coupling_contributions.csv',\n",
       " 'dipole_moments.csv',\n",
       " 'mulliken_charges.csv',\n",
       " 'train.csv',\n",
       " 'test.csv',\n",
       " 'structures.csv',\n",
       " 'structures']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_folder =  '../../data/input'\n",
    "os.listdir(csv_file_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pytorch_geometric_test.pkl',\n",
       " 'cis-trans-isomerism-feature_test.pkl',\n",
       " 'pytorch_geometric_train.pkl',\n",
       " 'laplaction_matrix_train.pkl',\n",
       " 'feature-engineering-physical-chemical-measurement_test.pkl',\n",
       " 'laplaction_matrix_test.pkl',\n",
       " 'cis-trans-isomerism-feature_train.pkl',\n",
       " 'feature-engineering-physical-chemical-measurement_train.pkl',\n",
       " 'stanislav-blinov_train.pkl',\n",
       " 'stanislav-blinov_test.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_folder =  '../../data/feature'\n",
    "[f for f in os.listdir(file_folder) if (f.endswith('.pkl')) and (not f.startswith('.'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "file_list = ['pytorch_geometric_test.pkl',\n",
    " 'cis-trans-isomerism-feature_test.pkl',\n",
    " 'pytorch_geometric_train.pkl',\n",
    " 'laplaction_matrix_train.pkl',\n",
    " 'feature-engineering-physical-chemical-measurement_test.pkl',\n",
    " 'laplaction_matrix_test.pkl',\n",
    " 'cis-trans-isomerism-feature_train.pkl',\n",
    " 'feature-engineering-physical-chemical-measurement_train.pkl',\n",
    " 'stanislav-blinov_train.pkl',\n",
    " 'stanislav-blinov_test.pkl']\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail = []\n",
    "def prepare_data(feature_folder='../../data/feature', csv_file_folder='../../data/input', feature_file_list=None, trail=trail):\n",
    "    \n",
    "    df_train=pd.read_pickle(f'{file_folder}/df_train.gzde', compression='gzip').rename(columns={'index': 'id'})\n",
    "    df_test=pd.read_pickle(f'{file_folder}/df_test.gzde', compression='gzip').rename(columns={'index': 'id'})\n",
    "    \n",
    "#     if os.path.exists(f'{feature_folder}/df_train'):\n",
    "#         print(f'=========================load from temp===============================')\n",
    "#         df_train = pd.read_pickle(f'{feature_folder}/df_train')\n",
    "#         df_test = pd.read_pickle(f'{feature_folder}/df_test')\n",
    "#         return df_train, df_test\n",
    "    \n",
    "#     df_train = pd.read_csv(f\"{csv_file_folder}/train.csv\")\n",
    "#     df_test = pd.read_csv(f\"{csv_file_folder}/test.csv\")\n",
    "#     scalar_coupling_contributions = pd.read_csv(f'{csv_file_folder}/scalar_coupling_contributions.csv')\n",
    "    \n",
    "#     #scalar_coupling_constant fc sd pso dso\n",
    "#     df_train = pd.merge(df_train, scalar_coupling_contributions, how = 'left',\n",
    "#                   left_on  = ['molecule_name', 'atom_index_0', 'atom_index_1', 'type'],\n",
    "#                   right_on = ['molecule_name', 'atom_index_0', 'atom_index_1', 'type'])\n",
    "    \n",
    "    print(df_train.shape, df_test.shape)\n",
    "\n",
    "    if type(feature_file_list) == type(None):\n",
    "        feature_file_list = os.listdir(feature_folder)\n",
    "\n",
    "    for f in feature_file_list:\n",
    "        print(f'========================={f}===============================')\n",
    "        if (f.endswith('.pkl')) and (not f.startswith('.')):\n",
    "            if f[:-4].endswith('train'):\n",
    "                df_feature_i = pd.read_pickle(f'{feature_folder}/{f}').sort_values(by=['id'])\n",
    "                df_feature_i = df_feature_i.reset_index(drop=True)\n",
    "                columns_i = df_feature_i.columns.tolist()\n",
    "                new_columns = set(columns_i) - set(df_train.columns.tolist())\n",
    "                duplicates_columns = [col for col in columns_i if col not in list(new_columns)]\n",
    "                for col in duplicates_columns:\n",
    "                    try:\n",
    "                        error = np.where(df_feature_i[col].values!=df_train[col].values)[0]\n",
    "                        if error.shape[0] > 0:\n",
    "                            if np.where(~np.isnan(df_feature_i[col].values[np.where(df_feature_i[col].values!=df_train[col].values)[0]]))[0].shape[0]>0:\n",
    "                                if not str in [type(df_train[col].values[0]),type(df_feature_i[col].values[0])]:\n",
    "                                    trail.append({'df_feature_i':df_feature_i, 'df_train':df_train})\n",
    "                                    print(col, error, [f'{v1}:{v2}' for v1, v2 in zip(df_feature_i[col].values[error], df_train[col].values[error])])\n",
    "                                    raise Exception()\n",
    "                    except Exception as e:\n",
    "#                         raise Exception(col)\n",
    "                        print(col)\n",
    "                df_train = pd.merge(df_train, df_feature_i[list(new_columns) + ['id']], on='id')\n",
    "                df_train = df_train.sort_values(by=['id'])\n",
    "                df_train = df_train.reset_index(drop=True)\n",
    "                print('train add', f, new_columns)\n",
    "            if f[:-4].endswith('test'):\n",
    "                df_feature_i = pd.read_pickle(f'{feature_folder}/{f}').sort_values(by=['id'])\n",
    "                df_feature_i = df_feature_i.reset_index(drop=True)\n",
    "                columns_i = df_feature_i.columns.tolist()\n",
    "                new_columns = set(columns_i) - set(df_test.columns.tolist())\n",
    "                duplicates_columns = [col for col in columns_i if col not in list(new_columns)]\n",
    "                for col in duplicates_columns:\n",
    "                    try:\n",
    "                        error = np.where(df_feature_i[col].values!=df_test[col].values)[0]\n",
    "                        if error.shape[0] > 0:\n",
    "                            if np.where(~np.isnan(df_feature_i[col].values[np.where(df_feature_i[col].values!=df_test[col].values)[0]]))[0].shape[0]>0:\n",
    "                                if not str in [type(df_test[col].values[0]),type(df_feature_i[col].values[0])]:\n",
    "                                    trail.append({'df_feature_i':df_feature_i, 'df_test':df_test})\n",
    "                                    print(col, error, [f'{v1}:{v2}' for v1, v2 in zip(df_feature_i[col].values[error], df_test[col].values[error])])\n",
    "                                    raise Exception()\n",
    "                    except Exception as e:\n",
    "#                         raise Exception(col)\n",
    "                        print(col)\n",
    "                df_test = pd.merge(df_test, df_feature_i[list(new_columns) + ['id']], on='id')\n",
    "                df_test = df_test.sort_values(by=['id'])\n",
    "                df_test = df_test.reset_index(drop=True)\n",
    "                print('test add', f, new_columns)\n",
    "\n",
    "    print(f'=========================encode label===============================')\n",
    "    numerics = ['int16', 'int8', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    for col in df_train.columns:\n",
    "        col_type = df_train[col].dtypes\n",
    "        if not col_type in numerics:\n",
    "            print(col, df_train[col].unique())\n",
    "            le = LabelEncoder()\n",
    "            le.fit(list(df_train[col].values) + list(df_test[col].values))\n",
    "            df_train[col] = le.transform(list(df_train[col].values))\n",
    "            df_test[col] = le.transform(list(df_test[col].values))\n",
    "            print(le.classes_)\n",
    "\n",
    "    print(f'=========================fill nan inf===============================')\n",
    "    df_train = df_train.replace([np.inf, -np.inf], np.nan)\n",
    "    df_train = df_train.fillna(0)\n",
    "    df_test = df_test.replace([np.inf, -np.inf], np.nan)\n",
    "    df_test = df_test.fillna(0)\n",
    "\n",
    "    print(f'=========================rename===============================')\n",
    "    df_train = df_train.rename(columns={'id': 'index'}) #'scalar_coupling_constant': 'y'\n",
    "    df_test = df_test.rename(columns={'id': 'index'})\n",
    "#     df_train = df_train.rename(columns={'molecule_name':'group'})\n",
    "#     df_test = df_test.rename(columns={'molecule_name':'group'})\n",
    "#     df_test = df_test.rename(columns={'cycle_size_mean_x':'atom_index_0_cycle_size_mean', \n",
    "#                             'cycle_size_mean_y':'atom_index_1_cycle_size_mean',\n",
    "#                            'n_cycle_x':'atom_index_0_n_cycle',\n",
    "#                            'n_cycle_y':'atom_index_1_n_cycle'})\n",
    "\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "    \n",
    "    if not os.path.exists(f'{feature_folder}/df_train'):\n",
    "        print(f'=========================save tmp===============================')\n",
    "        df_train.to_pickle(f'{file_folder}/df_train2.gzde', compression='gzip')\n",
    "        df_test.to_pickle(f'{file_folder}/df_test2.gzde', compression='gzip')\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4658147, 417) (2505542, 412)\n",
      "=========================pytorch_geometric_test.pkl===============================\n",
      "test add pytorch_geometric_test.pkl {'edge_3', 'edge_0', 'atom_index_0_node_pca', 'atom_index_1_node_pca', 'edge_5', 'edge_2', 'edge_4', 'edge_1'}\n",
      "=========================cis-trans-isomerism-feature_test.pkl===============================\n",
      "test add cis-trans-isomerism-feature_test.pkl {'is_cis', 'dihedral', 'is_trans'}\n",
      "=========================pytorch_geometric_train.pkl===============================\n",
      "train add pytorch_geometric_train.pkl {'edge_3', 'edge_0', 'atom_index_0_node_pca', 'atom_index_1_node_pca', 'edge_5', 'edge_2', 'edge_4', 'edge_1'}\n",
      "=========================laplaction_matrix_train.pkl===============================\n",
      "train add laplaction_matrix_train.pkl {'atom_index_1_p_lap_factors', 'atom_index_0_t_dist_core', 'atom_index_0_p_lap_factors', 'atom_index_0_p_lap_core', 'atom_index_0_p_dist_factors', 'atom_index_1_t_dist_core', 'atom_index_1_t_lap_factors_0', 'atom_index_1_p_dist_factors', 'atom_index_0_t_lap_factors_0', 'atom_index_1_p_lap_core', 'atom_index_0_t_dist_factors_0', 'atom_index_0_t_dist_factors_1', 'atom_index_1_t_dist_factors_1', 'atom_index_0_t_lap_core', 'atom_index_1_p_dist_core', 'atom_index_1_t_lap_factors_1', 'atom_index_1_t_lap_core', 'atom_index_0_p_dist_core', 'atom_index_0_t_lap_factors_1', 'atom_index_1_t_dist_factors_0'}\n",
      "=========================feature-engineering-physical-chemical-measurement_test.pkl===============================\n",
      "type\n",
      "test add feature-engineering-physical-chemical-measurement_test.pkl {'ebulution_min_x', 'volume_y', 'rayon_am_y', 'volume_x', 'masse_y', 'enthalpie_vaporisation_y', 'rayon_ac_y', 'bonds_distc_y', 'n_bonds_y', 'molecule_name', 'isotopes_y', 'y_bar_x', 'electronegativity_y', 'rad_y', 'bonds_distc_x', 'etat_x', 'cosdihedral_x', 'enthalpie_vaporisation_x', 'rayon_i_y', 'capacite_thermique_y', 'masse_x', 'charge_x', 'x_bar_x', 'rad_x', 'EN_x', 'cosdihedral_y', 'z_bar_x', 'enthalpie_fusion_x', 'conductivite_thermique_x', 'charge_y', 'dihedral_x', 'conductivite_thermique_y', 'EN_y', 'rayon_vdw_x', 'isotopes_emeteurs_x', 'rayon_am_x', 'electronegativity_x', 'fusion_x', 'dihedral_y', 'etat_y', 'rayon_ac_x', 'rayon_c_y', 'capacite_thermique_x', 'rayon_vdw_y', 'bond_lengths_mean_y', 'rayon_c_x', 'n_bonds_x', 'fusion_y', 'enthalpie_fusion_y', 'rayon_i_x', 'ebulution_min_y', 'isotopes_x', 'isotopes_emeteurs_y', 'bond_lengths_mean_x'}\n",
      "=========================laplaction_matrix_test.pkl===============================\n",
      "test add laplaction_matrix_test.pkl {'atom_index_1_p_lap_factors', 'atom_index_0_t_dist_core', 'atom_index_0_p_lap_factors', 'atom_index_0_p_lap_core', 'atom_index_0_p_dist_factors', 'atom_index_1_t_dist_core', 'atom_index_1_t_lap_factors_0', 'atom_index_1_p_dist_factors', 'atom_index_0_t_lap_factors_0', 'atom_index_1_p_lap_core', 'atom_index_0_t_dist_factors_0', 'atom_index_0_t_dist_factors_1', 'atom_index_1_t_dist_factors_1', 'atom_index_0_t_lap_core', 'atom_index_1_p_dist_core', 'atom_index_1_t_lap_factors_1', 'atom_index_1_t_lap_core', 'atom_index_0_p_dist_core', 'atom_index_0_t_lap_factors_1', 'atom_index_1_t_dist_factors_0'}\n",
      "=========================cis-trans-isomerism-feature_train.pkl===============================\n",
      "train add cis-trans-isomerism-feature_train.pkl {'is_cis', 'dihedral', 'is_trans'}\n",
      "=========================feature-engineering-physical-chemical-measurement_train.pkl===============================\n",
      "type\n",
      "scalar_coupling_constant [      0       1       2 ... 4658144 4658145 4658146] "
     ]
    }
   ],
   "source": [
    "df_train, df_test = prepare_data(feature_file_list=file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4658147, 536)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2505542, 531)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_gpu_p36)",
   "language": "python",
   "name": "conda_tensorflow_gpu_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
