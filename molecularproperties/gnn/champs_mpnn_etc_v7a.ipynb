{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "   div#notebook-container    { width: 95%; }\n",
       "   div#menubar-container     { width: 65%; }\n",
       "   div#maintoolbar-container { width: 99%; }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "   div#notebook-container    { width: 95%; }\n",
    "   div#menubar-container     { width: 65%; }\n",
    "   div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "PROJECT_PATH = os.path.dirname(os.path.realpath('__file__').replace('/lib',''))\n",
    "IDENTIFIER   = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "import pickle \n",
    "\n",
    "#numerical libs\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import PIL\n",
    "import cv2\n",
    "import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "#matplotlib.use('WXAgg')\n",
    "#matplotlib.use('Qt4Agg')\n",
    "#matplotlib.use('Qt5Agg') #Qt4Agg\n",
    "# print('matplotlib.get_backend : ', matplotlib.get_backend())\n",
    "#print(matplotlib.__version__)\n",
    "\n",
    "\n",
    "# torch libs\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import *\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.parallel.data_parallel import data_parallel\n",
    "\n",
    "from torch.nn.utils.rnn import *\n",
    "\n",
    "\n",
    "# std libs\n",
    "import collections\n",
    "import copy\n",
    "import numbers\n",
    "import inspect\n",
    "import shutil\n",
    "from timeit import default_timer as timer\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp\n",
    "\n",
    "#from pprintpp import pprint, pformat\n",
    "import json\n",
    "import zipfile\n",
    "\n",
    "\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import glob\n",
    "import sys\n",
    "from distutils.dir_util import copy_tree\n",
    "import time\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from dscribe.descriptors import ACSF\n",
    "from dscribe.core.system import System\n",
    "\n",
    "import torch_geometric.nn as gnn\n",
    "\n",
    "import networkx as nx\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import ChemicalFeatures\n",
    "from rdkit import RDConfig\n",
    "\n",
    "import rdkit.Chem.Draw\n",
    "from rdkit.Chem.Draw.MolDrawing import MolDrawing, DrawingOptions\n",
    "DrawingOptions.bondLineWidth=1.8\n",
    "\n",
    "from rdkit.Chem.rdmolops import SanitizeFlags\n",
    "\n",
    "# constant #\n",
    "PI  = np.pi\n",
    "INF = np.inf\n",
    "EPS = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv',\n",
       " 'magnetic_shielding_tensors.csv',\n",
       " 'potential_energy.csv',\n",
       " 'scalar_coupling_contributions.csv',\n",
       " 'dipole_moments.csv',\n",
       " 'mulliken_charges.csv',\n",
       " 'train.csv',\n",
       " 'test.csv',\n",
       " 'structures.csv',\n",
       " 'structures']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_folder = '../../data/input'\n",
    "os.listdir(file_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{file_folder}/train.csv')\n",
    "train_molecule_names = train.molecule_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f'{file_folder}/test.csv')\n",
    "test_molecule_names = test.molecule_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dir='../../data/temp/pytorch_geometric2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYMBOL=['H', 'C', 'N', 'O', 'F']\n",
    "\n",
    "ACSF_GENERATOR = ACSF(\n",
    "    species=SYMBOL,\n",
    "    rcut=6.0,\n",
    "    g2_params=[[1, 1], [1, 2], [1, 3]],\n",
    "    g4_params=[[1, 1, 1], [1, 2, 1], [1, 1, -1], [1, 2, -1]],\n",
    ")\n",
    "\n",
    "COUPLING_TYPE_STATS=[\n",
    "    #type   #mean, std, min, max\n",
    "    '1JHC',  94.9761528641869,   18.27722399839607,   66.6008,   204.8800,\n",
    "    '2JHC',  -0.2706244378832,    4.52360876732858,  -36.2186,    42.8192,\n",
    "    '3JHC',   3.6884695895355,    3.07090647005439,  -18.5821,    76.0437,\n",
    "    '1JHN',  47.4798844844683,   10.92204561670947,   24.3222,    80.4187,\n",
    "    '2JHN',   3.1247536134185,    3.67345877025737,   -2.6209,    17.7436,\n",
    "    '3JHN',   0.9907298624944,    1.31538940138001,   -3.1724,    10.9712,\n",
    "    '2JHH', -10.2866051639817,    3.97960190019757,  -35.1761,    11.8542,\n",
    "    '3JHH',   4.7710233597359,    3.70498129755812,   -3.0205,    17.4841,\n",
    "]\n",
    "NUM_COUPLING_TYPE = len(COUPLING_TYPE_STATS)//5\n",
    "\n",
    "COUPLING_TYPE_MEAN = [ COUPLING_TYPE_STATS[i*5+1] for i in range(NUM_COUPLING_TYPE)]\n",
    "COUPLING_TYPE_STD  = [ COUPLING_TYPE_STATS[i*5+2] for i in range(NUM_COUPLING_TYPE)]\n",
    "COUPLING_TYPE      = [ COUPLING_TYPE_STATS[i*5  ] for i in range(NUM_COUPLING_TYPE)]\n",
    "\n",
    "\n",
    "#---\n",
    "\n",
    "SYMBOL=['H', 'C', 'N', 'O', 'F']\n",
    "\n",
    "BOND_TYPE = [\n",
    "    Chem.rdchem.BondType.SINGLE,\n",
    "    Chem.rdchem.BondType.DOUBLE,\n",
    "    Chem.rdchem.BondType.TRIPLE,\n",
    "    Chem.rdchem.BondType.AROMATIC,\n",
    "]\n",
    "HYBRIDIZATION=[\n",
    "    #Chem.rdchem.HybridizationType.S,\n",
    "    Chem.rdchem.HybridizationType.SP,\n",
    "    Chem.rdchem.HybridizationType.SP2,\n",
    "    Chem.rdchem.HybridizationType.SP3,\n",
    "    #Chem.rdchem.HybridizationType.SP3D,\n",
    "    #Chem.rdchem.HybridizationType.SP3D2,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_str(t, mode='min'):\n",
    "    if mode=='min':\n",
    "        t  = int(t)/60\n",
    "        hr = t//60\n",
    "        min = t%60\n",
    "        return '%2d hr %02d min'%(hr,min)\n",
    "\n",
    "    elif mode=='sec':\n",
    "        t   = int(t)\n",
    "        min = t//60\n",
    "        sec = t%60\n",
    "        return '%2d min %02d sec'%(min,sec)\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "def read_pickle_from_file(pickle_file):\n",
    "    with open(pickle_file,'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "    return x\n",
    "\n",
    "def write_pickle_to_file(pickle_file, x):\n",
    "    with open(pickle_file, 'wb') as f:\n",
    "        pickle.dump(x, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# http://stackoverflow.com/questions/34950201/pycharm-print-end-r-statement-not-working\n",
    "class Logger(object):\n",
    "    def __init__(self):\n",
    "        self.terminal = sys.stdout  #stdout\n",
    "        self.file = None\n",
    "\n",
    "    def open(self, file, mode=None):\n",
    "        if mode is None: mode ='w'\n",
    "        self.file = open(file, mode)\n",
    "\n",
    "    def write(self, message, is_terminal=1, is_file=1 ):\n",
    "        if '\\r' in message: is_file=0\n",
    "\n",
    "        if is_terminal == 1:\n",
    "            self.terminal.write(message)\n",
    "            self.terminal.flush()\n",
    "            #time.sleep(1)\n",
    "\n",
    "        if is_file == 1:\n",
    "            self.file.write(message)\n",
    "            self.file.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        # this flush method is needed for python 3 compatibility.\n",
    "        # this handles the flush command by doing nothing.\n",
    "        # you might want to specify some extra behavior here.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChampsDataset(Dataset):\n",
    "    def __init__(self, molecule_names, graph_file_path):\n",
    "\n",
    "        self.id   = molecule_names\n",
    "        self.graph_file_path = graph_file_path\n",
    "        return\n",
    "\n",
    "        #zz=0\n",
    "        #self.dummy_graph = read_pickle_from_file(DATA_DIR + '/structure/graph/dsgdb9nsd_000001.pickle')\n",
    "\n",
    "    def __str__(self):\n",
    "            return 'str'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        molecule_name = self.id[index]\n",
    "        graph_file = self.graph_file_path + '/%s.pickle'%molecule_name\n",
    "        graph = read_pickle_from_file(graph_file)\n",
    "        assert(graph.molecule_name==molecule_name)\n",
    "\n",
    "        ##filter only J link\n",
    "        if 0:\n",
    "            # 1JHC,     2JHC,     3JHC,     1JHN,     2JHN,     3JHN,     2JHH,     3JHH\n",
    "            mask = np.zeros(len(graph.coupling.type),np.bool)\n",
    "            for t in ['1JHC',     '2JHH']:\n",
    "                mask += (graph.coupling.type == COUPLING_TYPE.index(t))\n",
    "\n",
    "            graph.coupling.id = graph.coupling.id [mask]\n",
    "            graph.coupling.contribution = graph.coupling.contribution [mask]\n",
    "            graph.coupling.index = graph.coupling.index [mask]\n",
    "            graph.coupling.type = graph.coupling.type [mask]\n",
    "            graph.coupling.value = graph.coupling.value [mask]\n",
    "\n",
    "        if 1:\n",
    "            atom = System(symbols =graph.axyz[0], positions=graph.axyz[1])\n",
    "            acsf = ACSF_GENERATOR.create(atom)\n",
    "            graph.node += [acsf, graph.axyz[1]]\n",
    "\n",
    "\n",
    "        # if 1:\n",
    "        #     graph.edge = graph.edge[:-1]\n",
    "\n",
    "        graph.node = np.concatenate(graph.node,-1)\n",
    "        graph.edge = np.concatenate(graph.edge,-1)\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net ------------------------------------\n",
    "# https://github.com/pytorch/examples/blob/master/imagenet/main.py ###############\n",
    "def adjust_learning_rate(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def get_learning_rate(optimizer):\n",
    "    lr=[]\n",
    "    for param_group in optimizer.param_groups:\n",
    "       lr +=[ param_group['lr'] ]\n",
    "\n",
    "    assert(len(lr)==1) #we support only one param_group\n",
    "    lr = lr[0]\n",
    "\n",
    "    return lr\n",
    "\n",
    "def null_collate(batch):\n",
    "\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    node = []\n",
    "    edge = []\n",
    "    edge_index  = []\n",
    "    node_batch_index = []\n",
    "\n",
    "    coupling_index = []\n",
    "    coupling_type  = []\n",
    "    coupling_value = []\n",
    "    coupling_batch_index = []\n",
    "    infor = []\n",
    "\n",
    "    offset = 0\n",
    "    for b in range(batch_size):\n",
    "        graph = batch[b]\n",
    "        #print(graph.molecule_name)\n",
    "\n",
    "        num_node = len(graph.node)\n",
    "        node.append(graph.node)\n",
    "        edge.append(graph.edge)\n",
    "        edge_index.append(graph.edge_index+offset)\n",
    "        node_batch_index.append([b]*num_node)\n",
    "\n",
    "        num_coupling = len(graph.coupling.value)\n",
    "        coupling_index.append(graph.coupling.index+offset)\n",
    "        coupling_type.append (graph.coupling.type)\n",
    "        coupling_value.append(graph.coupling.value)\n",
    "        coupling_batch_index.append([b]*num_coupling)\n",
    "\n",
    "        infor.append((graph.molecule_name, graph.smiles, graph.coupling.id))\n",
    "        offset += num_node\n",
    "\n",
    "\n",
    "    node = torch.from_numpy(np.concatenate(node)).float()\n",
    "    edge = torch.from_numpy(np.concatenate(edge)).float()\n",
    "    edge_index  = torch.from_numpy(np.concatenate(edge_index).astype(np.int32)).long()\n",
    "    node_batch_index = torch.from_numpy(np.concatenate(node_batch_index)).long()\n",
    "\n",
    "\n",
    "    coupling_index = torch.from_numpy(np.concatenate(coupling_index)).long()\n",
    "    coupling_type  = torch.from_numpy(np.concatenate(coupling_type )).long()\n",
    "    coupling_value = torch.from_numpy(np.concatenate(coupling_value)).float()\n",
    "    coupling_batch_index = torch.from_numpy(np.concatenate(coupling_batch_index)).long()\n",
    "    return node,edge,edge_index, node_batch_index, \\\n",
    "           coupling_index,coupling_type,coupling_value,coupling_batch_index, infor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NullScheduler():\n",
    "    def __init__(self, lr=0.01 ):\n",
    "        super(NullScheduler, self).__init__()\n",
    "        self.lr    = lr\n",
    "        self.cycle = 0\n",
    "\n",
    "    def __call__(self, time):\n",
    "        return self.lr\n",
    "\n",
    "    def __str__(self):\n",
    "        string = 'NullScheduler\\n' \\\n",
    "                + 'lr=%0.5f '%(self.lr)\n",
    "        return string\n",
    "\n",
    "class LinearBn(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, act=None):\n",
    "        super(LinearBn, self).__init__()\n",
    "        self.linear = nn.Linear(in_channel, out_channel, bias=False)\n",
    "        self.bn   = nn.BatchNorm1d(out_channel,eps=1e-05, momentum=0.1)\n",
    "        self.act  = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.act is not None:\n",
    "            x = self.act(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "#message passing\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, node_dim=96, edge_dim=16, num_target=8):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.num_message_passing = 6\n",
    "        node_hidden_dim=128\n",
    "        edge_hidden_dim=128\n",
    "\n",
    "        self.preprocess = nn.Sequential(\n",
    "            LinearBn(node_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            LinearBn(256, node_hidden_dim),\n",
    "        )\n",
    "        edge_net = nn.Sequential(\n",
    "            LinearBn(edge_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            LinearBn(32, 64),\n",
    "            nn.ReLU(),\n",
    "            LinearBn(64, edge_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            LinearBn(edge_hidden_dim, node_hidden_dim * node_hidden_dim) # edge_hidden_dim,  node_hidden_dim *node_hidden_dim\n",
    "        )\n",
    "\n",
    "        self.conv = gnn.NNConv(node_hidden_dim, node_hidden_dim, edge_net, aggr='mean', root_weight=True) #node_hidden_dim, node_hidden_dim\n",
    "        self.gru  = nn.GRU(node_hidden_dim, node_hidden_dim)\n",
    "        self.set2set = gnn.Set2Set(node_hidden_dim, processing_steps=6) # node_hidden_dim\n",
    "\n",
    "        #predict coupling constant\n",
    "        self.predict = nn.Sequential(\n",
    "            LinearBn(4*node_hidden_dim, 512),  #node_hidden_dim\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_target),\n",
    "        )\n",
    "\n",
    "    def forward(self, node, edge, edge_index, node_batch_index, coupling_index, coupling_type, coupling_batch_index):\n",
    "\n",
    "        #----\n",
    "        edge_index = edge_index.t().contiguous()\n",
    "\n",
    "        x = F.relu(self.preprocess(node))\n",
    "        h = x.unsqueeze(0)\n",
    "\n",
    "        for i in range(self.num_message_passing):\n",
    "            m    = F.relu(self.conv(x, edge_index, edge))\n",
    "            x, h = self.gru(m.unsqueeze(0), h)\n",
    "            x = x.squeeze(0)\n",
    "        #x =  num_node, node_hidden_dim\n",
    "\n",
    "        pool = self.set2set(x, node_batch_index) # global pool\n",
    "        pool = torch.index_select(\n",
    "            pool,\n",
    "            dim=0,\n",
    "            index=coupling_batch_index\n",
    "        )\n",
    "        x = torch.index_select(\n",
    "            x,\n",
    "            dim=0,\n",
    "            index=coupling_index.view(-1)\n",
    "        ).reshape(len(coupling_index),-1)\n",
    "\n",
    "        x = torch.cat([pool,x],-1)\n",
    "        predict = self.predict(x)\n",
    "\n",
    "        predict = torch.gather(predict,1,coupling_type.view(-1,1)).view(-1)\n",
    "        return predict\n",
    "\n",
    "\n",
    "# def criterion(predict, coupling_value):\n",
    "#     predict = predict.view(-1)\n",
    "#     coupling_value = coupling_value.view(-1)\n",
    "#     assert(predict.shape==coupling_value.shape)\n",
    "#\n",
    "#     loss = F.mse_loss(predict, coupling_value)\n",
    "#     return loss\n",
    "\n",
    "\n",
    "def criterion(predict, coupling_value):\n",
    "    predict = predict.view(-1)\n",
    "    coupling_value = coupling_value.view(-1)\n",
    "    assert(predict.shape==coupling_value.shape)\n",
    "\n",
    "    loss = torch.abs(predict-coupling_value)\n",
    "    loss = loss.mean()\n",
    "    loss = torch.log(loss)\n",
    "    return loss\n",
    "\n",
    "def compute_kaggle_metric( predict, coupling_value, coupling_type):\n",
    "\n",
    "    mae     = [None]*NUM_COUPLING_TYPE\n",
    "    log_mae = [None]*NUM_COUPLING_TYPE\n",
    "    diff = np.fabs(predict-coupling_value)\n",
    "    for t in range(NUM_COUPLING_TYPE):\n",
    "        index = np.where(coupling_type==t)[0]\n",
    "        if len(index)>0:\n",
    "            m = diff[index].mean()\n",
    "            log_m = np.log(m+1e-8)\n",
    "\n",
    "            mae[t] = m\n",
    "            log_mae[t] = log_m\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return mae, log_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_molecule_names_valid = random.sample(train_molecule_names, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_molecule_names_train = [ m for m in train_molecule_names if m not in  train_molecule_names_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('train_molecule_names_valid.pickle', 'wb') as f:\n",
    "#     pickle.dump(train_molecule_names_valid, f)\n",
    "    \n",
    "# with open('train_molecule_names_train.pickle', 'wb') as f:\n",
    "#     pickle.dump(train_molecule_names_valid, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_molecule_names_valid.pickle', 'rb') as f:\n",
    "    train_molecule_names_valid = pickle.load(f)\n",
    "\n",
    "with open('train_molecule_names_train.pickle', 'rb') as f:\n",
    "    train_molecule_names_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_valid(net, valid_loader):\n",
    "\n",
    "    valid_num = 0\n",
    "    valid_predict = []\n",
    "    valid_coupling_type  = []\n",
    "    valid_coupling_value = []\n",
    "\n",
    "    valid_loss = 0\n",
    "    for b, (node,edge,edge_index,node_batch_index,\n",
    "            coupling_index,coupling_type,coupling_value,coupling_batch_index,\n",
    "            infor) in enumerate(valid_loader):\n",
    "\n",
    "        #if b==5: break\n",
    "        net.eval()\n",
    "        node = node.cuda()\n",
    "        edge = edge.cuda()\n",
    "        edge_index  = edge_index.cuda()\n",
    "        node_batch_index = node_batch_index.cuda()\n",
    "        coupling_index = coupling_index.cuda()\n",
    "        coupling_type  = coupling_type.cuda()\n",
    "        coupling_value = coupling_value.cuda()\n",
    "        coupling_batch_index = coupling_batch_index.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predict = net(node,edge,edge_index,node_batch_index, coupling_index,coupling_type,coupling_batch_index)\n",
    "            loss = criterion(predict, coupling_value)\n",
    "\n",
    "        #---\n",
    "        batch_size = len(infor)\n",
    "        valid_predict.append(predict.data.cpu().numpy())\n",
    "        valid_coupling_type.append(coupling_type.data.cpu().numpy())\n",
    "        valid_coupling_value.append(coupling_value.data.cpu().numpy())\n",
    "\n",
    "        valid_loss += batch_size*loss.item()\n",
    "        valid_num  += batch_size\n",
    "\n",
    "#         print('\\r',end='',flush=True)\n",
    "        print('\\r %8d /%8d'%(valid_num, len(valid_loader.dataset)),end='',flush=True)\n",
    "\n",
    "        pass  #-- end of one data loader --\n",
    "    assert(valid_num == len(valid_loader.dataset))\n",
    "    #print('')\n",
    "    valid_loss = valid_loss/valid_num\n",
    "\n",
    "    #compute\n",
    "    predict = np.concatenate(valid_predict)\n",
    "    coupling_value = np.concatenate(valid_coupling_value)\n",
    "    coupling_type  = np.concatenate(valid_coupling_type).astype(np.int32)\n",
    "    mae, log_mae   = compute_kaggle_metric( predict, coupling_value, coupling_type,)\n",
    "\n",
    "    num_target = NUM_COUPLING_TYPE\n",
    "    for t in range(NUM_COUPLING_TYPE):\n",
    "        if mae[t] is None:\n",
    "            mae[t] = 0\n",
    "            log_mae[t]  = 0\n",
    "            num_target -= 1\n",
    "\n",
    "    mae_mean, log_mae_mean = sum(mae)/num_target, sum(log_mae)/num_target\n",
    "    #list(np.stack([mae, log_mae]).T.reshape(-1))\n",
    "\n",
    "    valid_loss = log_mae + [valid_loss,mae_mean, log_mae_mean, ]\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net loaded\n",
      "optimizer loaded\n",
      "| -1.093  0.32 -1.23 | -1.099 |  5 hr 50 min"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/ubuntu/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-21714cdc2d86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# print statistics  ------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0msum_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0msum_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_folder = '.'\n",
    "net_file = 'net'\n",
    "opt_file = 'optimizer'\n",
    "batch_size= 16\n",
    "EDGE_DIM   =  6\n",
    "NODE_DIM   = 96 ##  93  13\n",
    "NUM_TARGET =  8\n",
    "\n",
    "train_dataset = ChampsDataset(train_molecule_names_train, graph_dir)\n",
    "\n",
    "train_loader  = DataLoader(\n",
    "                train_dataset,\n",
    "                sampler     = RandomSampler(train_dataset),\n",
    "                batch_size  = batch_size,\n",
    "                drop_last   = True,\n",
    "                num_workers = 16,\n",
    "                pin_memory  = True,\n",
    "                collate_fn  = null_collate\n",
    "    )\n",
    "\n",
    "valid_dataset = ChampsDataset(train_molecule_names_valid, graph_dir)\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            #sampler     = SequentialSampler(valid_dataset),\n",
    "            sampler     = RandomSampler(valid_dataset),\n",
    "            batch_size  = batch_size,\n",
    "            drop_last   = False,\n",
    "            num_workers = 0,\n",
    "            pin_memory  = True,\n",
    "            collate_fn  = null_collate\n",
    ")\n",
    "\n",
    "net = Net(node_dim=NODE_DIM,edge_dim=EDGE_DIM, num_target=NUM_TARGET).cuda()\n",
    "if type(net_file)!=type(None) and os.path.exists(f'{save_folder}/{net_file}'):\n",
    "    net.load_state_dict(torch.load(f'{save_folder}/{net_file}', map_location=lambda storage, loc: storage))\n",
    "    print('net loaded')\n",
    "schduler = NullScheduler(lr=0.001)\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()),lr=schduler(0))\n",
    "if type(opt_file)!=type(None) and os.path.exists(f'{save_folder}/{opt_file}'):\n",
    "    checkpoint  = torch.load(f'{save_folder}/{opt_file}')\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print('optimizer loaded')\n",
    "\n",
    "# schduler = NullScheduler(lr=0.0001)\n",
    "# net = Net(node_dim=NODE_DIM,edge_dim=EDGE_DIM, num_target=NUM_TARGET).cuda()\n",
    "# optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()),lr=schduler(0))\n",
    "\n",
    "\n",
    "iter_accum  = 1\n",
    "num_iters   = 3000  *1000\n",
    "iter_smooth = 50\n",
    "iter_log    = 500\n",
    "iter_valid  = 500\n",
    "iter_save   = [0, num_iters-1]+ list(range(0, num_iters, 2500))#1*1000\n",
    "\n",
    "start_iter = 0\n",
    "start_epoch= 0\n",
    "rate       = 0\n",
    "\n",
    "\n",
    "train_loss   = np.zeros(20,np.float32)\n",
    "valid_loss   = np.zeros(20,np.float32)\n",
    "batch_loss   = np.zeros(20,np.float32)\n",
    "iter_ = 0\n",
    "i    = 0\n",
    "\n",
    "start = timer()\n",
    "while  iter_<num_iters:\n",
    "    sum_train_loss = np.zeros(20,np.float32)\n",
    "    sum_ = 0\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    for node,edge,edge_index,node_batch_index, coupling_index,coupling_type,coupling_value,coupling_batch_index, infor in train_loader:\n",
    "\n",
    "        #while 1:\n",
    "        batch_size = len(infor)\n",
    "        iter_  = i + start_iter\n",
    "        epoch = (iter_-start_iter)*batch_size/len(train_dataset) + start_epoch\n",
    "\n",
    "        #if 0:\n",
    "        if (iter_ % iter_valid==0):\n",
    "            valid_loss = do_valid(net, valid_loader) #\n",
    "            if type(save_folder) != type(None):\n",
    "                torch.save(net.state_dict(),f'{save_folder}/{net_file}')\n",
    "                torch.save({'optimizer': optimizer.state_dict()}, f'{save_folder}/{opt_file}')\n",
    "\n",
    "        # learning rate schduler -------------\n",
    "        lr = schduler(iter)\n",
    "        if lr<0 : break\n",
    "        adjust_learning_rate(optimizer, lr)\n",
    "        rate = get_learning_rate(optimizer)\n",
    "\n",
    "        # one iteration update  -------------\n",
    "        #net.set_mode('train',is_freeze_bn=True)\n",
    "\n",
    "        net.train()\n",
    "        node = node.cuda()\n",
    "        edge = edge.cuda()\n",
    "        edge_index = edge_index.cuda()\n",
    "        node_batch_index = node_batch_index.cuda()\n",
    "        coupling_index = coupling_index.cuda()\n",
    "        coupling_type  = coupling_type.cuda()\n",
    "        coupling_value = coupling_value.cuda()\n",
    "        coupling_batch_index = coupling_batch_index.cuda()\n",
    "\n",
    "        predict = net(node,edge,edge_index,node_batch_index, coupling_index,coupling_type,coupling_batch_index)\n",
    "        loss = criterion(predict, coupling_value)\n",
    "\n",
    "        (loss/iter_accum).backward()\n",
    "        if (iter_ % iter_accum)==0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # print statistics  ------------\n",
    "        batch_loss[:1] = [loss.item()]\n",
    "        sum_train_loss += batch_loss\n",
    "        sum_ += 1\n",
    "        if iter_%iter_smooth == 0:\n",
    "            train_loss = sum_train_loss/sum_\n",
    "            sum_train_loss = np.zeros(20,np.float32)\n",
    "            sum_ = 0\n",
    "\n",
    "        print('\\r',end='',flush=True)\n",
    "        print('| %+5.3f  %0.2f %+0.2f | %+5.3f | %s' % (*valid_loss[8:11], batch_loss[0], time_to_str((timer() - start),'min')) , end='',flush=True)\n",
    "        i=i+1\n",
    "\n",
    "\n",
    "    pass  #-- end of one data loader --\n",
    "pass #-- end of all iterations --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net, test_loader):\n",
    "    df_pred = pd.DataFrame()\n",
    "    N_ = len(test_loader)\n",
    "    for b, (node,edge,edge_index,node_batch_index,\n",
    "            coupling_index,coupling_type,coupling_value,coupling_batch_index,\n",
    "            infor) in enumerate(test_loader):\n",
    "\n",
    "        #if b==5: break\n",
    "        net.eval()\n",
    "        node = node.cuda()\n",
    "        edge = edge.cuda()\n",
    "        edge_index  = edge_index.cuda()\n",
    "        node_batch_index = node_batch_index.cuda()\n",
    "        coupling_index = coupling_index.cuda()\n",
    "        coupling_type  = coupling_type.cuda()\n",
    "        coupling_value = coupling_value.cuda()\n",
    "        coupling_batch_index = coupling_batch_index.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predict = net(node,edge,edge_index,node_batch_index, coupling_index,coupling_type,coupling_batch_index)\n",
    "        \n",
    "#         print(predict.cpu().detach().numpy().shape, infor[0][2].shape)\n",
    "        print(f'{b}/{N_}', end='',flush=True)\n",
    "        print('\\r',end='',flush=True)\n",
    "        df_pred_i = pd.DataFrame({'id':infor[0][2], 'scalar_coupling_constant':predict.cpu().detach().numpy() })\n",
    "        df_pred = pd.concat([df_pred, df_pred_i], axis=0)\n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f'{file_folder}/test.csv')\n",
    "test_molecule_names = test.molecule_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ChampsDataset(test_molecule_names, graph_dir)\n",
    "\n",
    "test_loader  = DataLoader(\n",
    "                test_dataset,\n",
    "                sampler     = RandomSampler(test_dataset),\n",
    "                batch_size  = 1,\n",
    "                drop_last   = True,\n",
    "                num_workers = 16,\n",
    "                pin_memory  = True,\n",
    "                collate_fn  = null_collate\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = predict(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_pred.shape)\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=-0.96\n",
    "# df_test_pred = df_trial.loc[idx]['df_test_pred']\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit['scalar_coupling_constant'] = df_pred['scalar_coupling_constant']#np.mean(df_pred.drop(columns=['id']).values, axis=1)\n",
    "df_submit['id'] = df_pred['id']\n",
    "df_submit.to_csv('../../data/submission/submission_gnn_{}.csv'.format(idx), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_gpu_p36)",
   "language": "python",
   "name": "conda_tensorflow_gpu_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
