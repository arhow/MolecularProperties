{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action=\"ignore\",category=DeprecationWarning)\n",
    "warnings.filterwarnings(action=\"ignore\",category=FutureWarning)\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from keras.layers import Dense, Input, Activation\n",
    "from keras.layers import BatchNormalization,Add,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, load_model\n",
    "from keras import callbacks\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn_model(input_shape):\n",
    "    inp = Input(shape=(input_shape,))\n",
    "    x = Dense(2048, activation=\"relu\")(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    #x = Dropout(0.4)(x)\n",
    "    for i in range(4):\n",
    "        x = Dense(1024, activation=\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    out = Dense(1, activation=\"linear\")(x)  \n",
    "   # out1 = Dense(2, activation=\"linear\")(x)#mulliken charge 2\n",
    "   # out2 = Dense(6, activation=\"linear\")(x)#tensor 6(xx,yy,zz)\n",
    "   # out3 = Dense(12, activation=\"linear\")(x)#tensor 12(others) \n",
    "   # out4 = Dense(1, activation=\"linear\")(x)#scalar_coupling_constant \n",
    "    #model = Model(inputs=inp, outputs=[out,out1,out2,out3,out4])\n",
    "    model = Model(inputs=inp, outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, label):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Loss for %s' % label)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    _= plt.legend(['Train','Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GPU preferences\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 2} ) \n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "sess = tf.Session(config=config) \n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_folder =  '../../data/input'\n",
    "file_folder =  '../../data/feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(f'{csv_file_folder}/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv(f'{csv_file_folder}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_types=train_csv[\"type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1JHC', '2JHH', '1JHN', '2JHN', '2JHC', '3JHH', '3JHC', '3JHN'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_columns = [['tertiary_angle_0', 'inv_dist1R', 'd_4_3', 'yukawa_H.y', 'mulliken_atom_0', 'dist_to_type_mean', 'dist_O_0_x', 'atom_1_n_bonds', 'dist_to_type_1_mean', 'atom_1_bond_lengths_mean', 'dist_xyz', 'dist_C_0_y', 'd_3_2', 'atom_index_1_ hybridization', 'atom_index_1_cycle_size_mean', 'dist_O_0_y', 'eem_1', 'inv_distPE', 'd_4_2', 'inv_distPR', 'dist_no_bond_min_y', 'dist_H_2_x', 'dist_H_1_x', 'tertiary_distance_2', 'dist_C_3_x', 'dist_O_1_x', 'atom_1_bond_lengths_std', 'dist_C_2_y', 'dist_C_2_x', 'mulliken_atom_1', 'cos_center1', 'dist_O_1_y', 'tertiary_angle_3', 'dist_H_2_y', 'dist_N_0_y', 'dist_C_1_y', 'inv_dist1E', 'distance_y', 'tertiary_angle_2', 'dist_N_0_x', 'd_2_1', 'molecule_atom_index_0_dist_max_div', 'adC1', 'adN1', 'd_4_0', 'dist_C_3_y', 'atom_3', 'distC0', 'tertiary_distance_4', 'tertiary_angle_5', 'd_5_1', 'molecule_atom_index_1_dist_min_diff', 'dist_C_4_y', 'dist_H_0_y', 'cos_f0', 'd_5_0', 'tertiary_distance_3', 'd_5_2', 'tertiary_atom_1', 'dist_C_4_x', 'cos_c0_f0', 'atom_index_0_sv_3', 'rc_C', 'cos_f1', 'tertiary_angle_8', 'dist_O_2_y', 'max_molecule_atom_1_dist_xyz', 'dist_F_0_y', 'atom_index_1_ aromatic', 'tertiary_angle_26', 'type_0'],\n",
    "['dist_H_0_y', 'd_3_2', 'dist_C_0_y', 'atom_index_1_ aromatic', 'atom_1_bond_lengths_mean', 'bond_atom', 'inv_dist1R', 'd_3_1', 'mulliken_atom_0', 'dist_H_0_x', 'dist_O_0_y', 'dist_C_1_x', 'tertiary_angle_0', 'dist_C_1_y', 'vander_C.y', 'dist_H_1_y', 'mulliken_atom_1', 'inv_dist0R', 'd_1_0', 'tertiary_distance_0', 'tertiary_angle_2', 'atom_index_1_explicit_valence', 'dist_N_0_y', 'inv_distPR', 'dist_C_2_x', 'vander_H.x', 'd_4_2', 'atom_index_0_eigv_max', 'tertiary_distance_2', 'dist_H_1_x', 'dist_N_1_x', 'dist_C_3_x', 'cos_f0', 'atom_index_1_sv_2', 'max_molecule_atom_0_dist_xyz', 'd_2_1'],\n",
    "['tertiary_atom_0', 'inv_dist0', 'dist_no_bond_min_x', 'atom_index_1_ hybridization', 'tertiary_angle_0', 'tertiary_angle_1', 'dist_O_0_x', 'cos_c0', 'd_5_2', 'tertiary_atom_1', 'cos_f0', 'dist_H_0_x', 'd_3_1', 'atom_index_1_degree', 'dist_C_0_y', 'adC2', 'dist_C_3_x', 'vander_O.y', 'mulliken_atom_1', 'atom_7', 'tertiary_angle_2', 'd_2_1', 'atom_3', 'd_5_1', 'd_6_2', 'd_4_1', 'tertiary_atom_2', 'molecule_atom_index_1_dist_min_diff', 'd_4_2', 'dist_C_2_x', 'cos_c0_f0', 'd_6_0', 'dist_O_0_y', 'd_4_3', 'd_3_0', 'd_7_0', 'd_3_2', 'inv_dist0R', 'atom_8', 'dist_C_1_x', 'd_6_1', 'd_2_0', 'd_8_1', 'mulliken_atom_0', 'dist_N_0_x', 'atom_4', 'tertiary_distance_2', 'd_7_2', 'dist_C_0_x', 'atom_1_bond_lengths_mean', 'dist_C_1_y', 'bond_atom', 'd_7_1', 'd_4_0', 'distC0', 'atom_index_1_cycle_size_mean', 'cos_c0_c1', 'tertiary_angle_3', 'dist_O_1_x', 'atom_index_1_n_cycle', 'max_molecule_atom_0_dist_xyz', 'molecule_atom_index_0_dist_max_div', 'atom_5', 'gap', 'cos_c1', 'dist_N_0_y', 'd_6_3', 'dist_C_3_y', 'inv_distP', 'dist_C_4_y'],\n",
    "['cos_c0', 'd_4_3', 'cos_c0_c1', 'molecule_atom_index_0_dist_min_diff', 'tertiary_atom_1', 'd_3_2', 'd_1_0', 'dist_H_0_y', 'mulliken_atom_0', 'mulliken_atom_1', 'dist_N_0_x', 'link0', 'tertiary_atom_2', 'dist_C_1_y', 'dist_C_1_x', 'cos_f0', 'dist_C_0_y', 'cos_f1', 'd_3_1', 'tertiary_distance_1', 'dist_O_0_y', 'cos_f0_f1', 'adC1', 'd_5_3', 'inv_distP', 'edge_4', 'd_6_2', 'dist_N_0_y', 'tertiary_distance_2', 'dist_O_0_x', 'cos_c1_f1', 'd_3_0', 'd_5_2', 'dist_C_0_x', 'adN1', 'cos_c0_f0', 'd_4_1', 'max_distance_y', 'dist_C_2_y', 'atom_5', 'adC3', 'dist_to_type_1_mean', 'vander_H.x', 'dist_C_3_y', 'dist_H_3_x', 'molecule_atom_index_0_dist_max_div', 'atom_7', 'dist_C_3_x', 'd_5_1', 'dist_H_3_y', 'atom_index_0_eigv_max', 'atom_6', 'dist_H_2_x', 'atom_index_1_sv_0', 'molecule_atom_index_1_dist_std_div', 'link1'],\n",
    "['d_3_1', 'dist_H_1_x', 'd_5_0', 'd_4_0', 'yukawa_H.x', 'inv_dist0', 'd_6_0', 'd_4_1', 'cos_c0', 'atom_3', 'dist_C_0_y', 'molecule_atom_index_0_dist_std_div', 'cos_c0_c1', 'd_4_2', 'min_molecule_atom_0_dist_xyz', 'sd_molecule_atom_0_dist_xyz', 'd_2_1', 'adC2', 'd_3_0', 'dist_C_1_y', 'd_4_3', 'dist_H_0_x', 'vander_C.x', 'd_5_3', 'dist_H_1_y', 'tertiary_distance_3', 'd_2_0', 'dist_O_0_x', 'd_5_1', 'dist_O_0_y', 'adC3', 'inv_dist0R', 'dist_C_3_y', 'atom_index_1_ hybridization', 'cos_f0', 'dist_C_2_x', 'd_5_2', 'd_6_1', 'dist_C_0_x', 'atom_1_bond_lengths_min', 'mulliken_atom_1', 'distance_farthest_0', 'tertiary_distance_1', 'min_molecule_atom_1_dist_xyz', 'yukawa_O.y', 'atom_0_bond_lengths_max'],\n",
    "['tertiary_angle_0', 'd_2_1', 'cos_c0', 'atom_1_bond_lengths_mean', 'd_3_1', 'd_2_0', 'tertiary_distance_1', 'd_3_2', 'tertiary_angle_1', 'cos_f0', 'tertiary_distance_2', 'dist_C_0_x', 'dist_H_0_x', 'dist_C_2_x', 'dist_O_0_y', 'd_4_1', 'd_4_3', 'atom_index_1_cycle_size_mean', 'molecule_atom_index_0_dist_min_diff', 'tertiary_atom_2', 'atom_4', 'cos_c0_f0', 'tertiary_distance_3', 'd_3_0', 'dist_median_bond_y', 'd_5_2', 'adC3', 'atom_5', 'dist_H_1_x', 'molecule_atom_index_0_dist_min_div', 'gap', 'molecule_atom_index_1_dist_min_div', 'dist_O_0_x', 'cos_c1', 'dist_C_0_y', 'd_5_1', 'dist_N_0_y', 'dist_C_3_y', 'dist_no_bond_min_y', 'd_4_0', 'dist_N_0_x', 'd_4_2', 'max_molecule_atom_0_dist_xyz', 'cos_c0_c1', 'adC2', 'atom_index_1_n_cycle', 'd_5_0', 'd_6_1', 'dist_C_4_y', 'dist_O_1_y', 'd_7_2', 'tertiary_angle_2', 'd_6_2', 'mulliken_atom_1', 'atom_6', 'd_7_3', 'dist_O_1_x'],\n",
    "['cos_c0_c1', 'atom_4', 'atom_5', 'molecule_atom_index_0_dist_min_diff', 'cos_c1', 'max_molecule_atom_1_dist_xyz', 'dist_to_type_std', 'd_3_2', 'cos_c0', 'dist_O_0_x', 'd_4_3', 'atom_6', 'dist_O_0_y', 'tertiary_atom_1', 'dist_C_2_y', 'd_4_2', 'dist_C_1_y', 'atom_7', 'tertiary_angle_1', 'dist_H_0_y', 'dist_no_bond_min_y', 'distance_c1', 'dist_C_2_x', 'linkM0', 'd_6_2', 'dist_C_0_y', 'd_5_2', 'd_7_2', 'dist_C_3_y', 'd_6_0', 'dihedral', 'max_molecule_atom_0_dist_xyz', 'd_7_3', 'd_6_1', 'dist_H_1_y', 'tertiary_atom_2', 'd_4_0', 'tertiary_atom_0', 'tertiary_angle_3', 'dist_C_0_x', 'dist_to_type_0_mean', 'dist_N_0_y', 'd_4_1', 'cos_c1_f1', 'cos_f0', 'dist_xyz', 'adC2', 'd_5_3', 'cos_f0_f1', 'gap', 'd_7_0', 'cos_f1', 'tertiary_distance_1', 'molecule_atom_index_0_dist_max_diff', 'd_2_1'],\n",
    "['cos_c0', 'tertiary_distance_1', 'cos_c1', 'd_3_2', 'tertiary_angle_1', 'tertiary_angle_0', 'atom_1_n_bonds', 'tertiary_distance_2', 'd_2_1', 'tertiary_angle_2', 'd_4_0', 'molecule_atom_index_0_dist_min_div', 'd_2_0', 'dist_H_0_x', 'd_3_1', 'cos_c0_c1', 'mulliken_atom_1', 'd_8_3', 'd_4_1', 'dist_C_0_y', 'd_3_0', 'atom_index_1_cycle_size_mean', 'dist_C_1_x', 'dist_C_2_x', 'adC2', 'adC1', 'atom_1_bond_lengths_std', 'atom_index_1_n_cycle', 'd_4_2', 'cos_f0', 'd_5_2', 'dist_to_type_0_mean', 'dist_O_0_x', 'molecule_atom_index_0_dist_std_diff', 'd_5_1', 'tertiary_angle_3', 'd_6_2', 'd_7_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ = pd.read_pickle(f'{file_folder}/df_train2.gzde', compression='gzip')\n",
    "df_train__plus = pd.read_pickle(f'{file_folder}/df_train2_plus.gzde', compression='gzip')\n",
    "df_train__plus = df_train__plus.rename(columns={'id':'index'})\n",
    "df_train_ = pd.merge(df_train_, df_train__plus, how='left', on='index')\n",
    "df_train_ = df_train_.fillna(0)\n",
    "\n",
    "df_test_ = pd.read_pickle(f'{file_folder}/df_test2.gzde', compression='gzip')\n",
    "df_test__plus = pd.read_pickle(f'{file_folder}/df_test2_plus.gzde', compression='gzip')\n",
    "df_test__plus = df_test__plus.rename(columns={'id':'index'})\n",
    "df_test_ = pd.merge(df_test_, df_test__plus, how='left', on='index')\n",
    "df_test_ = df_test_.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_list = df_train_.type.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain =True\n",
    "cv_score=[]\n",
    "cv_score_total=0\n",
    "epoch_n = 1000\n",
    "verbose = 1\n",
    "batch_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 0 out of ['1JHC' '2JHH' '1JHN' '2JHN' '2JHC' '3JHH' '3JHC' '3JHN'] \n",
      "\n",
      "Train on 3726517 samples, validate on 931630 samples\n",
      "Epoch 1/1000\n",
      "3726517/3726517 [==============================] - 118s 32us/step - loss: 1.9703 - val_loss: 2.3424\n",
      "Epoch 2/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 1.0876 - val_loss: 1.2276\n",
      "Epoch 3/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 1.0156 - val_loss: 1.2131\n",
      "Epoch 4/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.9721 - val_loss: 0.7531\n",
      "Epoch 5/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.9311 - val_loss: 1.0327\n",
      "Epoch 6/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.8982 - val_loss: 0.8051\n",
      "Epoch 7/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.8942 - val_loss: 1.1432\n",
      "Epoch 8/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.8815 - val_loss: 0.6794\n",
      "Epoch 9/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.8667 - val_loss: 0.6436\n",
      "Epoch 10/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.8644 - val_loss: 0.7282\n",
      "Epoch 11/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.8528 - val_loss: 0.5888\n",
      "Epoch 12/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.8378 - val_loss: 0.6736\n",
      "Epoch 13/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.8266 - val_loss: 0.4748\n",
      "Epoch 14/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.8153 - val_loss: 0.4943\n",
      "Epoch 15/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.8142 - val_loss: 0.4777\n",
      "Epoch 16/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.8155 - val_loss: 0.5714\n",
      "Epoch 17/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.8014 - val_loss: 0.6560\n",
      "Epoch 18/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.8007 - val_loss: 0.5594\n",
      "Epoch 19/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7946 - val_loss: 0.5216\n",
      "Epoch 20/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7939 - val_loss: 0.5044\n",
      "Epoch 21/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7914 - val_loss: 0.6021\n",
      "Epoch 22/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7911 - val_loss: 0.4416\n",
      "Epoch 23/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7815 - val_loss: 0.4815\n",
      "Epoch 24/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7723 - val_loss: 0.4846\n",
      "Epoch 25/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7780 - val_loss: 0.4363\n",
      "Epoch 26/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7781 - val_loss: 0.5017\n",
      "Epoch 27/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7797 - val_loss: 0.4302\n",
      "Epoch 28/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7789 - val_loss: 0.4536\n",
      "Epoch 29/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7741 - val_loss: 0.5152\n",
      "Epoch 30/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7777 - val_loss: 0.6015\n",
      "Epoch 31/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7578 - val_loss: 0.5516\n",
      "Epoch 32/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7729 - val_loss: 0.5870\n",
      "Epoch 33/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7486 - val_loss: 0.4648\n",
      "Epoch 34/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7490 - val_loss: 0.5836\n",
      "Epoch 35/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7551 - val_loss: 0.6217\n",
      "Epoch 36/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7423 - val_loss: 0.4335\n",
      "Epoch 37/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7513 - val_loss: 0.8653\n",
      "Epoch 38/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7466 - val_loss: 0.5099\n",
      "Epoch 39/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7513 - val_loss: 0.5489\n",
      "Epoch 40/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7669 - val_loss: 0.6445\n",
      "Epoch 41/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7474 - val_loss: 0.3974\n",
      "Epoch 42/1000\n",
      "3726517/3726517 [==============================] - 124s 33us/step - loss: 0.7508 - val_loss: 0.4037\n",
      "Epoch 43/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7455 - val_loss: 0.4184\n",
      "Epoch 44/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7434 - val_loss: 0.4778\n",
      "Epoch 45/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7478 - val_loss: 0.6233\n",
      "Epoch 46/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7412 - val_loss: 0.4645\n",
      "Epoch 47/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7246 - val_loss: 0.4720\n",
      "Epoch 48/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7322 - val_loss: 0.4298\n",
      "Epoch 49/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7338 - val_loss: 0.4518\n",
      "Epoch 50/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7377 - val_loss: 0.4382\n",
      "Epoch 51/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7285 - val_loss: 0.3694\n",
      "Epoch 52/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7241 - val_loss: 0.5876\n",
      "Epoch 53/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7457 - val_loss: 0.4766\n",
      "Epoch 54/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7286 - val_loss: 0.6423\n",
      "Epoch 55/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7245 - val_loss: 0.4096\n",
      "Epoch 56/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7327 - val_loss: 0.3817\n",
      "Epoch 57/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7295 - val_loss: 0.5218\n",
      "Epoch 58/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7348 - val_loss: 0.4354\n",
      "Epoch 59/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7226 - val_loss: 0.5875\n",
      "Epoch 60/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7351 - val_loss: 0.4018\n",
      "Epoch 61/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7524 - val_loss: 0.3882\n",
      "Epoch 62/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7268 - val_loss: 0.4502\n",
      "Epoch 63/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7269 - val_loss: 0.4056\n",
      "Epoch 64/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7272 - val_loss: 0.4682\n",
      "Epoch 65/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7128 - val_loss: 0.5780\n",
      "Epoch 66/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7307 - val_loss: 0.4117\n",
      "Epoch 67/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7154 - val_loss: 0.3744\n",
      "Epoch 68/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7199 - val_loss: 0.5773\n",
      "Epoch 69/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7011 - val_loss: 0.4341\n",
      "Epoch 70/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7095 - val_loss: 0.4288\n",
      "Epoch 71/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7363 - val_loss: 0.6198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7194 - val_loss: 0.4206\n",
      "Epoch 73/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7187 - val_loss: 0.4660\n",
      "Epoch 74/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7354 - val_loss: 0.3708\n",
      "Epoch 75/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7300 - val_loss: 0.4764\n",
      "Epoch 76/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7262 - val_loss: 0.3824\n",
      "Epoch 77/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7202 - val_loss: 0.3376\n",
      "Epoch 78/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7296 - val_loss: 0.4027\n",
      "Epoch 79/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6962 - val_loss: 0.3500\n",
      "Epoch 80/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7303 - val_loss: 0.4639\n",
      "Epoch 81/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7062 - val_loss: 0.4786\n",
      "Epoch 82/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6981 - val_loss: 0.3867\n",
      "Epoch 83/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7023 - val_loss: 0.5690\n",
      "Epoch 84/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7141 - val_loss: 0.5575\n",
      "Epoch 85/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7168 - val_loss: 0.3676\n",
      "Epoch 86/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7111 - val_loss: 0.3592\n",
      "Epoch 87/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7158 - val_loss: 0.3701\n",
      "Epoch 88/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7231 - val_loss: 0.4403\n",
      "Epoch 89/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7113 - val_loss: 0.3801\n",
      "Epoch 90/1000\n",
      "3726517/3726517 [==============================] - 123s 33us/step - loss: 0.7100 - val_loss: 0.3449\n",
      "Epoch 91/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6977 - val_loss: 0.3426\n",
      "Epoch 92/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7213 - val_loss: 0.4751\n",
      "Epoch 93/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7133 - val_loss: 0.4279\n",
      "Epoch 94/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7134 - val_loss: 0.5917\n",
      "Epoch 95/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6917 - val_loss: 0.3991\n",
      "Epoch 96/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6985 - val_loss: 0.3684\n",
      "Epoch 97/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.7070 - val_loss: 0.4419\n",
      "Epoch 98/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7137 - val_loss: 0.3606\n",
      "Epoch 99/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6873 - val_loss: 0.3976\n",
      "Epoch 100/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6863 - val_loss: 0.3400\n",
      "Epoch 101/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7199 - val_loss: 0.4604\n",
      "Epoch 102/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7114 - val_loss: 0.3416\n",
      "Epoch 103/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7084 - val_loss: 0.3980\n",
      "Epoch 104/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7005 - val_loss: 0.4255\n",
      "Epoch 105/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7133 - val_loss: 0.4141\n",
      "Epoch 106/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6998 - val_loss: 0.3485\n",
      "Epoch 107/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.7067 - val_loss: 0.3744\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 108/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6560 - val_loss: 0.2815\n",
      "Epoch 109/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6567 - val_loss: 0.2807\n",
      "Epoch 110/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6361 - val_loss: 0.2866\n",
      "Epoch 111/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6538 - val_loss: 0.2788\n",
      "Epoch 112/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6552 - val_loss: 0.2776\n",
      "Epoch 113/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6474 - val_loss: 0.2984\n",
      "Epoch 114/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6677 - val_loss: 0.2988\n",
      "Epoch 115/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6550 - val_loss: 0.2764\n",
      "Epoch 116/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6464 - val_loss: 0.2770\n",
      "Epoch 117/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6477 - val_loss: 0.2765\n",
      "Epoch 118/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6631 - val_loss: 0.2793\n",
      "Epoch 119/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6640 - val_loss: 0.2782\n",
      "Epoch 120/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6679 - val_loss: 0.2745\n",
      "Epoch 121/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6380 - val_loss: 0.2801\n",
      "Epoch 122/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6495 - val_loss: 0.2749\n",
      "Epoch 123/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6714 - val_loss: 0.2723\n",
      "Epoch 124/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6515 - val_loss: 0.2787\n",
      "Epoch 125/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6476 - val_loss: 0.2814\n",
      "Epoch 126/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6565 - val_loss: 0.2752\n",
      "Epoch 127/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6561 - val_loss: 0.2815\n",
      "Epoch 128/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6507 - val_loss: 0.2748\n",
      "Epoch 129/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6597 - val_loss: 0.2775\n",
      "Epoch 130/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6617 - val_loss: 0.2739\n",
      "Epoch 131/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6415 - val_loss: 0.2744\n",
      "Epoch 132/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6350 - val_loss: 0.2640\n",
      "Epoch 220/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6389 - val_loss: 0.2676\n",
      "Epoch 221/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6494 - val_loss: 0.2639\n",
      "Epoch 222/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6297 - val_loss: 0.2731\n",
      "Epoch 223/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6450 - val_loss: 0.2644\n",
      "Epoch 224/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6396 - val_loss: 0.2649\n",
      "Epoch 225/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6563 - val_loss: 0.2672\n",
      "Epoch 226/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6599 - val_loss: 0.2726\n",
      "Epoch 227/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6390 - val_loss: 0.2672\n",
      "Epoch 228/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6395 - val_loss: 0.2642\n",
      "Epoch 229/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6524 - val_loss: 0.2694\n",
      "Epoch 230/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6499 - val_loss: 0.2709\n",
      "Epoch 231/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6406 - val_loss: 0.2701\n",
      "Epoch 232/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6541 - val_loss: 0.2668\n",
      "Epoch 233/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6389 - val_loss: 0.2671\n",
      "Epoch 234/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6188 - val_loss: 0.2650\n",
      "Epoch 235/1000\n",
      "3726517/3726517 [==============================] - 124s 33us/step - loss: 0.6424 - val_loss: 0.2653\n",
      "Epoch 236/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6358 - val_loss: 0.2678\n",
      "Epoch 237/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6297 - val_loss: 0.2631\n",
      "Epoch 238/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6362 - val_loss: 0.2680\n",
      "Epoch 239/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6477 - val_loss: 0.2730\n",
      "Epoch 240/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6450 - val_loss: 0.2710\n",
      "Epoch 241/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6461 - val_loss: 0.2695\n",
      "Epoch 242/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6294 - val_loss: 0.2668\n",
      "Epoch 243/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6347 - val_loss: 0.2752\n",
      "Epoch 244/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6502 - val_loss: 0.2703\n",
      "Epoch 245/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6553 - val_loss: 0.2642\n",
      "Epoch 246/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6554 - val_loss: 0.2641\n",
      "Epoch 247/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6541 - val_loss: 0.2655\n",
      "Epoch 248/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6412 - val_loss: 0.2673\n",
      "Epoch 249/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6602 - val_loss: 0.2636\n",
      "Epoch 250/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6270 - val_loss: 0.2652\n",
      "Epoch 251/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6417 - val_loss: 0.2783\n",
      "Epoch 252/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6421 - val_loss: 0.2655\n",
      "Epoch 253/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6481 - val_loss: 0.2794\n",
      "Epoch 254/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6295 - val_loss: 0.2835\n",
      "Epoch 255/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6341 - val_loss: 0.2643\n",
      "Epoch 256/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6594 - val_loss: 0.2638\n",
      "Epoch 257/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6437 - val_loss: 0.2695\n",
      "Epoch 258/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6352 - val_loss: 0.2722\n",
      "Epoch 259/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6297 - val_loss: 0.2731\n",
      "Epoch 260/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6349 - val_loss: 0.2638\n",
      "Epoch 261/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6322 - val_loss: 0.2634\n",
      "Epoch 262/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6310 - val_loss: 0.2731\n",
      "Epoch 263/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6418 - val_loss: 0.2689\n",
      "Epoch 264/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6339 - val_loss: 0.2693\n",
      "Epoch 265/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6368 - val_loss: 0.2676\n",
      "Epoch 266/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6427 - val_loss: 0.2636\n",
      "Epoch 267/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6511 - val_loss: 0.2630\n",
      "\n",
      "Epoch 00267: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 268/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6470 - val_loss: 0.2633\n",
      "Epoch 269/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6575 - val_loss: 0.2635\n",
      "Epoch 270/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6464 - val_loss: 0.2635\n",
      "Epoch 271/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6521 - val_loss: 0.2637\n",
      "Epoch 272/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6426 - val_loss: 0.2758\n",
      "Epoch 273/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6461 - val_loss: 0.2717\n",
      "Epoch 274/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6405 - val_loss: 0.2663\n",
      "Epoch 275/1000\n",
      "3726517/3726517 [==============================] - 114s 31us/step - loss: 0.6460 - val_loss: 0.2634\n",
      "Epoch 276/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6317 - val_loss: 0.2631\n",
      "Epoch 277/1000\n",
      "3726517/3726517 [==============================] - 115s 31us/step - loss: 0.6553 - val_loss: 0.2663\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00277: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.3353677708388292\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "NumPy boolean array indexing assignment cannot assign 2505542 input values to the 0 output values where the mask is true",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-14241a246076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# for each molecule type we'll grab the predicted values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mtest_prediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_csv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mmol_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: NumPy boolean array indexing assignment cannot assign 2505542 input values to the 0 output values where the mask is true"
     ]
    }
   ],
   "source": [
    "start_time=datetime.now()\n",
    "test_prediction=np.zeros(len(test_csv))\n",
    "\n",
    "\n",
    "\n",
    "# Loop through each molecule type\n",
    "for mol_type in type_list:\n",
    "\n",
    "    model_name_wrt = ('molecule_model_%s.hdf5' % mol_type)\n",
    "    print('Training %s' % mol_type, 'out of', mol_types, '\\n')\n",
    "    \n",
    "#     full = build_couple_dataframe(train_csv, structures_csv, mol_type, n_atoms=11)\n",
    "#     full2 = build_couple_dataframe(test_csv, structures_csv, mol_type, n_atoms=11)\n",
    "#     df_train_ = take_n_atoms(full, 11)\n",
    "#     df_test_ = take_n_atoms(full2, 11)\n",
    "#     df_train_  = df_train_.fillna(0)\n",
    "#     df_test_  = df_test_.fillna(0)\n",
    "    \n",
    "#     # Standard Scaler from sklearn does seem to work better here than other Scalers\n",
    "#     input_data=StandardScaler().fit_transform(pd.concat([df_train_.loc[:,input_features],df_test_.loc[:,input_features]]))   \n",
    "#     #input_data=StandardScaler().fit_transform(df_train_.loc[:,input_features])\n",
    "#     target_data=df_train_.loc[:,\"scalar_coupling_constant\"].values\n",
    "    \n",
    "    input_data=StandardScaler().fit_transform(pd.concat([df_train_.loc[:,type_columns[mol_type]],\n",
    "                                                         df_test_.loc[:,type_columns[mol_type]]]))   \n",
    "    target_data=df_train_.loc[:,\"scalar_coupling_constant\"].values\n",
    "    \n",
    "    # Simple split to provide us a validation set to do our CV checks with\n",
    "    train_index, cv_index = train_test_split(np.arange(len(df_train_)),random_state=111, test_size=0.2)\n",
    "    # Split all our input and targets by train and cv indexes\n",
    "    train_target=target_data[train_index]\n",
    "    cv_target=target_data[cv_index]\n",
    "    train_input=input_data[train_index]\n",
    "    cv_input=input_data[cv_index]\n",
    "    test_input=input_data[len(df_train_):,:]\n",
    "\n",
    "    # Build the Neural Net\n",
    "    nn_model=create_nn_model(train_input.shape[1])\n",
    "    \n",
    "    # If retrain==False, then we load a previous saved model as a starting point.\n",
    "    if not retrain:\n",
    "        nn_model = load_model(model_name_rd)\n",
    "        \n",
    "    nn_model.compile(loss='mae', optimizer=Adam())#, metrics=[auc])\n",
    "    \n",
    "    # Callback for Early Stopping... May want to raise the min_delta for small numbers of epochs\n",
    "    es = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=40,verbose=1, mode='auto', restore_best_weights=True)\n",
    "    # Callback for Reducing the Learning Rate... when the monitor levels out for 'patience' epochs, then the LR is reduced\n",
    "    rlr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=30, min_lr=1e-6, mode='auto', verbose=1)\n",
    "    # Save the best value of the model for future use\n",
    "    sv_mod = callbacks.ModelCheckpoint(model_name_wrt, monitor='val_loss', save_best_only=True, period=1)\n",
    "    history = nn_model.fit(train_input,[train_target], \n",
    "            validation_data=(cv_input,[cv_target]), \n",
    "            callbacks=[es, rlr, sv_mod], epochs=epoch_n, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    cv_predict=nn_model.predict(cv_input)\n",
    "    plot_history(history, mol_type)\n",
    "    accuracy=np.mean(np.abs(cv_target-cv_predict[:,0]))\n",
    "    print(np.log(accuracy))\n",
    "    cv_score.append(np.log(accuracy))\n",
    "    cv_score_total+=np.log(accuracy)\n",
    "    \n",
    "    # Predict on the test data set using our trained model\n",
    "    test_predict=nn_model.predict(test_input)\n",
    "    \n",
    "    # for each molecule type we'll grab the predicted values\n",
    "    test_csv[test_csv[\"type\"]==mol_type]=test_predict[:,0]\n",
    "    K.clear_session()\n",
    "    break\n",
    "\n",
    "cv_score_total/=len(mol_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, molecule_name, atom_index_0, atom_index_1, type]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv[test_csv[\"type\"]==mol_type].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3JHC    811999\n",
       "2JHC    613138\n",
       "1JHC    380609\n",
       "3JHH    317435\n",
       "2JHH    203126\n",
       "3JHN     90616\n",
       "2JHN     64424\n",
       "1JHN     24195\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_gpu_p36)",
   "language": "python",
   "name": "conda_tensorflow_gpu_p36"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
