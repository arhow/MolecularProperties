{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "   div#notebook-container    { width: 95%; }\n",
       "   div#menubar-container     { width: 65%; }\n",
       "   div#maintoolbar-container { width: 99%; }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "   div#notebook-container    { width: 95%; }\n",
    "   div#menubar-container     { width: 65%; }\n",
    "   div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU, GRU\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.nn import NNConv, Set2Set\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.utils import remove_self_loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTransform(object):\n",
    "    def __call__(self, data):\n",
    "        # Specify target.\n",
    "        data.y = data.y[:, target]\n",
    "        return data\n",
    "\n",
    "\n",
    "class Complete(object):\n",
    "    def __call__(self, data):\n",
    "        device = data.edge_index.device\n",
    "\n",
    "        row = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
    "        col = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
    "\n",
    "        row = row.view(-1, 1).repeat(1, data.num_nodes).view(-1)\n",
    "        col = col.repeat(data.num_nodes)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "        edge_attr = None\n",
    "        if data.edge_attr is not None:\n",
    "            idx = data.edge_index[0] * data.num_nodes + data.edge_index[1]\n",
    "            size = list(data.edge_attr.size())\n",
    "            size[0] = data.num_nodes * data.num_nodes\n",
    "            edge_attr = data.edge_attr.new_zeros(size)\n",
    "            edge_attr[idx] = data.edge_attr\n",
    "\n",
    "        edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
    "        data.edge_attr = edge_attr\n",
    "        data.edge_index = edge_index\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "path = osp.join(osp.dirname(osp.realpath('__file__')), '..', 'data', 'QM9')\n",
    "transform = T.Compose([MyTransform(), Complete(), T.Distance(norm=False)])\n",
    "dataset = QM9(path, transform=transform).shuffle()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4079.5243685127575"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1125*np.log(1+25600/700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4672740504900.22"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "700*(np.exp2(4079.5243685127575/1125)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1125*np.log(1+0/700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 ==============> 0.0 ==============> 0.0\n",
      "509.9405460640947 ==============> 401.425821089579 ==============> 32.0\n",
      "1019.8810921281894 ==============> 1033.0554848040758 ==============> 82.0\n",
      "1529.8216381922841 ==============> 2026.9029433487538 ==============> 162.0\n",
      "2039.7621842563788 ==============> 3590.687590584987 ==============> 287.0\n",
      "2549.7027303204736 ==============> 6051.248717855625 ==============> 484.0\n",
      "3059.6432763845683 ==============> 9922.856660634421 ==============> 794.0\n",
      "3569.583822448663 ==============> 16014.698028223103 ==============> 1281.0\n",
      "4079.5243685127575 ==============> 25600.0 ==============> 2048.0\n"
     ]
    }
   ],
   "source": [
    "for m in np.linspace(0, 4079.5243685127575, num=9):\n",
    "    h = 700*(np.exp(m/1125)-1)\n",
    "    fft_bin = np.floor((4096+1)*h/51200)\n",
    "    print(m, '==============>',h, '==============>',fft_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ba232b337bcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Normalize targets to mean = 0 and std = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "# Normalize targets to mean = 0 and std = 1.\n",
    "mean = dataset.data.y[:, target].mean().item()\n",
    "std = dataset.data.y[:, target].std().item()\n",
    "dataset.data.y[:, target] = (dataset.data.y[:, target] - mean) / std\n",
    "\n",
    "# Split datasets.\n",
    "test_dataset = dataset[:100]\n",
    "val_dataset = dataset[100:200]\n",
    "train_dataset = dataset[200:300]\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.4999) tensor(0.5159)\n",
      "1 tensor(0.4771) tensor(0.3499)\n",
      "2 tensor(0.2239) tensor(0.0529)\n",
      "3 tensor(0.2700) tensor(0.0791)\n",
      "4 tensor(0.0472) tensor(0.0022)\n",
      "5 tensor(2.7774) tensor(3.6384)\n",
      "6 tensor(0.2818) tensor(0.0869)\n",
      "7 tensor(0.2052) tensor(0.0440)\n",
      "8 tensor(0.2316) tensor(0.0568)\n",
      "9 tensor(0.1547) tensor(0.0245)\n",
      "10 tensor(0.3481) tensor(0.1409)\n",
      "11 tensor(0.4661) tensor(0.3187)\n",
      "12 tensor(0.8643) tensor(0.5159)\n"
     ]
    }
   ],
   "source": [
    "for i in range(13):\n",
    "    print(i, train_dataset.data.x[:,i].std(), train_dataset.data.x[:,i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 0\n",
    "dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin0 = torch.nn.Linear(dataset.num_features, dim)\n",
    "\n",
    "        nn = Sequential(Linear(5, 128), ReLU(), Linear(128, dim * dim))\n",
    "        self.conv = NNConv(dim, dim, nn, aggr='mean', root_weight=False)\n",
    "        self.gru = GRU(dim, dim)\n",
    "\n",
    "        self.set2set = Set2Set(dim, processing_steps=3)\n",
    "        self.lin1 = torch.nn.Linear(2 * dim, dim)\n",
    "        self.lin2 = torch.nn.Linear(dim, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        out = F.relu(self.lin0(data.x))\n",
    "#         print(out.shape)\n",
    "        h = out.unsqueeze(0)\n",
    "#         print(h.shape)\n",
    "\n",
    "        for i in range(3):\n",
    "#             print('edge_index', data.edge_index.shape, 'edge_attr':data.edge_attr.shape)\n",
    "            m = F.relu(self.conv(out, data.edge_index, data.edge_attr))\n",
    "#             print(m.shape)\n",
    "            out, h = self.gru(m.unsqueeze(0), h)\n",
    "#             print(out.shape, h.shape)\n",
    "            out = out.squeeze(0)\n",
    "#             print(out.shape)\n",
    "\n",
    "        out = self.set2set(out, data.batch)\n",
    "        out = F.relu(self.lin1(out))\n",
    "        out = self.lin2(out)\n",
    "        out = out.view(-1)\n",
    "#         print(out.shape)\n",
    "        return out\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=5, min_lr=0.00001)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "#         print(i, data.y.shape)\n",
    "        loss = F.mse_loss(model(data), data.y)\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    error = 0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        error += (model(data) * std - data.y * std).abs().sum().item()  # MAE\n",
    "    return error / len(loader.dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, LR: 0.001000, Loss: 0.7713466, Validation MAE: 1.1874266, Test MAE: 1.0079571\n"
     ]
    }
   ],
   "source": [
    "best_val_error = None\n",
    "for epoch in range(1, 2):\n",
    "    lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "    loss = train(epoch)\n",
    "    val_error = test(val_loader)\n",
    "    scheduler.step(val_error)\n",
    "\n",
    "    if best_val_error is None or val_error <= best_val_error:\n",
    "        test_error = test(test_loader)\n",
    "        best_val_error = val_error\n",
    "\n",
    "    print('Epoch: {:03d}, LR: {:7f}, Loss: {:.7f}, Validation MAE: {:.7f}, Test MAE: {:.7f}'.format(epoch, lr, loss, val_error, test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_gpu_p36)",
   "language": "python",
   "name": "conda_tensorflow_gpu_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
