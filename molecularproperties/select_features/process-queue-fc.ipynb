{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "   div#notebook-container    { width: 95%; }\n",
       "   div#menubar-container     { width: 65%; }\n",
       "   div#maintoolbar-container { width: 99%; }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "   div#notebook-container    { width: 95%; }\n",
    "   div#menubar-container     { width: 65%; }\n",
    "   div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\") # Adds higher directory to python modules path.\n",
    "from utilities import aggregate_feature_calculators\n",
    "from utilities import aggregate_feature_calculators_setting as aggcal\n",
    "from utilities.parallel import Parallel\n",
    "from utilities.dfdb import DFDB\n",
    "\n",
    "from utilities.process.pqueue import *\n",
    "from utilities.process.pnode import *\n",
    "from utilities.process.putilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import copy\n",
    "import gc\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "import optuna\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold,TimeSeriesSplit, GroupKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv',\n",
       " 'magnetic_shielding_tensors.csv',\n",
       " 'potential_energy.csv',\n",
       " 'scalar_coupling_contributions.csv',\n",
       " 'dipole_moments.csv',\n",
       " 'mulliken_charges.csv',\n",
       " 'train.csv',\n",
       " 'test.csv',\n",
       " 'structures.csv',\n",
       " 'structures']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_folder =  '../../data/input'\n",
    "os.listdir(csv_file_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_folder =  '../../data/feature'\n",
    "[f for f in os.listdir(file_folder) if (f.endswith('.pkl')) and (not f.startswith('.'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=fc, type=0\n",
    "227\n",
    "{'columns': ['atom_index_1_cycle_size_mean', 'dist_H_0_y', 'dist_H_1_x', 'tertiary_atom_1', 'adC2', 'tertiary_distance_1', 'dist_C_2_y', 'molecule_atom_index_1_dist_min_diff', 'dist_C_1_y', 'atom_index_farthest_0', 'yukawa_H.y', 'inv_dist1R', 'dist_C_0_x', 'dist_H_3_x', 'tertiary_angle_3', 'dist_to_type_std', 'dist_C_3_y', 'eem_1', 'inv_distPR', 'dist_C_1_x', 'linkM0', 'dist_H_2_y', 'dist_H_0_x', 'adC1', 'tertiary_angle_0', 'adN1', 'dist_O_1_y', 'dist_C_2_x', 'eem_0', 'dist_C_4_x', 'adC3', 'tertiary_distance_3', 'dist_O_0_x', 'tertiary_angle_2', 'atom_1_bond_lengths_std', 'molecule_atom_index_0_dist_max_div', 'inv_dist0R', 'distance_farthest_0', 'yukawa_N.x', 'dist_H_3_y', 'molecule_type_dist_mean_diff', 'dist_N_0_x', 'max_molecule_atom_1_dist_xyz', 'dist_C_0_y', 'dist_H_2_x', 'dist_to_type_0_mean', 'tertiary_distance_5', 'atom_1_n_bonds', 'dist_C_3_x', 'tertiary_distance_0', 'dist_to_type_mean', 'distC1', 'dist_O_0_y', 'dist_C_4_y', 'tertiary_distance_2', 'cos_f0', 'atom_1_bond_lengths_max', 'dist_N_0_y', 'dist_xyz', 'dist_H_1_y', 'dist_O_1_x', 'tertiary_distance_4', 'atom_1_bond_lengths_mean', 'yukawa_H.x', 'tertiary_atom_0', 'tertiary_angle_4', 'inv_dist1E', 'tertiary_angle_1'], 'cv': {'cls': 'KFold', 'init': {'n_splits': 5, 'shuffle': True, 'random_state': 42}}, 'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}}, 'model': {'cls': 'lgb.LGBMRegressor', 'init': {'learning_rate': 0.2833769330240482, 'feature_fraction': 0.8818248470204605, 'bagging_fraction': 0.8205197060908092, 'min_data_in_leaf': 202, 'lambda_l1': 0.017039063121824582, 'lambda_l2': 0.8318702431636841, 'max_bin': 100, 'num_leaves': 255, 'random_state': 3895, 'n_jobs': 16}, 'fit': {}}, 'metric': 'mean_absolute_error'}\n",
    "y=fc, type=1\n",
    "561\n",
    "{'columns': ['atom_index_1_cycle_size_mean', 'dist_H_0_y', 'dist_H_1_x', 'linkM1', 'adC2', 'tertiary_distance_1', 'tertiary_distance_6', 'dist_C_2_y', 'distance_center0', 'dist_C_1_y', 'yukawa_H.y', 'inv_dist1R', 'dist_C_0_x', 'yukawa_C.x', 'inv_dist1', 'cos_center0', 'tertiary_angle_3', 'cos_center1', 'dist_C_3_y', 'vander_O.y', 'eem_1', 'inv_distPR', 'dist_C_1_x', 'inv_distP', 'vander_N.y', 'dist_H_2_y', 'dist_H_0_x', 'tertiary_angle_0', 'vander_N.x', 'dist_C_2_x', 'eem_0', 'coulomb_H.x', 'min_molecule_atom_1_dist_xyz', 'yukawa_N.y', 'molecule_atom_index_0_dist_mean_div', 'dist_C_4_x', 'adC3', 'tertiary_distance_3', 'linkN', 'dist_O_0_x', 'max_molecule_atom_0_dist_xyz', 'distance_center1', 'tertiary_angle_2', 'atom_1_bond_lengths_std', 'molecule_atom_index_0_dist_max_div', 'inv_dist0R', 'link0', 'yukawa_N.x', 'dist_H_3_y', 'dist_N_0_x', 'dist_C_0_y', 'molecule_atom_1_dist_min_diff', 'dist_to_type_0_mean', 'inv_distPE', 'vander_H.x', 'tertiary_distance_5', 'dist_N_1_y', 'dist_N_1_x', 'dist_C_3_x', 'tertiary_distance_0', 'dist_O_0_y', 'distN0', 'dist_C_4_y', 'cos_f1', 'tertiary_distance_2', 'vander_O.x', 'cos_f0', 'atom_1_bond_lengths_max', 'dist_N_0_y', 'dist_H_1_y', 'tertiary_distance_4', 'atom_1_bond_lengths_mean', 'tertiary_atom_0', 'distN1', 'tertiary_angle_1', 'adC4', 'bond_atom'], 'cv': {'cls': 'KFold', 'init': {'n_splits': 5, 'shuffle': True, 'random_state': 42}}, 'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}}, 'model': {'cls': 'lgb.LGBMRegressor', 'init': {'learning_rate': 0.2833769330240482, 'feature_fraction': 0.8818248470204605, 'bagging_fraction': 0.8205197060908092, 'min_data_in_leaf': 202, 'lambda_l1': 0.017039063121824582, 'lambda_l2': 0.8318702431636841, 'max_bin': 100, 'num_leaves': 255, 'random_state': 3895, 'n_jobs': 16}, 'fit': {}}, 'metric': 'mean_absolute_error'}\n",
    "y=fc, type=2\n",
    "788\n",
    "{'columns': ['atom_index_1_cycle_size_mean', 'atom_0_bond_lengths_max', 'dist_H_0_y', 'tertiary_atom_1', 'adC2', 'tertiary_atom_2', 'tertiary_distance_6', 'tertiary_distance_1', 'dist_C_2_y', 'molecule_atom_index_1_dist_min_diff', 'dist_C_1_y', 'dist_C_0_x', 'inv_dist1R', 'atom_1_bond_lengths_min', 'cos_c0_c1', 'tertiary_angle_3', 'inv_dist1', 'molecule_atom_index_0_dist_max_diff', 'dist_C_3_y', 'vander_O.y', 'eem_1', 'inv_distPR', 'dist_C_1_x', 'dist_H_0_x', 'adC1', 'tertiary_angle_0', 'adN1', 'dist_C_2_x', 'molecule_atom_index_0_dist_mean_div', 'molecule_atom_index_0_dist_min_diff', 'adC3', 'tertiary_distance_3', 'dist_O_0_x', 'max_molecule_atom_0_dist_xyz', 'tertiary_angle_2', 'atom_1_bond_lengths_std', 'inv_dist0R', 'distance_farthest_0', 'dist_N_0_x', 'dist_C_0_y', 'atom_index_1_n_cycle', 'molecule_atom_1_dist_min_diff', 'dist_to_type_0_mean', 'cos_c0', 'distC0', 'tertiary_atom_3', 'bond_atom', 'molecule_atom_index_1_dist_min_div', 'atom_1_n_bonds', 'vander_C.y', 'dist_C_3_x', 'tertiary_atom_4', 'dist_O_0_y', 'molecule_atom_index_0_dist_min_div', 'tertiary_distance_2', 'cos_f0', 'atom_1_bond_lengths_max', 'dist_N_0_y', 'dist_xyz', 'dist_H_1_y', 'dist_O_1_x', 'atom_1_bond_lengths_mean', 'min_molecule_atom_0_dist_xyz', 'molecule_type_dist_max', 'tertiary_atom_0', 'tertiary_angle_4', 'tertiary_angle_1', 'cos_c1'], 'cv': {'cls': 'KFold', 'init': {'n_splits': 5, 'shuffle': True, 'random_state': 42}}, 'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}}, 'model': {'cls': 'lgb.LGBMRegressor', 'init': {'learning_rate': 0.2833769330240482, 'feature_fraction': 0.8818248470204605, 'bagging_fraction': 0.8205197060908092, 'min_data_in_leaf': 202, 'lambda_l1': 0.017039063121824582, 'lambda_l2': 0.8318702431636841, 'max_bin': 100, 'num_leaves': 255, 'random_state': 3895, 'n_jobs': 16}, 'fit': {}}, 'metric': 'mean_absolute_error'}\n",
    "y=fc, type=3\n",
    "294\n",
    "{'columns': ['yukawa_H.y', 'dist_H_0_y', 'dist_H_3_x', 'tertiary_distance_2', 'dist_H_1_y', 'tertiary_angle_0', 'vander_H.y', 'adC3', 'dist_H_1_x', 'tertiary_distance_3', 'tertiary_atom_2', 'dist_to_type_0_mean', 'molecule_atom_index_0_dist_min_div', 'tertiary_angle_3', 'dist_H_2_x', 'dist_to_type_std', 'dist_C_0_y', 'tertiary_distance_1', 'adN1', 'molecule_atom_index_0_dist_mean_diff', 'inv_distPE', 'adC1', 'molecule_type_dist_max', 'cos_f0', 'eem_1', 'tertiary_atom_1', 'dist_C_3_y', 'molecule_atom_index_0_dist_min_diff', 'dist_N_0_y', 'cos_c1', 'molecule_dist_min', 'vander_H.x', 'mean_molecule_atom_1_dist_xyz', 'dist_H_2_y', 'dist_to_type_1_mean', 'dist_O_0_y', 'molecule_atom_index_0_dist_max_div', 'dist_C_3_x', 'cos_c0', 'mean_molecule_atom_0_dist_xyz', 'cos_f0_f1', 'cos_c0_c1', 'inv_distPR', 'dist_N_0_x', 'dist_C_1_x', 'dist_H_4_x', 'dist_O_0_x', 'dist_H_4_y', 'adC2', 'cos_f1', 'dist_C_0_x', 'min_molecule_atom_1_dist_xyz', 'dist_H_3_y', 'dist_C_1_y', 'max_distance_y', 'dist_C_2_y', 'dist_to_type_mean', 'yukawa_H.x', 'dist_xyz', 'dist_H_0_x', 'distance_c1', 'inv_distP', 'link0', 'tertiary_distance_4', 'tertiary_angle_1', 'distance_farthest_0', 'dist_C_2_x'], 'cv': {'cls': 'KFold', 'init': {'n_splits': 5, 'shuffle': True, 'random_state': 42}}, 'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}}, 'model': {'cls': 'lgb.LGBMRegressor', 'init': {'learning_rate': 0.2833769330240482, 'feature_fraction': 0.8818248470204605, 'bagging_fraction': 0.8205197060908092, 'min_data_in_leaf': 202, 'lambda_l1': 0.017039063121824582, 'lambda_l2': 0.8318702431636841, 'max_bin': 100, 'num_leaves': 255, 'random_state': 3895, 'n_jobs': 16}, 'fit': {}}, 'metric': 'mean_absolute_error'}\n",
    "y=fc, type=4\n",
    "468\n",
    "{'columns': ['yukawa_H.y', 'dist_H_0_y', 'dist_H_3_x', 'tertiary_distance_2', 'dist_H_1_y', 'tertiary_angle_0', 'vander_H.y', 'adC3', 'dist_H_1_x', 'tertiary_distance_3', 'tertiary_atom_2', 'dist_to_type_0_mean', 'molecule_atom_index_0_dist_min_div', 'tertiary_angle_3', 'dist_H_2_x', 'dist_to_type_std', 'dist_C_0_y', 'tertiary_distance_1', 'adN1', 'molecule_atom_index_0_dist_mean_diff', 'inv_distPE', 'adC1', 'molecule_type_dist_max', 'cos_f0', 'eem_1', 'tertiary_atom_1', 'dist_C_3_y', 'molecule_atom_index_0_dist_min_diff', 'dist_N_0_y', 'cos_c1', 'molecule_dist_min', 'vander_H.x', 'mean_molecule_atom_1_dist_xyz', 'dist_H_2_y', 'dist_to_type_1_mean', 'dist_O_0_y', 'molecule_atom_index_0_dist_max_div', 'dist_C_3_x', 'cos_c0', 'mean_molecule_atom_0_dist_xyz', 'cos_f0_f1', 'cos_c0_c1', 'inv_distPR', 'dist_N_0_x', 'dist_C_1_x', 'dist_H_4_x', 'dist_O_0_x', 'dist_H_4_y', 'adC2', 'cos_f1', 'dist_C_0_x', 'min_molecule_atom_1_dist_xyz', 'dist_H_3_y', 'dist_C_1_y', 'max_distance_y', 'dist_C_2_y', 'dist_to_type_mean', 'yukawa_H.x', 'dist_xyz', 'dist_H_0_x', 'distance_c1', 'inv_distP', 'link0', 'tertiary_distance_4', 'tertiary_angle_1', 'distance_farthest_0', 'dist_C_2_x'], 'cv': {'cls': 'KFold', 'init': {'n_splits': 5, 'shuffle': True, 'random_state': 42}}, 'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}}, 'model': {'cls': 'lgb.LGBMRegressor', 'init': {'learning_rate': 0.2833769330240482, 'feature_fraction': 0.8818248470204605, 'bagging_fraction': 0.8205197060908092, 'min_data_in_leaf': 202, 'lambda_l1': 0.017039063121824582, 'lambda_l2': 0.8318702431636841, 'max_bin': 100, 'num_leaves': 255, 'random_state': 3895, 'n_jobs': 16}, 'fit': {}}, 'metric': 'mean_absolute_error'}\n",
    "y=fc, type=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytrial = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=fc, type=5\n"
     ]
    }
   ],
   "source": [
    "# ''scalar_coupling_constant, 'fc', 'sd','pso','dso'\n",
    "for y in ['fc']:\n",
    "    for t in np.arange(5,8,1):\n",
    "        \n",
    "        print(f'y={y}, type={t}')\n",
    "        df_train=pd.read_pickle(f'{file_folder}/df_train.gzde', compression='gzip')\n",
    "#         df_test=pd.read_pickle(f'{file_folder}/df_test.gzde', compression='gzip')\n",
    "        \n",
    "        df_train['y'] = df_train[y]\n",
    "        df_train = df_train[df_train['type']==t]\n",
    "        n_samples = 500000 if df_train.shape[0] > 500000 else df_train.shape[0]\n",
    "        df_train = df_train.sample(n_samples).reset_index(drop=True)\n",
    "#         df_test = df_test[df_test['type']==t].reset_index(drop=True)\n",
    "        df_test = pd.DataFrame()\n",
    "        \n",
    "\n",
    "        param = {\n",
    "            'columns': df_train.columns.drop(['index', 'y','group', 'scalar_coupling_constant', 'fc', 'sd','pso','dso']).tolist(),\n",
    "            'cv': {\n",
    "                'cls': 'KFold',\n",
    "                'init':{\n",
    "                    'n_splits': 5,\n",
    "                    'shuffle': True,\n",
    "                    'random_state': 42,\n",
    "                },\n",
    "            },\n",
    "            'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}},\n",
    "            'model': {\n",
    "                'cls': 'lgb.LGBMRegressor',\n",
    "                'init': {\n",
    "                    'learning_rate': 0.2833769330240482,\n",
    "                    'feature_fraction': 0.8818248470204605,\n",
    "                    'bagging_fraction': 0.8205197060908092,\n",
    "                    'min_data_in_leaf': 202,\n",
    "                    'lambda_l1': 0.017039063121824582,\n",
    "                    'lambda_l2': 0.8318702431636841,\n",
    "                    'max_bin': 100,\n",
    "                    'num_leaves': 255,\n",
    "                    'random_state': 3895,\n",
    "                    'n_jobs': 16\n",
    "                },\n",
    "                'fit': {}\n",
    "            },\n",
    "            'metric': 'mean_absolute_error'\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "        process_queue = PQueue(df_train, df_test, param, mytrial)\n",
    "        sort_features = SortFeatureSelectTopNProcess(**{'top_n':200})\n",
    "        select_topn = RFESelectTopNProcess(**{'n_features_remain':20, 'n_features_to_remove':10})\n",
    "        remove_useless = RFERemoveUselessFeaturesProcess(**{})\n",
    "        process_queue.insert_node(sort_features)\n",
    "        process_queue.insert_node(select_topn)\n",
    "        process_queue.insert_node(remove_useless)\n",
    "\n",
    "        try:\n",
    "            result = process_queue.run()\n",
    "        except Exception as e:\n",
    "            print(e.__str__())\n",
    "        print(len(process_queue.trial))\n",
    "        print(process_queue.param)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_pickle(f'{file_folder}/df_train.gzde', compression='gzip')\n",
    "df_test=pd.read_pickle(f'{file_folder}/df_test.gzde', compression='gzip')\n",
    "df_train['y'] = df_train['fc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytrial=[]\n",
    "df_his, df_feature_importances, df_valid_pred, df_test_pred = pd.DataFrame(), pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "for t in  df_train.type.unique().tolist():\n",
    "    df_his_i, df_feature_importances_i, df_valid_pred_i, df_test_pred_i =  sk_process(df_train[df_train['type']==t].reset_index(drop=True), columns_list[t], f'modeling for {t}', df_test=df_test[df_test['type']==t].reset_index(drop=True), trial=mytrial, is_output_feature_importance=False, trial_level=1)\n",
    "    df_his = pd.concat([df_his, df_his_i], axis=0)\n",
    "    df_feature_importances = pd.concat([df_feature_importances, df_feature_importances_i], axis=0)\n",
    "    df_valid_pred = pd.concat([df_valid_pred, df_valid_pred_i], axis=0)\n",
    "    df_test_pred = pd.concat([df_test_pred, df_test_pred_i], axis=0)\n",
    "\n",
    "df_valid_pred = df_valid_pred.sort_values(by=['index']).reset_index(drop=True)\n",
    "df_test_pred = df_test_pred.sort_values(by=['index']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>message</th>\n",
       "      <th>nfeatures</th>\n",
       "      <th>train_metric_mean</th>\n",
       "      <th>val_metric_mean</th>\n",
       "      <th>trn_val_metric_diff</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-16 11:18:23.406847</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>78</td>\n",
       "      <td>0.820160</td>\n",
       "      <td>0.933006</td>\n",
       "      <td>0.112845</td>\n",
       "      <td>modeling for 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-16 11:18:40.952761</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>59</td>\n",
       "      <td>0.161547</td>\n",
       "      <td>0.200190</td>\n",
       "      <td>0.038643</td>\n",
       "      <td>modeling for 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-16 11:18:43.612953</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>58</td>\n",
       "      <td>0.286269</td>\n",
       "      <td>0.433112</td>\n",
       "      <td>0.146842</td>\n",
       "      <td>modeling for 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-16 11:18:50.776218</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>59</td>\n",
       "      <td>0.154898</td>\n",
       "      <td>0.237684</td>\n",
       "      <td>0.082786</td>\n",
       "      <td>modeling for 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-16 11:19:50.783660</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>68</td>\n",
       "      <td>0.360945</td>\n",
       "      <td>0.391322</td>\n",
       "      <td>0.030378</td>\n",
       "      <td>modeling for 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-07-16 11:20:19.215675</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>59</td>\n",
       "      <td>0.196629</td>\n",
       "      <td>0.225852</td>\n",
       "      <td>0.029223</td>\n",
       "      <td>modeling for 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-07-16 11:21:38.304023</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>59</td>\n",
       "      <td>0.427043</td>\n",
       "      <td>0.453386</td>\n",
       "      <td>0.026343</td>\n",
       "      <td>modeling for 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-07-16 11:21:46.386701</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>49</td>\n",
       "      <td>0.102380</td>\n",
       "      <td>0.141882</td>\n",
       "      <td>0.039502</td>\n",
       "      <td>modeling for 7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime         message  nfeatures  train_metric_mean  \\\n",
       "0 2019-07-16 11:18:23.406847  modeling for 0         78           0.820160   \n",
       "1 2019-07-16 11:18:40.952761  modeling for 3         59           0.161547   \n",
       "2 2019-07-16 11:18:43.612953  modeling for 1         58           0.286269   \n",
       "3 2019-07-16 11:18:50.776218  modeling for 4         59           0.154898   \n",
       "4 2019-07-16 11:19:50.783660  modeling for 2         68           0.360945   \n",
       "5 2019-07-16 11:20:19.215675  modeling for 6         59           0.196629   \n",
       "6 2019-07-16 11:21:38.304023  modeling for 5         59           0.427043   \n",
       "7 2019-07-16 11:21:46.386701  modeling for 7         49           0.102380   \n",
       "\n",
       "   val_metric_mean  trn_val_metric_diff         message  \n",
       "0         0.933006             0.112845  modeling for 0  \n",
       "1         0.200190             0.038643  modeling for 3  \n",
       "2         0.433112             0.146842  modeling for 1  \n",
       "3         0.237684             0.082786  modeling for 4  \n",
       "4         0.391322             0.030378  modeling for 2  \n",
       "5         0.225852             0.029223  modeling for 6  \n",
       "6         0.453386             0.026343  modeling for 5  \n",
       "7         0.141882             0.039502  modeling for 7  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trial = pd.DataFrame(mytrial)\n",
    "df_trial[['datetime', 'message', 'nfeatures', 'train_metric_mean', 'val_metric_mean', 'trn_val_metric_diff', 'message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44499493261917566\n",
      "0 0.9330056960257216\n",
      "3 0.2001904951609826\n",
      "1 0.4331118692460489\n",
      "4 0.23768410461908276\n",
      "2 0.39132241115217037\n",
      "6 0.22585247088385893\n",
      "5 0.4533857586621615\n",
      "7 0.14188187674382496\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(df_valid_pred.sort_values(by=['index']).reset_index(drop=True).predict.values, df_train.reset_index(drop=True).y.values))\n",
    "for t in df_train.type.unique().tolist():\n",
    "    index = df_train[df_train['type']==t]['index'].values\n",
    "    print(t, mean_absolute_error(df_valid_pred[df_valid_pred['index'].isin(index)].sort_values(by=['index']).reset_index(drop=True).predict.values, df_train[df_train['index'].isin(index)].reset_index(drop=True).y.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2505537</th>\n",
       "      <td>7163684</td>\n",
       "      <td>0.210720</td>\n",
       "      <td>0.871862</td>\n",
       "      <td>0.746697</td>\n",
       "      <td>1.206203</td>\n",
       "      <td>1.007102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505538</th>\n",
       "      <td>7163685</td>\n",
       "      <td>3.809454</td>\n",
       "      <td>3.867529</td>\n",
       "      <td>2.588954</td>\n",
       "      <td>2.918856</td>\n",
       "      <td>3.701579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505539</th>\n",
       "      <td>7163686</td>\n",
       "      <td>3.658385</td>\n",
       "      <td>3.428395</td>\n",
       "      <td>3.517420</td>\n",
       "      <td>1.978553</td>\n",
       "      <td>3.407225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505540</th>\n",
       "      <td>7163687</td>\n",
       "      <td>4.435589</td>\n",
       "      <td>4.727233</td>\n",
       "      <td>5.057265</td>\n",
       "      <td>4.668085</td>\n",
       "      <td>4.264797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505541</th>\n",
       "      <td>7163688</td>\n",
       "      <td>118.513458</td>\n",
       "      <td>118.589493</td>\n",
       "      <td>116.857854</td>\n",
       "      <td>117.165564</td>\n",
       "      <td>112.934275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index           0           1           2           3           4\n",
       "2505537  7163684    0.210720    0.871862    0.746697    1.206203    1.007102\n",
       "2505538  7163685    3.809454    3.867529    2.588954    2.918856    3.701579\n",
       "2505539  7163686    3.658385    3.428395    3.517420    1.978553    3.407225\n",
       "2505540  7163687    4.435589    4.727233    5.057265    4.668085    4.264797\n",
       "2505541  7163688  118.513458  118.589493  116.857854  117.165564  112.934275"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_pred.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0.44\n",
    "# df_test_pred = df_trial.loc[idx]['df_test_pred']\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit['scalar_coupling_constant'] = np.mean(df_test_pred.drop(columns=['index']).values, axis=1)\n",
    "df_submit['id'] = df_test_pred['index']\n",
    "df_submit.to_csv('../../data/submission/submission_lgbm_{}.csv'.format(idx), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_gpu_p36)",
   "language": "python",
   "name": "conda_tensorflow_gpu_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
