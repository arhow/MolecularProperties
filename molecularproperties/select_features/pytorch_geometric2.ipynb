{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "   div#notebook-container    { width: 95%; }\n",
       "   div#menubar-container     { width: 65%; }\n",
       "   div#maintoolbar-container { width: 99%; }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "   div#notebook-container    { width: 95%; }\n",
    "   div#menubar-container     { width: 65%; }\n",
    "   div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install dscribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge rdkit -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\") # Adds higher directory to python modules path.\n",
    "from utilities import aggregate_feature_calculators\n",
    "from utilities import aggregate_feature_calculators_setting as aggcal\n",
    "from utilities.parallel import Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_geometric2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from torch_geometric.data import Data, DataLoader\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch_geometric.datasets import Planetoid\n",
    "# from torch_geometric.datasets import QM9\n",
    "# from torch_geometric.datasets import TUDataset\n",
    "# import torch_geometric.transforms as T\n",
    "# from torch_geometric.nn import GCNConv, ChebConv  # noqa\n",
    "# from torch.nn import Sequential, Linear, ReLU, GRU\n",
    "# import torch_geometric.transforms as T\n",
    "# from torch_geometric.datasets import QM9\n",
    "# from torch_geometric.nn import NNConv, Set2Set\n",
    "# from torch_geometric.data import DataLoader\n",
    "# from torch_geometric.utils import remove_self_loops\n",
    "# from torch_geometric.data import Data\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold,TimeSeriesSplit, GroupKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv',\n",
       " 'magnetic_shielding_tensors.csv',\n",
       " 'potential_energy.csv',\n",
       " 'scalar_coupling_contributions.csv',\n",
       " 'dipole_moments.csv',\n",
       " 'mulliken_charges.csv',\n",
       " 'train.csv',\n",
       " 'test.csv',\n",
       " 'structures.csv',\n",
       " 'structures']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_folder = '../../data/input'\n",
    "os.listdir(file_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dir='../../data/temp/pytorch_geometric2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_convert_to_graph(graph_dir='../../data/temp/pytorch_geometric2', csv_dir=file_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{file_folder}/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f'{file_folder}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_molecule_names = test.molecule_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_molecule_names = train.molecule_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NullScheduler():\n",
    "    def __init__(self, lr=0.01 ):\n",
    "        super(NullScheduler, self).__init__()\n",
    "        self.lr    = lr\n",
    "        self.cycle = 0\n",
    "\n",
    "    def __call__(self, time):\n",
    "        return self.lr\n",
    "\n",
    "    def __str__(self):\n",
    "        string = 'NullScheduler\\n' \\\n",
    "                + 'lr=%0.5f '%(self.lr)\n",
    "        return string\n",
    "\n",
    "class LinearBn(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, act=None):\n",
    "        super(LinearBn, self).__init__()\n",
    "        self.linear = nn.Linear(in_channel, out_channel, bias=False)\n",
    "        self.bn   = nn.BatchNorm1d(out_channel,eps=1e-05, momentum=0.1)\n",
    "        self.act  = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.act is not None:\n",
    "            x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim ):\n",
    "        super(GraphConv, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            LinearBn(edge_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            LinearBn(256, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            LinearBn(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            LinearBn(128, node_dim * node_dim),\n",
    "            #nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.gru  = nn.GRU(node_dim, node_dim, batch_first=False, bidirectional=False)\n",
    "        self.bias = nn.Parameter(torch.Tensor(node_dim))\n",
    "        self.bias.data.uniform_(-1.0 / math.sqrt(node_dim), 1.0 / math.sqrt(node_dim))\n",
    "\n",
    "\n",
    "    def forward(self, node, edge_index, edge, hidden):\n",
    "        num_node, node_dim = node.shape\n",
    "        num_edge, edge_dim = edge.shape\n",
    "        edge_index = edge_index.t().contiguous()\n",
    "\n",
    "        #1. message :  m_j = SUM_i f(n_i, n_j, e_ij)  where i is neighbour(j)\n",
    "        x_i     = torch.index_select(node, 0, edge_index[0])\n",
    "        edge    = self.encoder(edge).view(-1,node_dim,node_dim)\n",
    "        #message = x_i.view(-1,node_dim,1)*edge\n",
    "        #message = message.sum(1)\n",
    "        message = x_i.view(-1,1,node_dim)@edge\n",
    "        message = message.view(-1,node_dim)\n",
    "        message = scatter_('mean', message, edge_index[1], dim_size=num_node)\n",
    "        message = F.relu(message +self.bias)\n",
    "\n",
    "        #2. update: n_j = f(n_j, m_j)\n",
    "        update = message\n",
    "\n",
    "        #batch_first=True\n",
    "        update, hidden = self.gru(update.view(1,-1,node_dim), hidden)\n",
    "        update = update.view(-1,node_dim)\n",
    "\n",
    "        return update, hidden\n",
    "\n",
    "class Set2Set(torch.nn.Module):\n",
    "\n",
    "    def softmax(self, x, index, num=None):\n",
    "        x = x -  scatter_max(x, index, dim=0, dim_size=num)[0][index]\n",
    "        x = x.exp()\n",
    "        x = x / (scatter_add(x, index, dim=0, dim_size=num)[index] + 1e-16)\n",
    "        return x\n",
    "\n",
    "    def __init__(self, in_channel, processing_step=1):\n",
    "        super(Set2Set, self).__init__()\n",
    "        num_layer = 1\n",
    "        out_channel = 2 * in_channel\n",
    "\n",
    "        self.processing_step = processing_step\n",
    "        self.in_channel  = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.num_layer   = num_layer\n",
    "        self.lstm = torch.nn.LSTM(out_channel, in_channel, num_layer)\n",
    "        self.lstm.reset_parameters()\n",
    "\n",
    "    def forward(self, x, batch_index):\n",
    "        batch_size = batch_index.max().item() + 1\n",
    "\n",
    "        h = (x.new_zeros((self.num_layer, batch_size, self.in_channel)),\n",
    "             x.new_zeros((self.num_layer, batch_size, self.in_channel)))\n",
    "\n",
    "        q_star = x.new_zeros(batch_size, self.out_channel)\n",
    "        for i in range(self.processing_step):\n",
    "            q, h = self.lstm(q_star.unsqueeze(0), h)\n",
    "            q = q.view(batch_size, -1)\n",
    "\n",
    "            e = (x * q[batch_index]).sum(dim=-1, keepdim=True) #shape = num_node x 1\n",
    "            a = self.softmax(e, batch_index, num=batch_size)   #shape = num_node x 1\n",
    "            r = scatter_add(a * x, batch_index, dim=0, dim_size=batch_size) #apply attention #shape = batch_size x ...\n",
    "            q_star = torch.cat([q, r], dim=-1)\n",
    "\n",
    "        return q_star\n",
    "\n",
    "#message passing\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, node_dim=13, edge_dim=5, num_target=8):\n",
    "        super(Net, self).__init__()\n",
    "        self.num_propagate = 6\n",
    "        self.num_s2s = 6\n",
    "\n",
    "        self.preprocess = nn.Sequential(\n",
    "            LinearBn(node_dim, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            LinearBn(128, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.propagate = GraphConv(128, edge_dim)\n",
    "        self.set2set = Set2Set(128, processing_step=self.num_s2s)\n",
    "\n",
    "\n",
    "        #predict coupling constant\n",
    "        self.predict = nn.Sequential(\n",
    "            LinearBn(4*128, 1024),  #node_hidden_dim\n",
    "            nn.ReLU(inplace=True),\n",
    "            LinearBn( 1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, num_target),\n",
    "        )\n",
    "\n",
    "    def forward(self, node, edge, edge_index, node_index, coupling_index):\n",
    "\n",
    "        num_node, node_dim = node.shape\n",
    "        num_edge, edge_dim = edge.shape\n",
    "\n",
    "        node   = self.preprocess(node)\n",
    "        hidden = node.view(1,num_node,-1)\n",
    "\n",
    "        for i in range(self.num_propagate):\n",
    "            node, hidden =  self.propagate(node, edge_index, edge, hidden)\n",
    "\n",
    "        pool = self.set2set(node, node_index)\n",
    "\n",
    "        #---\n",
    "        num_coupling = len(coupling_index)\n",
    "        coupling_atom0_index, coupling_atom1_index, coupling_type_index, coupling_batch_index = torch.split(coupling_index,1,dim=1)\n",
    "\n",
    "        pool  = torch.index_select( pool, dim=0, index=coupling_batch_index.view(-1))\n",
    "        node0 = torch.index_select( node, dim=0, index=coupling_atom0_index.view(-1))\n",
    "        node1 = torch.index_select( node, dim=0, index=coupling_atom1_index.view(-1))\n",
    "\n",
    "        predict = self.predict(torch.cat([pool,node0,node1],-1))\n",
    "        predict = torch.gather(predict, 1, coupling_type_index).view(-1)\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import scatter_\n",
    "from torch_scatter import *\n",
    "\n",
    "\n",
    "def train(net, schduler, optimizer, train_loader, valid_loader, epochs = 200, verbose=0):\n",
    "    \n",
    "    start = timer()    \n",
    "    start_epoch= 0\n",
    "    start_iter = 0\n",
    "    iter_ = start_iter\n",
    "#     batch_size = 16\n",
    "\n",
    "    epoch_len = len(train_loader)\n",
    "    his = []\n",
    "    for epoch in range(start_epoch, epochs, 1):\n",
    "\n",
    "        epoch_loss = 0\n",
    "        for node, edge, edge_index, node_index, coupling_value, coupling_index, infor in train_loader:\n",
    "            \n",
    "            # learning rate schduler -------------\n",
    "            lr = schduler(iter_)\n",
    "            if lr<0 : break\n",
    "            adjust_learning_rate(optimizer, lr)\n",
    "            rate = get_learning_rate(optimizer)\n",
    "\n",
    "            # train  -------------\n",
    "            net.train()\n",
    "            node = node.cuda()\n",
    "            edge = edge.cuda()\n",
    "            edge_index = edge_index.cuda()\n",
    "            node_index = node_index.cuda()\n",
    "            coupling_value = coupling_value.cuda()\n",
    "            coupling_index = coupling_index.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predict = net(node, edge, edge_index, node_index, coupling_index)\n",
    "            # update loss\n",
    "            loss = criterion(predict, coupling_value)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print statistics  ------------\n",
    "            epoch_loss += loss.item()\n",
    "            iter_ += 1\n",
    "            \n",
    "            if verbose > 0:\n",
    "                print(time_to_str((timer() - start),'min'), f'iter_:{iter_}/{epoch_len}', f'loss {loss.item():.4}', end='',flush=True)\n",
    "                print('\\r',end='',flush=True)\n",
    "                \n",
    "        valid_loss = do_valid(net, valid_loader)\n",
    "        epoch_loss /= len(train_loader)\n",
    "        \n",
    "        d_ = {'epoch':epoch, 'rate':rate,'loss':epoch_loss,'val_loss_1JHC':valid_loss[0],'val_loss_2JHC':valid_loss[1]}\n",
    "        d_ = {'val_loss_3JHC':valid_loss[2], 'val_loss_1JHN':valid_loss[3], 'val_loss_2JHN':valid_loss[4], 'val_loss_3JHN':valid_loss[5], 'val_loss_2JHH':valid_loss[6], **d_}\n",
    "        d_ = {'val_loss_3JHH':valid_loss[7], 'val_loss':valid_loss[8], 'val_mae':valid_loss[9], 'val_logmae':valid_loss[10], **d_}\n",
    "        his.append(d_)\n",
    "        if verbose > 0:\n",
    "            time_ = time_to_str((timer() - start),'min')\n",
    "            print(f'time {time_}, epoch {epoch} rate {rate} loss {epoch_loss:.4} val_loss {valid_loss[10]:.4}')\n",
    "    return his\n",
    "\n",
    "def do_valid(net, valid_loader):\n",
    "\n",
    "    valid_num = 0\n",
    "    valid_predict = []\n",
    "    valid_coupling_type  = []\n",
    "    valid_coupling_value = []\n",
    "\n",
    "    valid_loss = 0\n",
    "    for b, (node, edge, edge_index, node_index, coupling_value, coupling_index, infor) in enumerate(valid_loader):\n",
    "\n",
    "        net.eval()\n",
    "        node = node.cuda()\n",
    "        edge = edge.cuda()\n",
    "        edge_index = edge_index.cuda()\n",
    "        node_index = node_index.cuda()\n",
    "\n",
    "        coupling_value = coupling_value.cuda()\n",
    "        coupling_index = coupling_index.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predict = net(node, edge, edge_index, node_index, coupling_index)\n",
    "            loss = criterion(predict, coupling_value)\n",
    "\n",
    "        valid_predict.append(predict.data.cpu().numpy())\n",
    "        valid_coupling_type.append(coupling_index[:,2].data.cpu().numpy())\n",
    "        valid_coupling_value.append(coupling_value.data.cpu().numpy())\n",
    "\n",
    "        valid_loss += loss.item()\n",
    "        pass\n",
    "\n",
    "    valid_loss /= len(valid_loader)\n",
    "\n",
    "    #compute\n",
    "    predict = np.concatenate(valid_predict)\n",
    "    coupling_value = np.concatenate(valid_coupling_value)\n",
    "    coupling_type  = np.concatenate(valid_coupling_type).astype(np.int32)\n",
    "    mae, log_mae   = compute_kaggle_metric( predict, coupling_value, coupling_type,)\n",
    "\n",
    "    num_target = NUM_COUPLING_TYPE\n",
    "    for t in range(NUM_COUPLING_TYPE):\n",
    "        if mae[t] is None:\n",
    "            mae[t] = 0\n",
    "            log_mae[t]  = 0\n",
    "            num_target -= 1\n",
    "    mae_mean, log_mae_mean = np.sum(mae)/num_target, np.sum(log_mae)/num_target\n",
    "    valid_loss_detail = log_mae + [valid_loss, mae_mean, log_mae_mean]\n",
    "    \n",
    "    return valid_loss_detail\n",
    "\n",
    "def predict(test_loader):\n",
    "    valid_num = 0\n",
    "    valid_predict = []\n",
    "    valid_coupling_type  = []\n",
    "    valid_coupling_value = []\n",
    "\n",
    "    valid_loss = 0\n",
    "    df_pred = pd.DataFrame()\n",
    "    for b, (node, edge, edge_index, node_index, coupling_value, coupling_index, infor) in enumerate(test_loader):\n",
    "\n",
    "        #if b==5: break\n",
    "        net.eval()\n",
    "        node = node.cuda()\n",
    "        edge = edge.cuda()\n",
    "        edge_index = edge_index.cuda()\n",
    "        node_index = node_index.cuda()\n",
    "\n",
    "        coupling_value = coupling_value.cuda()\n",
    "        coupling_index = coupling_index.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predict = net(node, edge, edge_index, node_index, coupling_index)\n",
    "        df_pred_i = pd.DataFrame({'id':infor[0][2], 'scalar_coupling_constant':predict.cpu().detach().numpy() })\n",
    "        df_pred = pd.concat([df_pred, df_pred_i], axis=0)\n",
    "    return df_pred\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def get_learning_rate(optimizer):\n",
    "    lr=[]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr +=[ param_group['lr'] ]\n",
    "\n",
    "    assert(len(lr)==1) #we support only one param_group\n",
    "    lr = lr[0]\n",
    "\n",
    "    return lr\n",
    "\n",
    "def criterion(predict, truth):\n",
    "    predict = predict.view(-1)\n",
    "    truth   = truth.view(-1)\n",
    "    assert(predict.shape==truth.shape)\n",
    "\n",
    "    loss = torch.abs(predict-truth)\n",
    "    loss = loss.mean()\n",
    "    loss = torch.log(loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def criterion_mae(predict, truth):\n",
    "    predict = predict.view(-1)\n",
    "    truth   = truth.view(-1)\n",
    "    assert(predict.shape==truth.shape)\n",
    "\n",
    "    loss = torch.abs(predict-truth)\n",
    "    loss = loss.mean()\n",
    "#     loss = torch.log(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 hr 18 min iter_:2640/4250 loss -0.6502\r"
     ]
    }
   ],
   "source": [
    "batch_size=16\n",
    "node_dim = 93\n",
    "edge_dim =  6\n",
    "num_target = 8\n",
    "cache_folder = ''\n",
    "net_file = 'net'\n",
    "opt_file = 'opt'\n",
    "\n",
    "test_dataset = ChampsDataset(molecule_names=molecule_names_test, graph_file=graph_dir , csv='train', mode ='train', split=None, augment=None)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, sampler=RandomSampler(test_dataset), drop_last=True, num_workers=16, pin_memory=True, collate_fn=null_collate)\n",
    "\n",
    "trial = []\n",
    "\n",
    "cv = KFold(n_splits= 5, shuffle= True, random_state= 42)\n",
    "splits = cv.split(train_molecule_names) \n",
    "for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "    \n",
    "    train_molecule_names_nkfold = [train_molecule_names[i] for i in train_index]\n",
    "    valid_molecule_names_nkfold = [train_molecule_names[i] for i in valid_index]\n",
    "    train_dataset = ChampsDataset(molecule_names=train_molecule_names_nkfold, graph_file=graph_dir , csv='train', mode ='train', split=None, augment=None)\n",
    "    valid_dataset = ChampsDataset(molecule_names=valid_molecule_names_nkfold, graph_file=graph_dir , csv='train', mode ='train', split=None, augment=None)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=RandomSampler(train_dataset), drop_last=True, num_workers=16, pin_memory=True, collate_fn=null_collate)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, sampler=RandomSampler(valid_dataset), drop_last=True, num_workers=16, pin_memory=True, collate_fn=null_collate)\n",
    "    \n",
    "    net = Net(node_dim=node_dim,edge_dim=edge_dim, num_target=num_target).cuda()\n",
    "    if type(net_file)!=type(None):\n",
    "        net.load_state_dict(torch.load('net', map_location=lambda storage, loc: storage))\n",
    "    schduler = NullScheduler(lr=0.001)\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()),lr=schduler(0))\n",
    "    if type(opt_file)!=type(None):\n",
    "        checkpoint  = torch.load('opt')\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        \n",
    "    his = train(net, schduler, optimizer, train_loader, valid_loader, verbose = 1)\n",
    "    if type(test_loader) != type(None):\n",
    "        df_pred = predict(test_loader).sort_values(by=['id']).reset_index(drop=True)\n",
    "    torch.save(net.state_dict(),f'net{fold_n}')\n",
    "    torch.save({'optimizer': optimizer.state_dict()}, f'opt{fold_n}')\n",
    "    \n",
    "    trial.append({'df_pred':df_pred, 'train_his':his})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv('../../data/submission/submission_gnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_gpu_p36)",
   "language": "python",
   "name": "conda_tensorflow_gpu_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
