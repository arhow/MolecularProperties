{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "   div#notebook-container    { width: 95%; }\n",
       "   div#menubar-container     { width: 65%; }\n",
       "   div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "   div#notebook-container    { width: 95%; }\n",
    "   div#menubar-container     { width: 65%; }\n",
    "   div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\") # Adds higher directory to python modules path.\n",
    "from utilities import aggregate_feature_calculators\n",
    "from utilities import aggregate_feature_calculators_setting as aggcal\n",
    "from utilities.parallel import Parallel\n",
    "from utilities.dfdb import DFDB\n",
    "\n",
    "from utilities.process.pqueue import *\n",
    "from utilities.process.pnode import *\n",
    "from utilities.process.putilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import copy\n",
    "import gc\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "import optuna\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold,TimeSeriesSplit, GroupKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_folder =  '../../data/input'\n",
    "\n",
    "file_folder =  '../../data/feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train2 = pd.read_pickle(f'{file_folder}/df_train2.gzde', compression='gzip')\n",
    "# df_train2_plus = pd.read_pickle(f'{file_folder}/df_train2_plus.gzde', compression='gzip')\n",
    "# df_train2_plus = df_train2_plus.rename(columns={'id':'index'})\n",
    "\n",
    "# df_train2 = df_train2[df_train2['type']==0]\n",
    "# df_train2 = pd.merge(df_train2, df_train2_plus, how='left', on='index')\n",
    "# df_train2.to_pickle('tmp_df_train', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2 = df_train2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mytrial = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2['y'] = df_train2['scalar_coupling_constant']\n",
    "\n",
    "param = {\n",
    "    'columns': df_train2.columns.drop(['index', 'y','group', 'scalar_coupling_constant', 'fc', 'sd','pso','dso']).tolist(),\n",
    "    'cv': {\n",
    "        'cls': 'KFold',\n",
    "        'init':{\n",
    "            'n_splits': 5,\n",
    "            'shuffle': True,\n",
    "            'random_state': 42,\n",
    "        },\n",
    "    },\n",
    "    'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}},\n",
    "    'model': {\n",
    "        'cls': 'lgb.LGBMRegressor',\n",
    "        'init': {\n",
    "            'learning_rate': 0.2833769330240482,\n",
    "            'feature_fraction': 0.8818248470204605,\n",
    "            'bagging_fraction': 0.8205197060908092,\n",
    "            'min_data_in_leaf': 202,\n",
    "            'lambda_l1': 0.017039063121824582,\n",
    "            'lambda_l2': 0.8318702431636841,\n",
    "            'max_bin': 100,\n",
    "            'num_leaves': 255,\n",
    "            'random_state': 3895,\n",
    "            'n_estimators':1500,\n",
    "            'n_jobs': 16\n",
    "        },\n",
    "        'fit': {}\n",
    "    },\n",
    "    'metric': 'mean_absolute_error'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "process_queue = PQueue(df_train2, None, param, mytrial)\n",
    "sort_features = SortFeatureSelectTopNProcess(**{'top_n':200})\n",
    "select_topn = RFESelectTopNProcess(**{'n_features_remain':50, 'n_features_to_remove':10})\n",
    "# remove_useless = RFERemoveUselessFeaturesProcess(**{})\n",
    "process_queue.insert_node(sort_features)\n",
    "process_queue.insert_node(select_topn)\n",
    "# process_queue.insert_node(remove_useless)\n",
    "\n",
    "try:\n",
    "    result = process_queue.run()\n",
    "except Exception as e:\n",
    "    print(e.__str__())\n",
    "print(len(process_queue.trial))\n",
    "print(process_queue.param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'columns': df_train2.columns.drop(['index', 'y','group', 'scalar_coupling_constant', 'fc', 'sd','pso','dso']).tolist(),\n",
    "    'cv': {\n",
    "        'cls': 'GroupKFold',\n",
    "        'init':{\n",
    "            'n_splits': 5,\n",
    "#             'shuffle': True,\n",
    "#             'random_state': 42,\n",
    "        },\n",
    "    },\n",
    "    'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}},\n",
    "    'model': {\n",
    "        'cls': 'lgb.LGBMRegressor',\n",
    "        'init': {\n",
    "            'learning_rate': 0.2833769330240482,\n",
    "            'feature_fraction': 0.8818248470204605,\n",
    "            'bagging_fraction': 0.8205197060908092,\n",
    "            'min_data_in_leaf': 202,\n",
    "            'lambda_l1': 0.017039063121824582,\n",
    "            'lambda_l2': 0.8318702431636841,\n",
    "            'max_bin': 100,\n",
    "            'num_leaves': 255,\n",
    "            'random_state': 3895,\n",
    "            'n_estimators':1500,\n",
    "            'n_jobs': 16\n",
    "        },\n",
    "        'fit': {}\n",
    "    },\n",
    "    'metric': 'mean_absolute_error'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "process_queue = PQueue(df_train2, None, param, mytrial)\n",
    "sort_features = SortFeatureSelectTopNProcess(**{'top_n':200})\n",
    "select_topn = RFESelectTopNProcess(**{'n_features_remain':50, 'n_features_to_remove':10})\n",
    "# remove_useless = RFERemoveUselessFeaturesProcess(**{})\n",
    "process_queue.insert_node(sort_features)\n",
    "process_queue.insert_node(select_topn)\n",
    "# process_queue.insert_node(remove_useless)\n",
    "\n",
    "try:\n",
    "    result = process_queue.run()\n",
    "except Exception as e:\n",
    "    print(e.__str__())\n",
    "print(len(process_queue.trial))\n",
    "print(process_queue.param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=scalar_coupling_constant, type=7\n",
      "211\n",
      "{'columns': ['dist_to_type_1_mean', 'cos_f0', 'dist_O_0_x', 'atom_1_bond_lengths_min', 'd_5_2', 'cos_c1', 'd_2_1', 'molecule_atom_index_0_dist_min_div', 'atom_index_1_cycle_size_mean', 'd_4_2', 'inv_distPR', 'dist_N_0_x', 'dist_O_0_y', 'adC1', 'adC2', 'tertiary_angle_2', 'dist_C_2_y', 'molecule_atom_index_0_dist_std_diff', 'dist_C_2_x', 'dist_C_3_y', 'd_4_3', 'eem_1', 'molecule_atom_index_1_dist_min_diff', 'atom_1_bond_lengths_mean', 'tertiary_angle_1', 'inv_dist0R', 'd_4_0', 'd_4_1', 'mean_molecule_atom_0_dist_xyz', 'd_2_0', 'd_3_1', 'dist_C_1_x', 'dist_H_0_y', 'dist_C_0_y', 'd_5_3', 'tertiary_distance_3', 'd_3_2', 'dist_H_1_x', 'tertiary_distance_1', 'atom_1_n_bonds', 'd_8_3', 'cos_c0', 'tertiary_distance_2', 'tertiary_angle_0', 'cos_c0_c1', 'molecule_atom_index_0_dist_min_diff', 'yukawa_H.y'], 'cv': {'cls': 'KFold', 'init': {'n_splits': 3, 'shuffle': True, 'random_state': 42}}, 'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}}, 'model': {'cls': 'lgb.LGBMRegressor', 'init': {'learning_rate': 0.2833769330240482, 'feature_fraction': 0.8818248470204605, 'bagging_fraction': 0.8205197060908092, 'min_data_in_leaf': 202, 'lambda_l1': 0.017039063121824582, 'lambda_l2': 0.8318702431636841, 'max_bin': 100, 'num_leaves': 255, 'random_state': 3895, 'n_jobs': 16}, 'fit': {}}, 'metric': 'mean_absolute_error'}\n",
      "y=fc, type=7\n",
      "366\n",
      "{'columns': ['dist_to_type_1_mean', 'cos_f0', 'dist_O_0_x', 'atom_1_bond_lengths_min', 'd_5_2', 'cos_c1', 'd_2_1', 'molecule_atom_index_0_dist_min_div', 'atom_index_1_cycle_size_mean', 'd_4_2', 'inv_distPR', 'dist_N_0_x', 'dist_O_0_y', 'adC1', 'adC2', 'tertiary_angle_2', 'dist_C_2_y', 'dist_C_2_x', 'dist_C_3_y', 'd_4_3', 'eem_1', 'molecule_atom_index_1_dist_min_diff', 'atom_1_bond_lengths_mean', 'tertiary_angle_1', 'inv_dist0R', 'd_4_0', 'd_4_1', 'd_2_0', 'd_3_1', 'dist_C_1_x', 'dist_H_0_y', 'dist_C_0_y', 'd_5_3', 'tertiary_distance_3', 'd_3_2', 'dist_H_1_x', 'tertiary_distance_1', 'atom_1_n_bonds', 'd_8_3', 'cos_c0', 'tertiary_distance_2', 'tertiary_angle_0', 'cos_c0_c1', 'molecule_atom_index_0_dist_min_diff', 'yukawa_H.y'], 'cv': {'cls': 'KFold', 'init': {'n_splits': 3, 'shuffle': True, 'random_state': 42}}, 'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}}, 'model': {'cls': 'lgb.LGBMRegressor', 'init': {'learning_rate': 0.2833769330240482, 'feature_fraction': 0.8818248470204605, 'bagging_fraction': 0.8205197060908092, 'min_data_in_leaf': 202, 'lambda_l1': 0.017039063121824582, 'lambda_l2': 0.8318702431636841, 'max_bin': 100, 'num_leaves': 255, 'random_state': 3895, 'n_jobs': 16}, 'fit': {}}, 'metric': 'mean_absolute_error'}\n",
      "y=sd, type=7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-23506258793f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/MolecularProperties/utilities/process/pqueue.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_pnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/MolecularProperties/utilities/process/pqueue.py\u001b[0m in \u001b[0;36m_run_pnode\u001b[0;34m(self, pnode, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_pnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnext_node_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/MolecularProperties/utilities/process/pqueue.py\u001b[0m in \u001b[0;36m_run_pnode\u001b[0;34m(self, pnode, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_pnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnext_node_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/MolecularProperties/utilities/process/pqueue.py\u001b[0m in \u001b[0;36m_run_pnode\u001b[0;34m(self, pnode, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_pnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnext_node_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/MolecularProperties/utilities/process/pqueue.py\u001b[0m in \u001b[0;36m_run_pnode\u001b[0;34m(self, pnode, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mpnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}-{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mnext_node_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/MolecularProperties/utilities/process/pnode.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, df_train, df_test, param, trial, score, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mwidth_frist_rfe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mdf_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_trial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_trial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_metric_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'param'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/MolecularProperties/utilities/process/process.py\u001b[0m in \u001b[0;36mwidth_frist_rfe\u001b[0;34m(df_train, param, trial, score, message, df_test)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mparam_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mdf_his\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_feature_importances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_valid_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msk_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_output_feature_importance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mval_mae_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_his\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval_mae_mean\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/MolecularProperties/utilities/process/process.py\u001b[0m in \u001b[0;36msk_process\u001b[0;34m(df_train, param, message, df_test, trial, is_output_feature_importance, trial_level)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0my_valid_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0moriginal_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m                              % (self._n_features, n_features))\n\u001b[1;32m    606\u001b[0m         return self.booster_.predict(X, raw_score=raw_score, num_iteration=num_iteration,\n\u001b[0;32m--> 607\u001b[0;31m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[1;32m   2201\u001b[0m         return predictor.predict(data, num_iteration,\n\u001b[1;32m   2202\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m                                  data_has_header, is_reshape)\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[0;34m(self, mat, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__pred_for_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[0;34m(mat, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m    536\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_parameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_num_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m                 preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_preds\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mout_num_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length for predict results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# , 'fc', 'sd','pso','dso'\n",
    "for y in ['scalar_coupling_constant', 'fc', 'sd','pso','dso']:\n",
    "\n",
    "    for t in np.arange(0,8,1):\n",
    "        \n",
    "        print(f'y={y}, type={t}')\n",
    "        df_train=pd.read_pickle('tmp_df_train', compression='gzip')\n",
    "#         df_test=pd.read_pickle(f'{file_folder}/df_test.gzde', compression='gzip')\n",
    "        \n",
    "        df_train['y'] = df_train[y]\n",
    "        df_train = df_train[df_train['type']==t]\n",
    "        n_samples = 500000 if df_train.shape[0] > 500000 else df_train.shape[0]\n",
    "        df_train = df_train.sample(n_samples).reset_index(drop=True)\n",
    "#         df_test = df_test[df_test['type']==t].reset_index(drop=True)\n",
    "        df_test = pd.DataFrame()\n",
    "        \n",
    "\n",
    "        param = {\n",
    "            'columns': df_train.columns.drop(['index', 'y','group', 'scalar_coupling_constant', 'fc', 'sd','pso','dso']).tolist(),\n",
    "            'cv': {\n",
    "                'cls': 'KFold',\n",
    "                'init':{\n",
    "                    'n_splits': 5,\n",
    "                    'shuffle': True,\n",
    "                    'random_state': 42,\n",
    "                },\n",
    "            },\n",
    "            'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}},\n",
    "            'model': {\n",
    "                'cls': 'lgb.LGBMRegressor',\n",
    "                'init': {\n",
    "                    'learning_rate': 0.2833769330240482,\n",
    "                    'feature_fraction': 0.8818248470204605,\n",
    "                    'bagging_fraction': 0.8205197060908092,\n",
    "                    'min_data_in_leaf': 202,\n",
    "                    'lambda_l1': 0.017039063121824582,\n",
    "                    'lambda_l2': 0.8318702431636841,\n",
    "                    'max_bin': 100,\n",
    "                    'num_leaves': 255,\n",
    "                    'random_state': 3895,\n",
    "#                     'n_estimators':1500,\n",
    "                    'n_jobs': 16\n",
    "                    \n",
    "#                     'boosting_type': 'gbdt',\n",
    "#                     'learning_rate': 0.2,\n",
    "#                     'num_leaves': 256,\n",
    "#                     'min_child_samples': 79,\n",
    "#                     'max_depth': 9,\n",
    "#                     'subsample_freq': 1,\n",
    "#                     'subsample': 0.9,\n",
    "#                     'bagging_seed': 11,\n",
    "#                     'reg_alpha': 0.1,\n",
    "#                     'reg_lambda': 0.3,\n",
    "#                     'colsample_bytree': 1.0\n",
    "                },\n",
    "                'fit': {}\n",
    "            },\n",
    "            'metric': 'mean_absolute_error'\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "        process_queue = PQueue(df_train, df_test, param, mytrial)\n",
    "        sort_features = SortFeatureSelectTopNProcess(**{'top_n':200})\n",
    "        select_topn = RFESelectTopNProcess(**{'n_features_remain':50, 'n_features_to_remove':10})\n",
    "        remove_useless = RFERemoveUselessFeaturesProcess(**{})\n",
    "        process_queue.insert_node(sort_features)\n",
    "        process_queue.insert_node(select_topn)\n",
    "        process_queue.insert_node(remove_useless)\n",
    "\n",
    "        try:\n",
    "            result = process_queue.run()\n",
    "        except Exception as e:\n",
    "            print(e.__str__())\n",
    "        print(len(process_queue.trial))\n",
    "        print(process_queue.param)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "        \n",
    "    learning_rate = trial.suggest_uniform('learning_rate', .01, .5)\n",
    "    feature_fraction = trial.suggest_uniform('feature_fraction', .6, 1)\n",
    "    bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.6, 1)\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 200, 800)\n",
    "    lambda_l1 = trial.suggest_loguniform('lambda_l1', 1e-6, 1e2)\n",
    "    lambda_l2 = trial.suggest_loguniform('lambda_l2', 1e-6, 1e2)\n",
    "    max_bin = trial.suggest_int('max_bin', 10, 100)\n",
    "    num_leaves = trial.suggest_int('num_leaves', 4, 512)\n",
    "        \n",
    "    args = columns_list[t].copy()\n",
    "    args['model']['init']={\n",
    "                'learning_rate':learning_rate,\n",
    "                'feature_fraction':feature_fraction,\n",
    "                'bagging_fraction':bagging_fraction,\n",
    "                'min_data_in_leaf':min_data_in_leaf,\n",
    "                'lambda_l1':lambda_l1,\n",
    "                'lambda_l2':lambda_l2,\n",
    "                'max_bin':max_bin,\n",
    "                'num_leaves':num_leaves,\n",
    "                'n_jobs':16\n",
    "    }\n",
    "    \n",
    "    df_his, df_feature_importances, df_valid_pred, df_test_pred =  sk_process(df_train[df_train['type']==t].reset_index(drop=True), args, f'modeling for {t}', df_test=None, trial=mytrial, is_output_feature_importance=False, trial_level=1)\n",
    "    val_metric_mean = np.mean(df_his.valid)\n",
    "    return val_metric_mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_trial = pd.DataFrame(mytrial)\n",
    "# df_trial[df_trial['message']=='tune hyperparam'][['datetime', 'message', 'nfeatures', 'train_metric_mean', 'val_metric_mean', 'trn_val_metric_diff']].sort_values(by=['val_metric_mean']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train=pd.read_pickle(f'{file_folder}/df_train.gzde', compression='gzip')\n",
    "# df_test=pd.read_pickle(f'{file_folder}/df_test.gzde', compression='gzip')\n",
    "# df_train['y'] = df_train['scalar_coupling_constant']\n",
    "\n",
    "\n",
    "df_train=pd.read_pickle(f'{file_folder}/tmp_df_train', compression='gzip')\n",
    "df_test=pd.read_pickle(f'{file_folder}/tmp_df_test', compression='gzip')\n",
    "df_train['y'] = df_train['scalar_coupling_constant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{csv_file_folder}/train.csv')\n",
    "train['molecule_index'] = train['molecule_name'].str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "\n",
    "df_add_structures = pd.read_pickle(f'{file_folder}/struct_eigen.pkl', compression='gzip') \n",
    "df_add_structures['molecule_index'] = df_add_structures['molecule_name'].str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "df_add_structures = df_add_structures.drop(columns=['molecule_name'])\n",
    "def _map_atom_charges(df, structures, atom_idx):\n",
    "    df = pd.merge(df, structures, how = 'left', left_on  = ['molecule_index', f'atom_index_{atom_idx}'], right_on = ['molecule_index',  'atom_index'])\n",
    "    df = df.drop('atom_index', axis=1)\n",
    "    rename_list = {}\n",
    "    for col in structures.columns.drop(['molecule_index',  'atom_index']).tolist():\n",
    "        rename_list[col] = f'atom_index_{atom_idx}_{col}'\n",
    "    df = df.rename(columns=rename_list)\n",
    "    return df\n",
    "\n",
    "df_add = _map_atom_charges(train[['molecule_index', 'atom_index_0','atom_index_1']], df_add_structures, 0)\n",
    "df_add = _map_atom_charges(df_add, df_add_structures, 1)\n",
    "df_add = df_add.fillna(0)\n",
    "df_add['index'] = df_add.index\n",
    "df_add = df_add.drop(columns=['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "\n",
    "del train\n",
    "del df_add_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, df_add , how='left', on='index')\n",
    "add_columns = df_add.columns.drop(['index']).tolist()\n",
    "del df_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_columns = df_add.columns.drop(['index']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_file_folder =  '../../data/oof'\n",
    "# print([f for f in os.listdir(oof_file_folder) if f.startswith('lgbm')])\n",
    "# df_oof_train = pd.DataFrame()\n",
    "# df_oof_test = pd.DataFrame()\n",
    "# for f in [f for f in os.listdir(oof_file_folder) if f.startswith('lgbm')]:\n",
    "#     feat_name = f.split('_')[1]\n",
    "#     if 'train' in f:\n",
    "#         df_oof_i = pd.read_pickle(f'{oof_file_folder}/{f}')[['id', feat_name]].rename(columns={'id':'index', feat_name:f'oof_{feat_name}'})\n",
    "#         df_oof_train = pd.concat([df_oof_train, df_oof_i], axis=1)\n",
    "#     if 'test' in f:\n",
    "#         df_oof_i = pd.read_pickle(f'{oof_file_folder}/{f}')[['id', feat_name]].rename(columns={'id':'index', feat_name:f'oof_{feat_name}'})\n",
    "#         df_oof_test = pd.concat([df_oof_test, df_oof_i], axis=1)\n",
    "\n",
    "# df_train = pd.concat([df_train, df_oof_train[['oof_sd','oof_fc','oof_pso','oof_dso']]], axis=1)\n",
    "# df_test = pd.concat([df_test, df_oof_test[['oof_sd','oof_fc','oof_pso','oof_dso']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = [\n",
    "{'columns': add_columns + ['tertiary_distance_2', 'dist_H_2_y', 'dist_H_0_y', 'distC0', 'inv_dist1R', 'dist_C_2_x', 'dist_to_type_std', 'dist_C_2_y', 'dist_C_0_x', 'atom_1_n_bonds', 'd_5_1', 'yukawa_H.y', 'd_4_1', 'd_4_2', 'd_4_3', 'd_3_0', 'dist_H_2_x', 'd_4_0', 'tertiary_distance_4', 'tertiary_angle_1', 'd_3_1', 'dist_H_1_y', 'coulomb_H.y', 'dist_C_4_x', 'atom_index_farthest_0', 'distance_farthest_0', 'tertiary_angle_2', 'distance_c1', 'atom_1_bond_lengths_std', 'inv_dist0R', 'eem_0', 'inv_distPR', 'dist_N_0_y', 'dist_H_3_x', 'distC1', 'tertiary_atom_0', 'dist_H_1_x', 'dist_C_0_y', 'adC1', 'max_distance_y', 'tertiary_distance_5', 'dist_to_type_0_mean', 'atom_1_bond_lengths_mean', 'd_1_0', 'dist_O_1_y', 'tertiary_angle_0', 'yukawa_N.x', 'dist_C_4_y', 'atom_index_1_cycle_size_mean', 'tertiary_atom_1', 'inv_dist1', 'd_2_1', 'dist_C_1_y', 'adC2', 'inv_dist1E', 'molecule_atom_index_1_dist_min_diff', 'dist_to_type_1_mean', 'dist_to_type_mean', 'adC3', 'dist_O_0_y', 'eem_1', 'adN1', 'tertiary_distance_3', 'dist_N_0_x', 'molecule_atom_index_0_dist_max_div', 'dist_O_1_x', 'dist_C_3_y', 'tertiary_angle_3', 'cos_f0', 'd_3_2', 'dist_O_0_x', 'dist_H_3_y', 'dist_C_3_x', 'tertiary_angle_4'], 'cv': {'cls': 'KFold', 'init': {'n_splits': 5, 'shuffle': True, 'random_state': 42}}, 'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}}, 'model': {'cls': 'lgb.LGBMRegressor', 'init': {'learning_rate': 0.2833769330240482, 'feature_fraction': 0.8818248470204605, 'bagging_fraction': 0.8205197060908092, 'min_data_in_leaf': 202, 'lambda_l1': 0.017039063121824582, 'lambda_l2': 0.8318702431636841, 'max_bin': 100, 'num_leaves': 255, 'random_state': 3895, 'n_estimators':3000, 'n_jobs': 16}, 'fit': {}}, 'metric': 'mean_absolute_error'},\n",
    "{'columns': add_columns + ['yukawa_N.x', 'inv_distPR', 'molecule_atom_index_0_dist_mean_div', 'dist_C_0_y', 'dist_N_1_x', 'dist_C_1_x', 'd_4_1', 'molecule_atom_1_dist_min_diff', 'dist_N_0_y', 'cos_f1', 'dist_O_0_x', 'tertiary_distance_5', 'vander_N.x', 'dist_C_3_x', 'coulomb_H.x', 'dist_C_3_y', 'd_9_2', 'distance_center0', 'd_3_2', 'd_5_2', 'dist_C_2_x', 'dist_to_type_0_mean', 'dist_N_0_x', 'dist_O_0_y', 'd_4_3', 'dist_H_1_x', 'atom_1_bond_lengths_max', 'atom_1_bond_lengths_std', 'd_3_1', 'dist_H_3_y', 'tertiary_distance_1', 'molecule_atom_index_0_dist_max_div', 'inv_distP', 'tertiary_angle_3', 'tertiary_distance_0', 'linkN', 'd_2_0', 'd_4_2', 'd_5_3', 'dist_to_type_std', 'd_4_0', 'd_3_0', 'dist_H_0_y', 'dist_C_0_x', 'tertiary_angle_0', 'dist_N_1_y', 'adC3', 'inv_dist1R', 'dist_H_1_y', 'eem_1', 'dist_C_1_y', 'tertiary_distance_3', 'd_2_1', 'dist_H_2_y', 'tertiary_distance_4', 'link0', 'tertiary_angle_2', 'd_1_0', 'dist_C_2_y', 'tertiary_atom_0', 'yukawa_H.y', 'molecule_name.1', 'distance_c1', 'inv_dist0R', 'max_molecule_atom_0_dist_xyz', 'atom_1_bond_lengths_mean', 'cos_center0', 'cos_center0_center1', 'inv_dist1', 'eem_0', 'vander_H.x', 'tertiary_distance_2', 'dist_C_4_x', 'distN0', 'dist_H_0_x', 'max_distance_y', 'cos_f0'], 'cv': {'cls': 'KFold', 'init': {'n_splits': 5, 'shuffle': True, 'random_state': 42}}, 'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}}, 'model': {'cls': 'lgb.LGBMRegressor', 'init': {'learning_rate': 0.2833769330240482, 'feature_fraction': 0.8818248470204605, 'bagging_fraction': 0.8205197060908092, 'min_data_in_leaf': 202, 'lambda_l1': 0.017039063121824582, 'lambda_l2': 0.8318702431636841, 'max_bin': 100, 'num_leaves': 255, 'random_state': 3895, 'n_estimators':3000, 'n_jobs': 16}, 'fit': {}}, 'metric': 'mean_absolute_error'},\n",
    "{'columns': add_columns + ['molecule_atom_index_1_dist_min_diff', 'tertiary_angle_1', 'dist_C_0_y', 'tertiary_atom_2', 'd_6_2', 'dist_C_1_x', 'atom_8', 'd_4_1', 'd_9_1', 'dist_N_0_y', 'cos_c1', 'd_7_0', 'dist_O_0_x', 'tertiary_distance_5', 'dist_C_3_x', 'dist_O_1_x', 'dist_C_3_y', 'd_7_2', 'd_3_2', 'd_5_2', 'd_6_0', 'dist_C_2_x', 'dist_N_0_x', 'dist_to_type_0_mean', 'molecule_atom_index_0_dist_max_diff', 'dist_O_0_y', 'd_4_3', 'dist_H_1_x', 'atom_1_bond_lengths_std', 'd_3_1', 'd_5_0', 'tertiary_distance_1', 'molecule_atom_index_0_dist_max_div', 'adC1', 'tertiary_angle_3', 'atom_4', 'tertiary_distance_0', 'd_2_0', 'atom_3', 'cos_c0_c1', 'd_4_2', 'd_5_3', 'd_4_0', 'd_6_3', 'd_3_0', 'dist_H_0_y', 'dist_C_0_x', 'adN1', 'bond_atom', 'd_8_2', 'tertiary_angle_0', 'distC0', 'adC3', 'inv_dist1R', 'd_8_1', 'd_7_1', 'eem_1', 'dist_C_1_y', 'tertiary_distance_3', 'atom_index_1_cycle_size_mean', 'inv_dist0', 'd_2_1', 'dist_H_2_y', 'atom_1_n_bonds', 'tertiary_angle_2', 'd_1_0', 'molecule_atom_index_0_dist_mean_diff', 'dist_C_2_y', 'tertiary_atom_1', 'vander_O.y', 'tertiary_atom_0', 'distC1', 'adC2', 'atom_7', 'max_molecule_atom_0_dist_xyz', 'atom_1_bond_lengths_mean', 'dist_C_4_y', 'd_5_1', 'molecule_type_dist_max', 'd_6_1', 'distance_farthest_0', 'molecule_atom_index_0_dist_min_div', 'tertiary_distance_2', 'atom_5', 'dist_H_0_x', 'cos_c0', 'cos_f0'], 'cv': {'cls': 'KFold', 'init': {'n_splits': 5, 'shuffle': True, 'random_state': 42}}, 'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}}, 'model': {'cls': 'lgb.LGBMRegressor', 'init': {'learning_rate': 0.2833769330240482, 'feature_fraction': 0.8818248470204605, 'bagging_fraction': 0.8205197060908092, 'min_data_in_leaf': 202, 'lambda_l1': 0.017039063121824582, 'lambda_l2': 0.8318702431636841, 'max_bin': 100, 'num_leaves': 255, 'random_state': 3895, 'n_estimators':3000, 'n_jobs': 16}, 'fit': {}}, 'metric': 'mean_absolute_error'},\n",
    "{'columns': add_columns + ['molecule_atom_index_0_dist_min_diff', 'inv_distPR', 'tertiary_angle_1', 'dist_C_0_y', 'tertiary_atom_2', 'd_6_2', 'dist_C_1_x', 'd_4_1', 'dist_N_0_y', 'cos_c1', 'dist_to_type_mean', 'yukawa_H.x', 'cos_f1', 'dist_O_0_x', 'dist_H_3_x', 'dist_C_3_x', 'dist_C_3_y', 'd_7_2', 'dist_O_1_y', 'd_3_2', 'd_5_2', 'dist_C_2_x', 'inv_distPE', 'dist_N_0_x', 'dist_to_type_0_mean', 'molecule_dist_min', 'dist_O_0_y', 'd_4_3', 'dist_to_type_1_mean', 'dist_H_1_x', 'd_3_1', 'dist_H_3_y', 'd_5_0', 'tertiary_distance_1', 'molecule_atom_index_0_dist_max_div', 'inv_distP', 'tertiary_angle_3', 'adC4', 'd_2_0', 'atom_3', 'cos_c0_c1', 'd_4_2', 'd_5_3', 'dist_to_type_std', 'd_4_0', 'd_6_3', 'd_3_0', 'dist_H_0_y', 'dist_C_0_x', 'adN1', 'tertiary_angle_0', 'yukawa_C.x', 'mean_molecule_atom_0_dist_xyz', 'adC3', 'dist_H_1_y', 'dist_H_2_x', 'dist_C_1_y', 'tertiary_distance_3', 'coulomb_H.y', 'd_2_1', 'dist_H_2_y', 'vander_H.y', 'link0', 'tertiary_distance_4', 'vander_C.x', 'tertiary_angle_2', 'd_1_0', 'dist_C_2_y', 'tertiary_atom_1', 'yukawa_H.y', 'dist_H_4_y', 'mean_molecule_atom_1_dist_xyz', 'adC2', 'd_5_1', 'molecule_type_dist_max', 'vander_N.y', 'distance_farthest_0', 'molecule_atom_index_0_dist_min_div', 'vander_H.x', 'tertiary_distance_2', 'atom_5', 'cos_c0', 'vander_O.x', 'cos_f0_f1', 'dist_H_0_x', 'max_distance_y', 'dist_xyz', 'cos_f0'], 'cv': {'cls': 'KFold', 'init': {'n_splits': 5, 'shuffle': True, 'random_state': 42}}, 'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}}, 'model': {'cls': 'lgb.LGBMRegressor', 'init': {'learning_rate': 0.2833769330240482, 'feature_fraction': 0.8818248470204605, 'bagging_fraction': 0.8205197060908092, 'min_data_in_leaf': 202, 'lambda_l1': 0.017039063121824582, 'lambda_l2': 0.8318702431636841, 'max_bin': 100, 'num_leaves': 255, 'random_state': 3895, 'n_estimators':3000, 'n_jobs': 16}, 'fit': {}}, 'metric': 'mean_absolute_error'},\n",
    "{'columns': add_columns + ['dist_C_1_y', 'dist_C_1_x', 'atom_3', 'dist_C_0_y', 'd_4_2', 'dist_H_0_x', 'min_molecule_atom_0_dist_xyz', 'd_4_0', 'd_3_0', 'd_5_3', 'cos_c0_c1', 'adC3', 'tertiary_distance_1', 'cos_c0', 'tertiary_distance_3', 'inv_distPR', 'dist_O_0_y', 'molecule_atom_index_1_dist_min_diff', 'tertiary_atom_1', 'd_5_0', 'd_6_3', 'adC2', 'vander_C.x', 'd_3_2', 'd_6_0', 'dist_N_0_x', 'dist_C_3_y', 'max_molecule_atom_0_dist_xyz', 'molecule_atom_index_0_dist_std_div', 'dist_C_0_x', 'molecule_atom_index_0_dist_min_div', 'tertiary_angle_0', 'inv_distP', 'd_4_3', 'dist_O_0_x', 'cos_f0', 'molecule_atom_index_0_dist_std_diff', 'yukawa_H.x', 'd_2_1', 'd_3_1', 'inv_dist0R', 'tertiary_distance_2', 'd_5_1', 'tertiary_atom_0', 'd_4_1', 'atom_1_bond_lengths_mean', 'inv_dist0', 'atom_1_bond_lengths_min'], 'cv': {'cls': 'KFold', 'init': {'n_splits': 5, 'shuffle': True, 'random_state': 42}}, 'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}}, 'model': {'cls': 'lgb.LGBMRegressor', 'init': {'learning_rate': 0.2833769330240482, 'feature_fraction': 0.8818248470204605, 'bagging_fraction': 0.8205197060908092, 'min_data_in_leaf': 202, 'lambda_l1': 0.017039063121824582, 'lambda_l2': 0.8318702431636841, 'max_bin': 100, 'num_leaves': 255, 'random_state': 3895, 'n_estimators':3000, 'n_jobs': 16}, 'fit': {}}, 'metric': 'mean_absolute_error'},\n",
    "{'columns': add_columns + ['dist_C_1_y', 'dist_C_1_x', 'atom_3', 'dist_C_0_y', 'd_4_2', 'dist_H_0_x', 'min_molecule_atom_0_dist_xyz', 'd_4_0', 'd_3_0', 'd_5_3', 'cos_c0_c1', 'adC3', 'tertiary_distance_1', 'cos_c0', 'tertiary_distance_3', 'inv_distPR', 'dist_O_0_y', 'molecule_atom_index_1_dist_min_diff', 'tertiary_atom_1', 'd_5_0', 'd_6_3', 'adC2', 'vander_C.x', 'd_3_2', 'd_6_0', 'dist_N_0_x', 'dist_C_3_y', 'max_molecule_atom_0_dist_xyz', 'molecule_atom_index_0_dist_std_div', 'dist_C_0_x', 'molecule_atom_index_0_dist_min_div', 'tertiary_angle_0', 'inv_distP', 'd_4_3', 'dist_O_0_x', 'cos_f0', 'molecule_atom_index_0_dist_std_diff', 'yukawa_H.x', 'd_2_1', 'd_3_1', 'inv_dist0R', 'tertiary_distance_2', 'd_5_1', 'tertiary_atom_0', 'd_4_1', 'atom_1_bond_lengths_mean', 'inv_dist0', 'atom_1_bond_lengths_min'], 'cv': {'cls': 'KFold', 'init': {'n_splits': 5, 'shuffle': True, 'random_state': 42}}, 'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}}, 'model': {'cls': 'lgb.LGBMRegressor', 'init': {'learning_rate': 0.2833769330240482, 'feature_fraction': 0.8818248470204605, 'bagging_fraction': 0.8205197060908092, 'min_data_in_leaf': 202, 'lambda_l1': 0.017039063121824582, 'lambda_l2': 0.8318702431636841, 'max_bin': 100, 'num_leaves': 255, 'random_state': 3895, 'n_estimators':3000, 'n_jobs': 16}, 'fit': {}}, 'metric': 'mean_absolute_error'},\n",
    "{'columns': add_columns + ['dist_C_1_y', 'dist_C_1_x', 'atom_3', 'dist_C_0_y', 'd_4_2', 'dist_H_0_x', 'min_molecule_atom_0_dist_xyz', 'd_4_0', 'd_3_0', 'd_5_3', 'cos_c0_c1', 'adC3', 'tertiary_distance_1', 'cos_c0', 'tertiary_distance_3', 'inv_distPR', 'dist_O_0_y', 'molecule_atom_index_1_dist_min_diff', 'tertiary_atom_1', 'd_5_0', 'd_6_3', 'adC2', 'vander_C.x', 'd_3_2', 'd_6_0', 'dist_N_0_x', 'dist_C_3_y', 'max_molecule_atom_0_dist_xyz', 'molecule_atom_index_0_dist_std_div', 'dist_C_0_x', 'molecule_atom_index_0_dist_min_div', 'tertiary_angle_0', 'inv_distP', 'd_4_3', 'dist_O_0_x', 'cos_f0', 'molecule_atom_index_0_dist_std_diff', 'yukawa_H.x', 'd_2_1', 'd_3_1', 'inv_dist0R', 'tertiary_distance_2', 'd_5_1', 'tertiary_atom_0', 'd_4_1', 'atom_1_bond_lengths_mean', 'inv_dist0', 'atom_1_bond_lengths_min'], 'cv': {'cls': 'KFold', 'init': {'n_splits': 5, 'shuffle': True, 'random_state': 42}}, 'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}}, 'model': {'cls': 'lgb.LGBMRegressor', 'init': {'learning_rate': 0.2833769330240482, 'feature_fraction': 0.8818248470204605, 'bagging_fraction': 0.8205197060908092, 'min_data_in_leaf': 202, 'lambda_l1': 0.017039063121824582, 'lambda_l2': 0.8318702431636841, 'max_bin': 100, 'num_leaves': 255, 'random_state': 3895, 'n_estimators':3000, 'n_jobs': 16}, 'fit': {}}, 'metric': 'mean_absolute_error'},\n",
    "{'columns': add_columns + ['dist_to_type_1_mean', 'cos_f0', 'dist_O_0_x', 'atom_1_bond_lengths_min', 'd_5_2', 'cos_c1', 'd_2_1', 'molecule_atom_index_0_dist_min_div', 'atom_index_1_cycle_size_mean', 'd_4_2', 'inv_distPR', 'dist_N_0_x', 'dist_O_0_y', 'adC1', 'adC2', 'tertiary_angle_2', 'dist_C_2_y', 'molecule_atom_index_0_dist_std_diff', 'dist_C_2_x', 'dist_C_3_y', 'd_4_3', 'eem_1', 'molecule_atom_index_1_dist_min_diff', 'atom_1_bond_lengths_mean', 'tertiary_angle_1', 'inv_dist0R', 'd_4_0', 'd_4_1', 'mean_molecule_atom_0_dist_xyz', 'd_2_0', 'd_3_1', 'dist_C_1_x', 'dist_H_0_y', 'dist_C_0_y', 'd_5_3', 'tertiary_distance_3', 'd_3_2', 'dist_H_1_x', 'tertiary_distance_1', 'atom_1_n_bonds', 'd_8_3', 'cos_c0', 'tertiary_distance_2', 'tertiary_angle_0', 'cos_c0_c1', 'molecule_atom_index_0_dist_min_diff', 'yukawa_H.y'], 'cv': {'cls': 'KFold', 'init': {'n_splits': 5, 'shuffle': True, 'random_state': 42}}, 'scaler': {'cls': 'StandardScaler', 'init': {}, 'fit': {}}, 'model': {'cls': 'lgb.LGBMRegressor', 'init': {'learning_rate': 0.2833769330240482, 'feature_fraction': 0.8818248470204605, 'bagging_fraction': 0.8205197060908092, 'min_data_in_leaf': 202, 'lambda_l1': 0.017039063121824582, 'lambda_l2': 0.8318702431636841, 'max_bin': 100, 'num_leaves': 255, 'random_state': 3895, 'n_estimators':3000, 'n_jobs': 16}, 'fit': {}}, 'metric': 'mean_absolute_error'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mytrial=[]\n",
    "# df_his, df_feature_importances, df_valid_pred, df_test_pred = pd.DataFrame(), pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "# for t in  df_train.type.unique().tolist()[-2:]:\n",
    "#     study = optuna.create_study()\n",
    "#     study.optimize(objective, n_trials=200)\n",
    "#     print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_model_init_list = [\n",
    "# {'learning_rate': 0.4847973878400747, 'feature_fraction': 0.951715013033655, 'bagging_fraction': 0.6640125849570521, 'min_data_in_leaf': 437, 'lambda_l1': 0.0001680598586558378, 'lambda_l2': 5.156758691503555e-06, 'max_bin': 56, 'num_leaves': 490},\n",
    "# {'learning_rate': 0.4041014002815698, 'feature_fraction': 0.9333037289627406, 'bagging_fraction': 0.7450389220980993, 'min_data_in_leaf': 243, 'lambda_l1': 3.7722915702800837e-06, 'lambda_l2': 4.243139074965437e-05, 'max_bin': 100, 'num_leaves': 506},\n",
    "# {'learning_rate': 0.3864250628338235, 'feature_fraction': 0.934428347076253, 'bagging_fraction': 0.8030642265243596, 'min_data_in_leaf': 203, 'lambda_l1': 0.022599448912350148, 'lambda_l2': 4.0097557007881285e-05, 'max_bin': 63, 'num_leaves': 301},\n",
    "# {'learning_rate': 0.3310621175605656, 'feature_fraction': 0.9096874372780241, 'bagging_fraction': 0.8461946729271688, 'min_data_in_leaf': 202, 'lambda_l1': 4.416715454062167e-05, 'lambda_l2': 97.7284456360912, 'max_bin': 73, 'num_leaves': 341},\n",
    "# {'learning_rate': 0.4360511696328724, 'feature_fraction': 0.9267135240558227, 'bagging_fraction': 0.8834671928769631, 'min_data_in_leaf': 426, 'lambda_l1': 0.00740756930750945, 'lambda_l2': 3.042623853713187, 'max_bin': 98, 'num_leaves': 508},\n",
    "# {'learning_rate': 0.4180174094678352, 'feature_fraction': 0.9626050915651176, 'bagging_fraction': 0.6880017140331517, 'min_data_in_leaf': 340, 'lambda_l1': 1.1359051360278207, 'lambda_l2': 0.0008619870627273151, 'max_bin': 82, 'num_leaves': 511},\n",
    "# {'learning_rate': 0.4540923930379812, 'feature_fraction': 0.971839776738276, 'bagging_fraction': 0.6672418499150679, 'min_data_in_leaf': 534, 'lambda_l1': 0.08926785662993982, 'lambda_l2': 2.835575484786637e-05, 'max_bin': 92, 'num_leaves': 509},\n",
    "# {'learning_rate': 0.3069006560814881, 'feature_fraction': 0.9963388008472429, 'bagging_fraction': 0.8793632084474166, 'min_data_in_leaf': 217, 'lambda_l1': 1.1982777608084696, 'lambda_l2': 26.943766780064788, 'max_bin': 80, 'num_leaves': 461}\n",
    "# ]\n",
    "\n",
    "# params_list=[]\n",
    "# for param, model_init in zip(columns_list, param_model_init_list):\n",
    "#     param['model']['init'] = model_init\n",
    "#     params_list.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-63569bdd461c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf_valid_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_valid_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position)\u001b[0m\n\u001b[1;32m   4717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4718\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4719\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4721\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1704\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1706\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'index'"
     ]
    }
   ],
   "source": [
    "mytrial=[]\n",
    "df_his, df_feature_importances, df_valid_pred, df_test_pred = pd.DataFrame(), pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "for t in  df_train.type.unique().tolist():\n",
    "    df_his_i, df_feature_importances_i, df_valid_pred_i, df_test_pred_i =  sk_process(df_train[df_train['type']==t].reset_index(drop=True), columns_list[t], f'modeling for {t}', df_test=None, trial=mytrial, is_output_feature_importance=False, trial_level=0)\n",
    "    df_his = pd.concat([df_his, df_his_i], axis=0)\n",
    "    df_feature_importances = pd.concat([df_feature_importances, df_feature_importances_i], axis=0)\n",
    "    df_valid_pred = pd.concat([df_valid_pred, df_valid_pred_i], axis=0)\n",
    "    df_test_pred = pd.concat([df_test_pred, df_test_pred_i], axis=0)\n",
    "    \n",
    "\n",
    "df_valid_pred = df_valid_pred.sort_values(by=['index']).reset_index(drop=True)\n",
    "# df_test_pred = df_test_pred.sort_values(by=['index']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30716498427613625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>message</th>\n",
       "      <th>nfeatures</th>\n",
       "      <th>train_metric_mean</th>\n",
       "      <th>val_metric_mean</th>\n",
       "      <th>trn_val_metric_diff</th>\n",
       "      <th>trn_val_metric_diff_rate</th>\n",
       "      <th>message</th>\n",
       "      <th>log_val_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-17 18:08:40.348853</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>98</td>\n",
       "      <td>0.075624</td>\n",
       "      <td>0.659857</td>\n",
       "      <td>0.584233</td>\n",
       "      <td>7.725526</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>-0.415733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-17 19:07:44.749280</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>112</td>\n",
       "      <td>0.005203</td>\n",
       "      <td>0.158181</td>\n",
       "      <td>0.152978</td>\n",
       "      <td>29.401667</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>-1.844015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-17 19:26:09.252896</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>101</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.387191</td>\n",
       "      <td>0.382576</td>\n",
       "      <td>82.898392</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>-0.948837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-17 20:04:03.334713</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>72</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.174294</td>\n",
       "      <td>0.173736</td>\n",
       "      <td>311.118556</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>-1.747011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-17 21:37:43.703132</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>111</td>\n",
       "      <td>0.052656</td>\n",
       "      <td>0.257090</td>\n",
       "      <td>0.204434</td>\n",
       "      <td>3.882455</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>-1.358331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-08-17 22:35:00.043051</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>72</td>\n",
       "      <td>0.015936</td>\n",
       "      <td>0.179346</td>\n",
       "      <td>0.163409</td>\n",
       "      <td>10.253807</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>-1.718439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-18 00:13:20.176635</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>72</td>\n",
       "      <td>0.089534</td>\n",
       "      <td>0.294850</td>\n",
       "      <td>0.205315</td>\n",
       "      <td>2.293152</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>-1.221290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-18 00:59:45.200085</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>71</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.125110</td>\n",
       "      <td>0.124309</td>\n",
       "      <td>155.107509</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>-2.078561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime         message  nfeatures  train_metric_mean  \\\n",
       "0 2019-08-17 18:08:40.348853  modeling for 0         98           0.075624   \n",
       "1 2019-08-17 19:07:44.749280  modeling for 3        112           0.005203   \n",
       "2 2019-08-17 19:26:09.252896  modeling for 1        101           0.004615   \n",
       "3 2019-08-17 20:04:03.334713  modeling for 4         72           0.000558   \n",
       "4 2019-08-17 21:37:43.703132  modeling for 2        111           0.052656   \n",
       "5 2019-08-17 22:35:00.043051  modeling for 6         72           0.015936   \n",
       "6 2019-08-18 00:13:20.176635  modeling for 5         72           0.089534   \n",
       "7 2019-08-18 00:59:45.200085  modeling for 7         71           0.000801   \n",
       "\n",
       "   val_metric_mean  trn_val_metric_diff  trn_val_metric_diff_rate  \\\n",
       "0         0.659857             0.584233                  7.725526   \n",
       "1         0.158181             0.152978                 29.401667   \n",
       "2         0.387191             0.382576                 82.898392   \n",
       "3         0.174294             0.173736                311.118556   \n",
       "4         0.257090             0.204434                  3.882455   \n",
       "5         0.179346             0.163409                 10.253807   \n",
       "6         0.294850             0.205315                  2.293152   \n",
       "7         0.125110             0.124309                155.107509   \n",
       "\n",
       "          message  log_val_mae  \n",
       "0  modeling for 0    -0.415733  \n",
       "1  modeling for 3    -1.844015  \n",
       "2  modeling for 1    -0.948837  \n",
       "3  modeling for 4    -1.747011  \n",
       "4  modeling for 2    -1.358331  \n",
       "5  modeling for 6    -1.718439  \n",
       "6  modeling for 5    -1.221290  \n",
       "7  modeling for 7    -2.078561  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trial = pd.DataFrame(mytrial)\n",
    "df_trial['trn_val_metric_diff_rate'] = df_trial['trn_val_metric_diff'] / df_trial['train_metric_mean']\n",
    "df_trial['log_val_mae'] = df_trial['val_metric_mean'].apply(lambda x : np.log(x))\n",
    "print(mean_absolute_error(df_valid_pred.sort_values(by=['index']).reset_index(drop=True).predict.values, df_train.reset_index(drop=True).y.values))\n",
    "df_trial[['datetime', 'message', 'nfeatures', 'train_metric_mean', 'val_metric_mean', 'trn_val_metric_diff', 'trn_val_metric_diff_rate', 'message', 'log_val_mae']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.283506349135093\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>message</th>\n",
       "      <th>nfeatures</th>\n",
       "      <th>train_metric_mean</th>\n",
       "      <th>val_metric_mean</th>\n",
       "      <th>trn_val_metric_diff</th>\n",
       "      <th>trn_val_metric_diff_rate</th>\n",
       "      <th>message</th>\n",
       "      <th>log_val_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-15 10:39:59.213047</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>74</td>\n",
       "      <td>0.119730</td>\n",
       "      <td>0.620052</td>\n",
       "      <td>0.500322</td>\n",
       "      <td>4.178773</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>-0.477952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-15 13:42:36.123079</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>88</td>\n",
       "      <td>0.010164</td>\n",
       "      <td>0.148630</td>\n",
       "      <td>0.138466</td>\n",
       "      <td>13.622600</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>-1.906292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-15 13:58:27.208197</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>77</td>\n",
       "      <td>0.005992</td>\n",
       "      <td>0.356884</td>\n",
       "      <td>0.350892</td>\n",
       "      <td>58.557778</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>-1.030344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-15 14:44:40.291754</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>48</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>0.146795</td>\n",
       "      <td>0.140992</td>\n",
       "      <td>24.295292</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>-1.918717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-15 18:21:57.496771</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>87</td>\n",
       "      <td>0.069108</td>\n",
       "      <td>0.236843</td>\n",
       "      <td>0.167735</td>\n",
       "      <td>2.427154</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>-1.440359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-08-15 19:45:46.663349</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>48</td>\n",
       "      <td>0.032048</td>\n",
       "      <td>0.157919</td>\n",
       "      <td>0.125871</td>\n",
       "      <td>3.927608</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>-1.845675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-15 22:09:19.347532</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>48</td>\n",
       "      <td>0.113392</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.158347</td>\n",
       "      <td>1.396451</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>-1.302914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-15 23:12:30.828864</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>47</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>0.106440</td>\n",
       "      <td>0.102202</td>\n",
       "      <td>24.114797</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>-2.240173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime         message  nfeatures  train_metric_mean  \\\n",
       "0 2019-08-15 10:39:59.213047  modeling for 0         74           0.119730   \n",
       "1 2019-08-15 13:42:36.123079  modeling for 3         88           0.010164   \n",
       "2 2019-08-15 13:58:27.208197  modeling for 1         77           0.005992   \n",
       "3 2019-08-15 14:44:40.291754  modeling for 4         48           0.005803   \n",
       "4 2019-08-15 18:21:57.496771  modeling for 2         87           0.069108   \n",
       "5 2019-08-15 19:45:46.663349  modeling for 6         48           0.032048   \n",
       "6 2019-08-15 22:09:19.347532  modeling for 5         48           0.113392   \n",
       "7 2019-08-15 23:12:30.828864  modeling for 7         47           0.004238   \n",
       "\n",
       "   val_metric_mean  trn_val_metric_diff  trn_val_metric_diff_rate  \\\n",
       "0         0.620052             0.500322                  4.178773   \n",
       "1         0.148630             0.138466                 13.622600   \n",
       "2         0.356884             0.350892                 58.557778   \n",
       "3         0.146795             0.140992                 24.295292   \n",
       "4         0.236843             0.167735                  2.427154   \n",
       "5         0.157919             0.125871                  3.927608   \n",
       "6         0.271739             0.158347                  1.396451   \n",
       "7         0.106440             0.102202                 24.114797   \n",
       "\n",
       "          message  log_val_mae  \n",
       "0  modeling for 0    -0.477952  \n",
       "1  modeling for 3    -1.906292  \n",
       "2  modeling for 1    -1.030344  \n",
       "3  modeling for 4    -1.918717  \n",
       "4  modeling for 2    -1.440359  \n",
       "5  modeling for 6    -1.845675  \n",
       "6  modeling for 5    -1.302914  \n",
       "7  modeling for 7    -2.240173  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trial = pd.DataFrame(mytrial)\n",
    "df_trial['trn_val_metric_diff_rate'] = df_trial['trn_val_metric_diff'] / df_trial['train_metric_mean']\n",
    "df_trial['log_val_mae'] = df_trial['val_metric_mean'].apply(lambda x : np.log(x))\n",
    "print(mean_absolute_error(df_valid_pred.sort_values(by=['index']).reset_index(drop=True).predict.values, df_train.reset_index(drop=True).y.values))\n",
    "df_trial[['datetime', 'message', 'nfeatures', 'train_metric_mean', 'val_metric_mean', 'trn_val_metric_diff', 'trn_val_metric_diff_rate', 'message', 'log_val_mae']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>message</th>\n",
       "      <th>nfeatures</th>\n",
       "      <th>train_metric_mean</th>\n",
       "      <th>val_metric_mean</th>\n",
       "      <th>trn_val_metric_diff</th>\n",
       "      <th>trn_val_metric_diff_rate</th>\n",
       "      <th>message</th>\n",
       "      <th>log_val_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-15 02:05:41.126228</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>74</td>\n",
       "      <td>0.210362</td>\n",
       "      <td>0.666421</td>\n",
       "      <td>0.456060</td>\n",
       "      <td>2.167979</td>\n",
       "      <td>modeling for 0</td>\n",
       "      <td>-0.405833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-15 02:51:57.952391</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>88</td>\n",
       "      <td>0.023252</td>\n",
       "      <td>0.157248</td>\n",
       "      <td>0.133996</td>\n",
       "      <td>5.762899</td>\n",
       "      <td>modeling for 3</td>\n",
       "      <td>-1.849933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-15 02:58:18.893885</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>77</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.381008</td>\n",
       "      <td>0.362726</td>\n",
       "      <td>19.839749</td>\n",
       "      <td>modeling for 1</td>\n",
       "      <td>-0.964934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-15 03:12:43.772104</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>48</td>\n",
       "      <td>0.013993</td>\n",
       "      <td>0.157495</td>\n",
       "      <td>0.143502</td>\n",
       "      <td>10.255205</td>\n",
       "      <td>modeling for 4</td>\n",
       "      <td>-1.848363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-15 04:38:06.906174</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>87</td>\n",
       "      <td>0.109666</td>\n",
       "      <td>0.258878</td>\n",
       "      <td>0.149211</td>\n",
       "      <td>1.360594</td>\n",
       "      <td>modeling for 2</td>\n",
       "      <td>-1.351400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-08-15 05:07:21.139056</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>48</td>\n",
       "      <td>0.055038</td>\n",
       "      <td>0.170250</td>\n",
       "      <td>0.115212</td>\n",
       "      <td>2.093308</td>\n",
       "      <td>modeling for 6</td>\n",
       "      <td>-1.770487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-15 06:04:46.187347</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>48</td>\n",
       "      <td>0.164317</td>\n",
       "      <td>0.297397</td>\n",
       "      <td>0.133080</td>\n",
       "      <td>0.809900</td>\n",
       "      <td>modeling for 5</td>\n",
       "      <td>-1.212686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-15 06:19:11.274392</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>47</td>\n",
       "      <td>0.009743</td>\n",
       "      <td>0.114216</td>\n",
       "      <td>0.104473</td>\n",
       "      <td>10.723145</td>\n",
       "      <td>modeling for 7</td>\n",
       "      <td>-2.169668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime         message  nfeatures  train_metric_mean  \\\n",
       "0 2019-08-15 02:05:41.126228  modeling for 0         74           0.210362   \n",
       "1 2019-08-15 02:51:57.952391  modeling for 3         88           0.023252   \n",
       "2 2019-08-15 02:58:18.893885  modeling for 1         77           0.018283   \n",
       "3 2019-08-15 03:12:43.772104  modeling for 4         48           0.013993   \n",
       "4 2019-08-15 04:38:06.906174  modeling for 2         87           0.109666   \n",
       "5 2019-08-15 05:07:21.139056  modeling for 6         48           0.055038   \n",
       "6 2019-08-15 06:04:46.187347  modeling for 5         48           0.164317   \n",
       "7 2019-08-15 06:19:11.274392  modeling for 7         47           0.009743   \n",
       "\n",
       "   val_metric_mean  trn_val_metric_diff  trn_val_metric_diff_rate  \\\n",
       "0         0.666421             0.456060                  2.167979   \n",
       "1         0.157248             0.133996                  5.762899   \n",
       "2         0.381008             0.362726                 19.839749   \n",
       "3         0.157495             0.143502                 10.255205   \n",
       "4         0.258878             0.149211                  1.360594   \n",
       "5         0.170250             0.115212                  2.093308   \n",
       "6         0.297397             0.133080                  0.809900   \n",
       "7         0.114216             0.104473                 10.723145   \n",
       "\n",
       "          message  log_val_mae  \n",
       "0  modeling for 0    -0.405833  \n",
       "1  modeling for 3    -1.849933  \n",
       "2  modeling for 1    -0.964934  \n",
       "3  modeling for 4    -1.848363  \n",
       "4  modeling for 2    -1.351400  \n",
       "5  modeling for 6    -1.770487  \n",
       "6  modeling for 5    -1.212686  \n",
       "7  modeling for 7    -2.169668  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trial[['datetime', 'message', 'nfeatures', 'train_metric_mean', 'val_metric_mean', 'trn_val_metric_diff', 'trn_val_metric_diff_rate', 'message', 'log_val_mae']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0.34\n",
    "# df_test_pred = df_trial.loc[idx]['df_test_pred']\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit['scalar_coupling_constant'] = np.mean(df_test_pred.drop(columns=['index']).values, axis=1)*y_std+y_mean\n",
    "df_submit['id'] = df_test_pred['index']\n",
    "df_submit.to_csv('../../data/submission/submission_lgbm_{}.csv'.format(idx), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
