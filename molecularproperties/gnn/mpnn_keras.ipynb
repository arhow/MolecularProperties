{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "   div#notebook-container    { width: 95%; }\n",
       "   div#menubar-container     { width: 65%; }\n",
       "   div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "   div#notebook-container    { width: 95%; }\n",
    "   div#menubar-container     { width: 65%; }\n",
    "   div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install tensorflow-gpu==2.0a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.utils import shuffle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-alpha0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.csv',\n",
       " 'structures',\n",
       " 'sample_submission.csv',\n",
       " 'magnetic_shielding_tensors.csv',\n",
       " 'mulliken_charges.csv',\n",
       " 'potential_energy.csv',\n",
       " 'scalar_coupling_contributions.csv',\n",
       " 'dipole_moments.csv',\n",
       " 'structures.csv',\n",
       " 'train.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_folder = '../../data/input'\n",
    "os.listdir(file_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(f'{file_folder}/train.csv')\n",
    "# magnetic_shielding_tensors = pd.read_csv(f'{file_folder}/magnetic_shielding_tensors.csv')\n",
    "# mulliken_charges = pd.read_csv(f'{file_folder}/mulliken_charges.csv')\n",
    "# potential_energy = pd.read_csv(f'{file_folder}/potential_energy.csv')\n",
    "# scalar_coupling_contributions = pd.read_csv(f'{file_folder}/scalar_coupling_contributions.csv')\n",
    "# dipole_moments = pd.read_csv(f'{file_folder}/dipole_moments.csv')\n",
    "# structures = pd.read_csv(f'{file_folder}/structures.csv')\n",
    "# test = pd.read_csv(f'{file_folder}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# col = 'type'\n",
    "# le = LabelEncoder()\n",
    "# le.fit(list(train[col].values) + list(test[col].values))\n",
    "# le.classes_\n",
    "['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in train.columns:\n",
    "#     col_type = df_train[col].dtypes\n",
    "#     if not col_type in numerics:\n",
    "#         print(col, df_train[col].unique())\n",
    "#         le = LabelEncoder()\n",
    "#         le.fit(list(df_train[col].values) + list(df_test[col].values))\n",
    "#         df_train[col] = le.transform(list(df_train[col].values))\n",
    "#         df_test[col] = le.transform(list(df_test[col].values))\n",
    "#         print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../../data/npz\"\n",
    "\n",
    "nodes_train     = np.load(datadir + \"/nodes_train.npz\" )['arr_0']\n",
    "in_edges_train  = np.load(datadir + \"/in_edges_train.npz\")['arr_0']\n",
    "out_edges_train = np.load(datadir + \"/out_edges_train.npz\" )['arr_0']\n",
    "\n",
    "# nodes_test     = np.load(datadir + \"/nodes_test.npz\" )['arr_0']\n",
    "# in_edges_test  = np.load(datadir + \"/in_edges_test.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_train.shape, in_edges_train.shape, out_edges_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_labels = out_edges_train.reshape(-1,out_edges_train.shape[1]*out_edges_train.shape[2],1)\n",
    "in_edges_train = in_edges_train.reshape(-1,in_edges_train.shape[1]*in_edges_train.shape[2],in_edges_train.shape[3])\n",
    "# in_edges_test  = in_edges_test.reshape(-1,in_edges_test.shape[1]*in_edges_test.shape[2],in_edges_test.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-315856ba2c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnodes_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_edges_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_edges_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \"\"\"\n\u001b[1;32m    402\u001b[0m     \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;31m# convert sparse matrices to CSR for row-based indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0mresampled_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msafe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresampled_arrays\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# syntactic sugar for the unit argument case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;31m# convert sparse matrices to CSR for row-based indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0mresampled_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msafe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresampled_arrays\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# syntactic sugar for the unit argument case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36msafe_indexing\u001b[0;34m(X, indices)\u001b[0m\n\u001b[1;32m    214\u001b[0m                                    indices.dtype.kind == 'i'):\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# This is often substantially faster than X[indices]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# nodes_train, in_edges_train, out_labels = shuffle(nodes_train, in_edges_train, out_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message_Passer_NNM(tf.keras.layers.Layer):\n",
    "    def __init__(self, node_dim):\n",
    "        super(Message_Passer_NNM, self).__init__()\n",
    "        self.node_dim = node_dim\n",
    "        self.nn = tf.keras.layers.Dense(units=self.node_dim*self.node_dim, activation = tf.nn.relu)\n",
    "      \n",
    "    def call(self, node_j, edge_ij):\n",
    "        \n",
    "        # Embed the edge as a matrix\n",
    "        A = self.nn(edge_ij)\n",
    "        \n",
    "        # Reshape so matrix mult can be done\n",
    "        A = tf.reshape(A, [-1, self.node_dim, self.node_dim])\n",
    "        node_j = tf.reshape(node_j, [-1, self.node_dim, 1])\n",
    "        \n",
    "        # Multiply edge matrix by node and shape into message list\n",
    "        messages = tf.linalg.matmul(A, node_j)\n",
    "        messages = tf.reshape(messages, [-1, tf.shape(edge_ij)[1], self.node_dim])\n",
    "\n",
    "        return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message_Agg(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Message_Agg, self).__init__()\n",
    "    \n",
    "    def call(self, messages):\n",
    "        return tf.math.reduce_sum(messages, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Update_Func_GRU(tf.keras.layers.Layer):\n",
    "    def __init__(self, state_dim):\n",
    "        super(Update_Func_GRU, self).__init__()\n",
    "        self.concat_layer = tf.keras.layers.Concatenate(axis=1)\n",
    "        self.GRU = tf.keras.layers.GRU(state_dim)\n",
    "        \n",
    "    def call(self, old_state, agg_messages):\n",
    "    \n",
    "        # Remember node dim\n",
    "        n_nodes  = tf.shape(old_state)[1]\n",
    "        node_dim = tf.shape(old_state)[2]\n",
    "        \n",
    "        # Reshape so GRU can be applied, concat so old_state and messages are in sequence\n",
    "        old_state = tf.reshape(old_state, [-1, 1, tf.shape(old_state)[-1]])\n",
    "        agg_messages = tf.reshape(agg_messages, [-1, 1, tf.shape(agg_messages)[-1]])\n",
    "        concat = self.concat_layer([old_state, agg_messages])\n",
    "        \n",
    "        # Apply GRU and then reshape so it can be returned\n",
    "        activation = self.GRU(concat)\n",
    "        activation = tf.reshape(activation, [-1, n_nodes, node_dim])\n",
    "        \n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Edge_Regressor(tf.keras.layers.Layer):\n",
    "    def __init__(self, intermediate_dim):\n",
    "        super(Edge_Regressor, self).__init__()\n",
    "        self.concat_layer = tf.keras.layers.Concatenate()\n",
    "        self.hidden_layer_1 = tf.keras.layers.Dense(units=intermediate_dim, activation=tf.nn.relu)\n",
    "        self.hidden_layer_2 = tf.keras.layers.Dense(units=intermediate_dim, activation=tf.nn.relu)\n",
    "        self.output_layer = tf.keras.layers.Dense(units=1, activation=None)\n",
    "\n",
    "        \n",
    "    def call(self, nodes, edges):\n",
    "            \n",
    "        # Remember node dims\n",
    "        n_nodes  = tf.shape(nodes)[1]\n",
    "        node_dim = tf.shape(nodes)[2]\n",
    "        \n",
    "        # Tile and reshape to match edges\n",
    "        state_i = tf.reshape(tf.tile(nodes, [1, 1, n_nodes]),[-1,n_nodes*n_nodes, node_dim ])\n",
    "        state_j = tf.tile(nodes, [1, n_nodes, 1])\n",
    "        \n",
    "        # concat edges and nodes and apply MLP\n",
    "        concat = self.concat_layer([state_i, edges, state_j])\n",
    "        activation_1 = self.hidden_layer_1(concat)  \n",
    "        activation_2 = self.hidden_layer_2(activation_1)\n",
    "\n",
    "        return self.output_layer(activation_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MP_Layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, state_dim):\n",
    "        super(MP_Layer, self).__init__(self)\n",
    "        self.message_passers  = Message_Passer_NNM(node_dim = state_dim) \n",
    "        self.message_aggs    = Message_Agg()\n",
    "        self.update_functions = Update_Func_GRU(state_dim = state_dim)\n",
    "        \n",
    "        self.state_dim = state_dim         \n",
    "\n",
    "    def call(self, nodes, edges, mask):\n",
    "      \n",
    "        n_nodes  = tf.shape(nodes)[1]\n",
    "        node_dim = tf.shape(nodes)[2]\n",
    "        \n",
    "        state_j = tf.tile(nodes, [1, n_nodes, 1])\n",
    "\n",
    "        messages  = self.message_passers(state_j, edges)\n",
    "\n",
    "        # Do this to ignore messages from non-existant nodes\n",
    "        masked =  tf.math.multiply(messages, mask)\n",
    "        \n",
    "        masked = tf.reshape(masked, [tf.shape(messages)[0], n_nodes, n_nodes, node_dim])\n",
    "\n",
    "        agg_m = self.message_aggs(masked)\n",
    "        \n",
    "        updated_nodes = self.update_functions(nodes, agg_m)\n",
    "        \n",
    "        nodes_out = updated_nodes\n",
    "        # Batch norm seems not to work. \n",
    "        #nodes_out = self.batch_norm(updated_nodes)\n",
    "        \n",
    "        return nodes_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_input = tf.keras.Input(shape=(None,), name='adj_input')\n",
    "nod_input = tf.keras.Input(shape=(None,), name='nod_input')\n",
    "class MPNN(tf.keras.Model):\n",
    "    def __init__(self, out_int_dim, state_dim, T):\n",
    "        super(MPNN, self).__init__(self)   \n",
    "        self.T = T\n",
    "        self.embed = tf.keras.layers.Dense(units=state_dim, activation=tf.nn.relu)\n",
    "        self.MP = MP_Layer( state_dim)     \n",
    "        self.edge_regressor  = Edge_Regressor(out_int_dim)\n",
    "        self.batch_norm = tf.keras.layers.BatchNormalization() \n",
    "\n",
    "        \n",
    "    def call(self, inputs =  [adj_input, nod_input]):\n",
    "      \n",
    "      \n",
    "        nodes            = inputs['nod_input']\n",
    "        edges            = inputs['adj_input']\n",
    "\n",
    "        # Get distances, and create mask wherever 0 (i.e. non-existant nodes)\n",
    "        # This also masks node self-interactions...\n",
    "        # This assumes distance is last\n",
    "        len_edges = tf.shape(edges)[-1]\n",
    "        \n",
    "        _, x = tf.split(edges, [len_edges -1, 1], 2)\n",
    "        mask =  tf.where(tf.equal(x, 0), x, tf.ones_like(x))\n",
    "        \n",
    "        # Embed node to be of the chosen node dimension (you can also just pad)\n",
    "        nodes = self.embed(nodes) \n",
    "        \n",
    "        nodes = self.batch_norm(nodes)\n",
    "        # Run the T message passing steps\n",
    "        for mp in range(self.T):\n",
    "            nodes =  self.MP(nodes, edges, mask)\n",
    "        \n",
    "        # Regress the output values\n",
    "        con_edges = self.edge_regressor(nodes, edges)\n",
    "        \n",
    "        \n",
    "        return con_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(orig , preds):\n",
    " \n",
    "    # Mask values for which no scalar coupling exists\n",
    "    mask  = tf.where(tf.equal(orig, 0), orig, tf.ones_like(orig))\n",
    "\n",
    "    nums  = tf.boolean_mask(orig,  mask)\n",
    "    preds = tf.boolean_mask(preds,  mask)\n",
    "\n",
    "\n",
    "    reconstruction_error = tf.reduce_mean(tf.square(tf.subtract(nums, preds)))\n",
    "\n",
    "\n",
    "    return reconstruction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_mse(orig , preds):\n",
    " \n",
    "    # Mask values for which no scalar coupling exists\n",
    "    mask  = tf.where(tf.equal(orig, 0), orig, tf.ones_like(orig))\n",
    "\n",
    "    nums  = tf.boolean_mask(orig,  mask)\n",
    "    preds = tf.boolean_mask(preds,  mask)\n",
    "\n",
    "\n",
    "    reconstruction_error = tf.math.log(tf.reduce_mean(tf.square(tf.subtract(nums, preds))))\n",
    "\n",
    "\n",
    "    return reconstruction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(orig , preds):\n",
    " \n",
    "    # Mask values for which no scalar coupling exists\n",
    "    mask  = tf.where(tf.equal(orig, 0), orig, tf.ones_like(orig))\n",
    "\n",
    "    nums  = tf.boolean_mask(orig,  mask)\n",
    "    preds = tf.boolean_mask(preds,  mask)\n",
    "\n",
    "\n",
    "    reconstruction_error = tf.reduce_mean(tf.abs(tf.subtract(nums, preds)))\n",
    "\n",
    "\n",
    "    return reconstruction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_mae(orig , preds):\n",
    " \n",
    "    # Mask values for which no scalar coupling exists\n",
    "    mask  = tf.where(tf.equal(orig, 0), orig, tf.ones_like(orig))\n",
    "\n",
    "    nums  = tf.boolean_mask(orig,  mask)\n",
    "    preds = tf.boolean_mask(preds,  mask)\n",
    "\n",
    "    reconstruction_error = tf.math.log(tf.reduce_mean(tf.abs(tf.subtract(nums, preds))))\n",
    "\n",
    "    return reconstruction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = learning_rate\n",
    "    drop = 0.1\n",
    "    epochs_drop = 20.0\n",
    "    lrate = initial_lrate * np.power(drop,  \n",
    "           np.floor((epoch)/epochs_drop))\n",
    "    tf.print(\"Learning rate: \", lrate)\n",
    "    return lrate\n",
    "\n",
    "lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 15, restore_best_weights=True)\n",
    "\n",
    "#lrate  =  tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "#                              patience=5, min_lr=0.00001, verbose = 1)\n",
    "\n",
    "opt = tf.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnn = MPNN(out_int_dim = 256, state_dim = 64, T = 2)\n",
    "mpnn.compile(opt, log_mae, metrics = [mae, log_mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(out_labels)*0.8)\n",
    "batch_size = 16\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=653, shape=(10, 841, 1), dtype=float32, numpy=\n",
       "array([[[-0.25252724],\n",
       "        [-0.46343338],\n",
       "        [-0.47184452],\n",
       "        ...,\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[-0.42281568],\n",
       "        [-1.4393371 ],\n",
       "        [-1.4949441 ],\n",
       "        ...,\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[-0.00225324],\n",
       "        [-0.14406522],\n",
       "        [-0.14406522],\n",
       "        ...,\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.1604631 ],\n",
       "        [-0.26247677],\n",
       "        [-0.2393753 ],\n",
       "        ...,\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[-0.12093869],\n",
       "        [-0.06156129],\n",
       "        [-0.09681971],\n",
       "        ...,\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[-0.23534523],\n",
       "        [-0.28116727],\n",
       "        [-0.3592159 ],\n",
       "        ...,\n",
       "        [ 0.        ],\n",
       "        [ 0.        ],\n",
       "        [ 0.        ]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpnn.call({'adj_input' : in_edges_train[:10], 'nod_input': nodes_train[:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68002"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 1/200\n",
      "68002/68002 - 424s - loss: -9.6600e-01 - mae: 0.3828 - log_mse: -1.0289e+00 - val_loss: -9.5943e-01 - val_mae: 0.4180 - val_log_mse: -1.1082e+00\n",
      "Learning rate:  0.001\n",
      "Epoch 2/200\n",
      "68002/68002 - 424s - loss: -9.7458e-01 - mae: 0.3796 - log_mse: -1.0468e+00 - val_loss: -9.8226e-01 - val_mae: 0.4041 - val_log_mse: -1.1713e+00\n",
      "Learning rate:  0.001\n",
      "Epoch 3/200\n",
      "68002/68002 - 421s - loss: -9.8585e-01 - mae: 0.3753 - log_mse: -1.0688e+00 - val_loss: -9.6591e-01 - val_mae: 0.4121 - val_log_mse: -1.1448e+00\n",
      "Learning rate:  0.001\n",
      "Epoch 4/200\n",
      "68002/68002 - 421s - loss: -9.9159e-01 - mae: 0.3732 - log_mse: -1.0809e+00 - val_loss: -9.5818e-01 - val_mae: 0.4123 - val_log_mse: -1.1261e+00\n",
      "Learning rate:  0.001\n",
      "Epoch 5/200\n",
      "68002/68002 - 423s - loss: -1.0006e+00 - mae: 0.3697 - log_mse: -1.1008e+00 - val_loss: -9.5868e-01 - val_mae: 0.4141 - val_log_mse: -1.1091e+00\n",
      "Learning rate:  0.001\n",
      "Epoch 6/200\n",
      "68002/68002 - 420s - loss: -1.0086e+00 - mae: 0.3668 - log_mse: -1.1167e+00 - val_loss: -9.7102e-01 - val_mae: 0.4061 - val_log_mse: -1.1588e+00\n",
      "Learning rate:  0.001\n",
      "Epoch 7/200\n",
      "68002/68002 - 422s - loss: -1.0206e+00 - mae: 0.3623 - log_mse: -1.1402e+00 - val_loss: -9.6128e-01 - val_mae: 0.4123 - val_log_mse: -1.0877e+00\n",
      "Learning rate:  0.001\n",
      "Epoch 8/200\n",
      "68002/68002 - 423s - loss: -1.0229e+00 - mae: 0.3616 - log_mse: -1.1472e+00 - val_loss: -8.9528e-01 - val_mae: 0.4332 - val_log_mse: -9.4867e-01\n",
      "Learning rate:  0.001\n",
      "Epoch 9/200\n",
      "68002/68002 - 422s - loss: -1.0301e+00 - mae: 0.3590 - log_mse: -1.1591e+00 - val_loss: -1.0189e+00 - val_mae: 0.3908 - val_log_mse: -1.2511e+00\n",
      "Learning rate:  0.001\n",
      "Epoch 10/200\n",
      "68002/68002 - 424s - loss: -1.0377e+00 - mae: 0.3562 - log_mse: -1.1768e+00 - val_loss: -9.7571e-01 - val_mae: 0.4066 - val_log_mse: -1.1369e+00\n",
      "Learning rate:  0.001\n",
      "Epoch 11/200\n",
      "68002/68002 - 423s - loss: -1.0448e+00 - mae: 0.3537 - log_mse: -1.1905e+00 - val_loss: -8.7312e-01 - val_mae: 0.4427 - val_log_mse: -8.7436e-01\n",
      "Learning rate:  0.001\n",
      "Epoch 12/200\n",
      "68002/68002 - 423s - loss: -1.0482e+00 - mae: 0.3526 - log_mse: -1.1979e+00 - val_loss: -1.0321e+00 - val_mae: 0.3860 - val_log_mse: -1.2635e+00\n",
      "Learning rate:  0.001\n",
      "Epoch 13/200\n",
      "68002/68002 - 421s - loss: -1.0554e+00 - mae: 0.3501 - log_mse: -1.2125e+00 - val_loss: -9.5940e-01 - val_mae: 0.4100 - val_log_mse: -1.1194e+00\n",
      "Learning rate:  0.001\n",
      "Epoch 14/200\n",
      "68002/68002 - 422s - loss: -1.0601e+00 - mae: 0.3484 - log_mse: -1.2220e+00 - val_loss: -9.7992e-01 - val_mae: 0.4014 - val_log_mse: -1.1331e+00\n",
      "Learning rate:  0.001\n",
      "Epoch 15/200\n",
      "68002/68002 - 422s - loss: -1.0666e+00 - mae: 0.3461 - log_mse: -1.2376e+00 - val_loss: -9.5643e-01 - val_mae: 0.4125 - val_log_mse: -1.0432e+00\n",
      "Learning rate:  0.001\n",
      "Epoch 16/200\n",
      "68002/68002 - 422s - loss: -1.0717e+00 - mae: 0.3444 - log_mse: -1.2471e+00 - val_loss: -1.0414e+00 - val_mae: 0.3813 - val_log_mse: -1.2771e+00\n",
      "Learning rate:  0.001\n",
      "Epoch 17/200\n",
      "68002/68002 - 423s - loss: -1.0787e+00 - mae: 0.3419 - log_mse: -1.2617e+00 - val_loss: -9.9977e-01 - val_mae: 0.3972 - val_log_mse: -1.1947e+00\n",
      "Learning rate:  0.001\n",
      "Epoch 18/200\n",
      "68002/68002 - 419s - loss: -1.0831e+00 - mae: 0.3404 - log_mse: -1.2717e+00 - val_loss: -1.0143e+00 - val_mae: 0.3905 - val_log_mse: -1.2002e+00\n",
      "Learning rate:  0.001\n",
      "Epoch 19/200\n",
      "68002/68002 - 424s - loss: -1.0857e+00 - mae: 0.3396 - log_mse: -1.2746e+00 - val_loss: -1.0560e+00 - val_mae: 0.3758 - val_log_mse: -1.2984e+00\n",
      "Learning rate:  0.001\n",
      "Epoch 20/200\n",
      "68002/68002 - 423s - loss: -1.0923e+00 - mae: 0.3373 - log_mse: -1.2890e+00 - val_loss: -1.0324e+00 - val_mae: 0.3834 - val_log_mse: -1.2527e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 21/200\n",
      "68002/68002 - 419s - loss: -1.2660e+00 - mae: 0.2839 - log_mse: -1.6000e+00 - val_loss: -1.2252e+00 - val_mae: 0.3233 - val_log_mse: -1.6112e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 22/200\n",
      "68002/68002 - 422s - loss: -1.2959e+00 - mae: 0.2755 - log_mse: -1.6570e+00 - val_loss: -1.2338e+00 - val_mae: 0.3206 - val_log_mse: -1.6343e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 23/200\n",
      "68002/68002 - 425s - loss: -1.3075e+00 - mae: 0.2724 - log_mse: -1.6784e+00 - val_loss: -1.2409e+00 - val_mae: 0.3187 - val_log_mse: -1.6431e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 24/200\n",
      "68002/68002 - 421s - loss: -1.3156e+00 - mae: 0.2701 - log_mse: -1.6940e+00 - val_loss: -1.2477e+00 - val_mae: 0.3167 - val_log_mse: -1.6570e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 25/200\n",
      "68002/68002 - 423s - loss: -1.3215e+00 - mae: 0.2686 - log_mse: -1.7047e+00 - val_loss: -1.2338e+00 - val_mae: 0.3199 - val_log_mse: -1.6313e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 26/200\n",
      "68002/68002 - 423s - loss: -1.3271e+00 - mae: 0.2670 - log_mse: -1.7148e+00 - val_loss: -1.2504e+00 - val_mae: 0.3156 - val_log_mse: -1.6636e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 27/200\n",
      "68002/68002 - 423s - loss: -1.3315e+00 - mae: 0.2659 - log_mse: -1.7227e+00 - val_loss: -1.2503e+00 - val_mae: 0.3159 - val_log_mse: -1.6618e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 28/200\n",
      "68002/68002 - 422s - loss: -1.3353e+00 - mae: 0.2648 - log_mse: -1.7290e+00 - val_loss: -1.2518e+00 - val_mae: 0.3153 - val_log_mse: -1.6625e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 29/200\n",
      "68002/68002 - 424s - loss: -1.3392e+00 - mae: 0.2638 - log_mse: -1.7369e+00 - val_loss: -1.2490e+00 - val_mae: 0.3157 - val_log_mse: -1.6573e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 30/200\n",
      "68002/68002 - 421s - loss: -1.3427e+00 - mae: 0.2629 - log_mse: -1.7440e+00 - val_loss: -1.2577e+00 - val_mae: 0.3139 - val_log_mse: -1.6748e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 31/200\n",
      "68002/68002 - 419s - loss: -1.3452e+00 - mae: 0.2622 - log_mse: -1.7480e+00 - val_loss: -1.2572e+00 - val_mae: 0.3139 - val_log_mse: -1.6755e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 32/200\n",
      "68002/68002 - 421s - loss: -1.3482e+00 - mae: 0.2614 - log_mse: -1.7540e+00 - val_loss: -1.2492e+00 - val_mae: 0.3151 - val_log_mse: -1.6642e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 33/200\n",
      "68002/68002 - 422s - loss: -1.3512e+00 - mae: 0.2607 - log_mse: -1.7595e+00 - val_loss: -1.2529e+00 - val_mae: 0.3146 - val_log_mse: -1.6657e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 34/200\n",
      "68002/68002 - 420s - loss: -1.3537e+00 - mae: 0.2600 - log_mse: -1.7640e+00 - val_loss: -1.2643e+00 - val_mae: 0.3120 - val_log_mse: -1.6861e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 35/200\n",
      "68002/68002 - 421s - loss: -1.3561e+00 - mae: 0.2594 - log_mse: -1.7683e+00 - val_loss: -1.2658e+00 - val_mae: 0.3118 - val_log_mse: -1.6917e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 36/200\n",
      "68002/68002 - 422s - loss: -1.3590e+00 - mae: 0.2587 - log_mse: -1.7741e+00 - val_loss: -1.2630e+00 - val_mae: 0.3122 - val_log_mse: -1.6922e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 37/200\n",
      "68002/68002 - 424s - loss: -1.3603e+00 - mae: 0.2583 - log_mse: -1.7761e+00 - val_loss: -1.2517e+00 - val_mae: 0.3146 - val_log_mse: -1.6632e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 38/200\n",
      "68002/68002 - 421s - loss: -1.3627e+00 - mae: 0.2577 - log_mse: -1.7802e+00 - val_loss: -1.2698e+00 - val_mae: 0.3105 - val_log_mse: -1.7001e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 39/200\n",
      "68002/68002 - 421s - loss: -1.3648e+00 - mae: 0.2572 - log_mse: -1.7855e+00 - val_loss: -1.2660e+00 - val_mae: 0.3111 - val_log_mse: -1.6948e+00\n",
      "Learning rate:  0.0001\n",
      "Epoch 40/200\n",
      "68002/68002 - 424s - loss: -1.3666e+00 - mae: 0.2567 - log_mse: -1.7877e+00 - val_loss: -1.2664e+00 - val_mae: 0.3111 - val_log_mse: -1.6956e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 41/200\n",
      "68002/68002 - 421s - loss: -1.3924e+00 - mae: 0.2503 - log_mse: -1.8275e+00 - val_loss: -1.2849e+00 - val_mae: 0.3064 - val_log_mse: -1.7251e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 42/200\n",
      "68002/68002 - 423s - loss: -1.3950e+00 - mae: 0.2496 - log_mse: -1.8293e+00 - val_loss: -1.2853e+00 - val_mae: 0.3064 - val_log_mse: -1.7258e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 43/200\n",
      "68002/68002 - 421s - loss: -1.3959e+00 - mae: 0.2493 - log_mse: -1.8305e+00 - val_loss: -1.2854e+00 - val_mae: 0.3064 - val_log_mse: -1.7248e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 44/200\n",
      "68002/68002 - 422s - loss: -1.3968e+00 - mae: 0.2492 - log_mse: -1.8333e+00 - val_loss: -1.2862e+00 - val_mae: 0.3062 - val_log_mse: -1.7268e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 45/200\n",
      "68002/68002 - 424s - loss: -1.3973e+00 - mae: 0.2490 - log_mse: -1.8328e+00 - val_loss: -1.2865e+00 - val_mae: 0.3061 - val_log_mse: -1.7272e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 46/200\n",
      "68002/68002 - 420s - loss: -1.3975e+00 - mae: 0.2489 - log_mse: -1.8330e+00 - val_loss: -1.2865e+00 - val_mae: 0.3060 - val_log_mse: -1.7279e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 47/200\n",
      "68002/68002 - 421s - loss: -1.3977e+00 - mae: 0.2489 - log_mse: -1.8325e+00 - val_loss: -1.2868e+00 - val_mae: 0.3060 - val_log_mse: -1.7276e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 48/200\n",
      "68002/68002 - 419s - loss: -1.3984e+00 - mae: 0.2488 - log_mse: -1.8350e+00 - val_loss: -1.2863e+00 - val_mae: 0.3062 - val_log_mse: -1.7263e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 49/200\n",
      "68002/68002 - 420s - loss: -1.3986e+00 - mae: 0.2487 - log_mse: -1.8339e+00 - val_loss: -1.2868e+00 - val_mae: 0.3060 - val_log_mse: -1.7273e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 50/200\n",
      "68002/68002 - 423s - loss: -1.3986e+00 - mae: 0.2486 - log_mse: -1.8333e+00 - val_loss: -1.2865e+00 - val_mae: 0.3061 - val_log_mse: -1.7274e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 51/200\n",
      "68002/68002 - 423s - loss: -1.3992e+00 - mae: 0.2486 - log_mse: -1.8355e+00 - val_loss: -1.2868e+00 - val_mae: 0.3061 - val_log_mse: -1.7278e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 52/200\n",
      "68002/68002 - 425s - loss: -1.3994e+00 - mae: 0.2485 - log_mse: -1.8349e+00 - val_loss: -1.2847e+00 - val_mae: 0.3064 - val_log_mse: -1.7245e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 53/200\n",
      "68002/68002 - 420s - loss: -1.4001e+00 - mae: 0.2484 - log_mse: -1.8385e+00 - val_loss: -1.2872e+00 - val_mae: 0.3059 - val_log_mse: -1.7285e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 54/200\n",
      "68002/68002 - 420s - loss: -1.4000e+00 - mae: 0.2484 - log_mse: -1.8360e+00 - val_loss: -1.2875e+00 - val_mae: 0.3058 - val_log_mse: -1.7292e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 55/200\n",
      "68002/68002 - 418s - loss: -1.4006e+00 - mae: 0.2482 - log_mse: -1.8379e+00 - val_loss: -1.2872e+00 - val_mae: 0.3060 - val_log_mse: -1.7290e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 56/200\n",
      "68002/68002 - 423s - loss: -1.4005e+00 - mae: 0.2483 - log_mse: -1.8376e+00 - val_loss: -1.2878e+00 - val_mae: 0.3058 - val_log_mse: -1.7298e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 57/200\n",
      "68002/68002 - 419s - loss: -1.4007e+00 - mae: 0.2481 - log_mse: -1.8373e+00 - val_loss: -1.2875e+00 - val_mae: 0.3059 - val_log_mse: -1.7285e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 58/200\n",
      "68002/68002 - 422s - loss: -1.4008e+00 - mae: 0.2481 - log_mse: -1.8356e+00 - val_loss: -1.2873e+00 - val_mae: 0.3059 - val_log_mse: -1.7285e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 59/200\n",
      "68002/68002 - 423s - loss: -1.4015e+00 - mae: 0.2480 - log_mse: -1.8385e+00 - val_loss: -1.2874e+00 - val_mae: 0.3059 - val_log_mse: -1.7295e+00\n",
      "Learning rate:  1.0000000000000003e-05\n",
      "Epoch 60/200\n",
      "68002/68002 - 422s - loss: -1.4015e+00 - mae: 0.2479 - log_mse: -1.8385e+00 - val_loss: -1.2872e+00 - val_mae: 0.3059 - val_log_mse: -1.7283e+00\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 61/200\n",
      "68002/68002 - 422s - loss: -1.4049e+00 - mae: 0.2471 - log_mse: -1.8429e+00 - val_loss: -1.2889e+00 - val_mae: 0.3055 - val_log_mse: -1.7309e+00\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 62/200\n",
      "68002/68002 - 421s - loss: -1.4049e+00 - mae: 0.2471 - log_mse: -1.8429e+00 - val_loss: -1.2888e+00 - val_mae: 0.3055 - val_log_mse: -1.7310e+00\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 63/200\n",
      "68002/68002 - 422s - loss: -1.4052e+00 - mae: 0.2471 - log_mse: -1.8439e+00 - val_loss: -1.2889e+00 - val_mae: 0.3055 - val_log_mse: -1.7313e+00\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 64/200\n",
      "68002/68002 - 423s - loss: -1.4053e+00 - mae: 0.2471 - log_mse: -1.8436e+00 - val_loss: -1.2888e+00 - val_mae: 0.3055 - val_log_mse: -1.7311e+00\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 65/200\n",
      "68002/68002 - 420s - loss: -1.4053e+00 - mae: 0.2470 - log_mse: -1.8441e+00 - val_loss: -1.2886e+00 - val_mae: 0.3056 - val_log_mse: -1.7308e+00\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-55815c7487dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m mpnn.fit({'adj_input' : in_edges_train[:train_size], 'nod_input': nodes_train[:train_size]}, y = out_labels[:train_size], batch_size = batch_size, epochs = 200, \n\u001b[1;32m      2\u001b[0m          \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_early\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m          validation_data = ({'adj_input' : in_edges_train[train_size:], 'nod_input': nodes_train[train_size:]},out_labels[train_size:]) )\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    855\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m       return training_arrays.fit_loop(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1245\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m           \u001b[0mreset_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m           output_loss_metrics=self._output_loss_metrics)\n\u001b[0m\u001b[1;32m   1248\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, reset_metrics, output_loss_metrics)\u001b[0m\n\u001b[1;32m    293\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    296\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    243\u001b[0m                         'compiling the model.')\n\u001b[1;32m    244\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         model.optimizer.apply_gradients(zip(grads,\n\u001b[1;32m    247\u001b[0m                                             model.trainable_weights))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_zeros\u001b[0;34m(shape, dtype)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m     \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fast_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_fast_fill\u001b[0;34m(value, shape, dtype)\u001b[0m\n\u001b[1;32m    595\u001b[0m   return array_ops.fill(\n\u001b[1;32m    596\u001b[0m       \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m       constant_op.constant(value, dtype=dtype))\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mfill\u001b[0;34m(dims, value, name)\u001b[0m\n\u001b[1;32m   3522\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   3523\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Fill\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3524\u001b[0;31m         name, _ctx._post_execution_callbacks, dims, value)\n\u001b[0m\u001b[1;32m   3525\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mpnn.fit({'adj_input' : in_edges_train[:train_size], 'nod_input': nodes_train[:train_size]}, y = out_labels[:train_size], batch_size = batch_size, epochs = 200, \n",
    "         callbacks = [lrate, stop_early], use_multiprocessing = True, initial_epoch = 0, verbose = 2, \n",
    "         validation_data = ({'adj_input' : in_edges_train[train_size:], 'nod_input': nodes_train[train_size:]},out_labels[train_size:]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del nodes_train\n",
    "del in_edges_train\n",
    "del out_edges_train\n",
    "\n",
    "# nodes_test     = np.load(datadir + \"/nodes_test.npz\" )['arr_0']\n",
    "# in_edges_test  = np.load(datadir + \"/in_edges_test.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'in_edges_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ffdc46ccda7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mout_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0min_edges_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'in_edges_train' is not defined"
     ]
    }
   ],
   "source": [
    "del out_labels\n",
    "# del in_edges_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "model = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_test     = np.load(datadir + \"/nodes_test.npz\" )['arr_0']\n",
    "in_edges_test  = np.load(datadir + \"/in_edges_test.npz\")['arr_0']\n",
    "in_edges_test  = in_edges_test.reshape(-1,in_edges_test.shape[1]*in_edges_test.shape[2],in_edges_test.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = mpnn.predict({'adj_input' : in_edges_test, 'nod_input': nodes_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45772, 841, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(file_folder + \"/train.csv\")\n",
    "test = pd.read_csv(file_folder + \"/test.csv\")\n",
    "\n",
    "test_group = test.groupby('molecule_name')\n",
    "\n",
    "# scale_min  = train['scalar_coupling_constant'].min()\n",
    "# scale_max = train['scalar_coupling_constant'].max()\n",
    "# scale_mid = (scale_max + scale_min)/2\n",
    "# scale_norm = scale_max - scale_mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_outs(test_group, preds):\n",
    "    i = 0\n",
    "    x = np.array([])\n",
    "    for test_gp, preds in zip(test_group, preds):\n",
    "        if (not i%1000):\n",
    "            print(i)\n",
    "\n",
    "        gp = test_gp[1]\n",
    "        \n",
    "        x = np.append(x, (preds[gp['atom_index_0'].values, gp['atom_index_1'].values] + preds[gp['atom_index_1'].values, gp['atom_index_0'].values])/2.0)\n",
    "        \n",
    "        i = i+1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = 29\n",
    "preds = preds.reshape((-1,max_size, max_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n"
     ]
    }
   ],
   "source": [
    "out_unscaled = make_outs(test_group, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['scalar_coupling_constant'] = out_unscaled\n",
    "test['scalar_coupling_constant'] = test['scalar_coupling_constant']\n",
    "# test[['id','scalar_coupling_constant']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2505537</th>\n",
       "      <td>7163684</td>\n",
       "      <td>dsgdb9nsd_133885</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHC</td>\n",
       "      <td>0.490522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505538</th>\n",
       "      <td>7163685</td>\n",
       "      <td>dsgdb9nsd_133885</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHC</td>\n",
       "      <td>3.348294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505539</th>\n",
       "      <td>7163686</td>\n",
       "      <td>dsgdb9nsd_133885</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>3JHC</td>\n",
       "      <td>1.352033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505540</th>\n",
       "      <td>7163687</td>\n",
       "      <td>dsgdb9nsd_133885</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>2JHC</td>\n",
       "      <td>4.983674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505541</th>\n",
       "      <td>7163688</td>\n",
       "      <td>dsgdb9nsd_133885</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>121.098145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id     molecule_name  atom_index_0  atom_index_1  type  \\\n",
       "2505537  7163684  dsgdb9nsd_133885            15             3  2JHC   \n",
       "2505538  7163685  dsgdb9nsd_133885            15             4  2JHC   \n",
       "2505539  7163686  dsgdb9nsd_133885            15             6  3JHC   \n",
       "2505540  7163687  dsgdb9nsd_133885            15             7  2JHC   \n",
       "2505541  7163688  dsgdb9nsd_133885            15             8  1JHC   \n",
       "\n",
       "         scalar_coupling_constant  \n",
       "2505537                  0.490522  \n",
       "2505538                  3.348294  \n",
       "2505539                  1.352033  \n",
       "2505540                  4.983674  \n",
       "2505541                121.098145  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2505542, 6)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['id','scalar_coupling_constant']].to_csv('../../data/submission/submission_mpnn_keras_.03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
