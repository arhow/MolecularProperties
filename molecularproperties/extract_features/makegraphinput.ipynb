{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "   div#notebook-container    { width: 95%; }\n",
       "   div#menubar-container     { width: 65%; }\n",
       "   div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "   div#notebook-container    { width: 95%; }\n",
    "   div#menubar-container     { width: 65%; }\n",
    "   div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv', 'structures', 'magnetic_shielding_tensors.csv', 'mulliken_charges.csv', 'potential_energy.csv', 'scalar_coupling_contributions.csv', 'dipole_moments.csv', 'structures.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "datadir = \"../../data/input\"\n",
    "print(os.listdir(datadir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nodes_test.npz', 'test_bonds.csv', 'in_edges_train.npz', 'nodes_train.npz', 'out_edges_train.npz', 'angles.csv', 'train_bonds.csv', 'in_edges_test.npz']\n"
     ]
    }
   ],
   "source": [
    "tmpdir = \"../../data/temp/mpnn_keras\"\n",
    "print(os.listdir(tmpdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(datadir + '/train.csv')\n",
    "test = pd.read_csv(datadir + '/test.csv')\n",
    "structures = pd.read_csv(datadir + '/structures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'molecule_name', 'atom_index_0', 'atom_index_1', 'type',\n",
       "       'scalar_coupling_constant'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bonds = pd.read_csv(tmpdir + '/train_bonds.csv')\n",
    "test_bonds = pd.read_csv(tmpdir + '/test_bonds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "angs = pd.read_csv(tmpdir + '/angles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_min  = train['scalar_coupling_constant'].min()\n",
    "scale_max  = train['scalar_coupling_constant'].max()\n",
    "scale_mid = (scale_max + scale_min)/2\n",
    "scale_norm = scale_max - scale_mid\n",
    "\n",
    "train['scalar_coupling_constant'] = (train['scalar_coupling_constant'] - scale_mid)/scale_norm\n",
    "\n",
    "# One hot encoding gets  too big for Kaggle, let's try label\n",
    "# use npz now, back to OH\n",
    "train[['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']] =  pd.get_dummies(train['type'])\n",
    "test[['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']]  =  pd.get_dummies(test['type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures[['C', 'F' ,'H', 'N', 'O']] = pd.get_dummies(structures['atom'])\n",
    "structures[['x', 'y', 'z']] = structures[['x', 'y', 'z']]/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bonds[['nbond_1', 'nbond_1.5', 'nbond_2', 'nbond_3']] = pd.get_dummies(test_bonds['nbond'])#test_bonds['nbond']/3\n",
    "train_bonds[['nbond_1', 'nbond_1.5', 'nbond_2', 'nbond_3']] = pd.get_dummies(train_bonds['nbond'])#train_bonds['nbond']/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "angs['dihedral'] = angs['dihedral']/np.pi\n",
    "# Should I rather one-hot this?\n",
    "angs['shortest_path_n_bonds'] = angs['shortest_path_n_bonds']/6.0\n",
    "angs = angs.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mol_names = train['molecule_name'].unique()\n",
    "test_mol_names  = test['molecule_name'].unique()\n",
    "\n",
    "train_structures = structures.loc[structures['molecule_name'].isin(train_mol_names)]\n",
    "test_structures = structures.loc[structures['molecule_name'].isin(test_mol_names)]\n",
    "\n",
    "train_struct_group = train_structures.groupby('molecule_name')\n",
    "test_struct_group  = test_structures.groupby('molecule_name')\n",
    "\n",
    "train_group = train.groupby('molecule_name')\n",
    "test_group  = test.groupby('molecule_name')\n",
    "\n",
    "train_bond_group = train_bonds.groupby('molecule_name')\n",
    "test_bond_group  = test_bonds.groupby('molecule_name')\n",
    "\n",
    "train_angs = angs.loc[angs['molecule_name'].isin(train_mol_names)]\n",
    "test_angs = angs.loc[angs['molecule_name'].isin(test_mol_names)]\n",
    "\n",
    "train_angs_group = train_angs.groupby('molecule_name')\n",
    "test_angs_group  = test_angs.groupby('molecule_name')\n",
    "\n",
    "# Find max nodes in graph:\n",
    "max_size = train_struct_group.size().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values our nodes will have\n",
    "node_vals = ['C', 'F' ,'H', 'N', 'O']#, 'x', 'y', 'z']\n",
    "#Values our edges will have (minus distance, for now)\n",
    "bond_vals = ['nbond_1', 'nbond_1.5', 'nbond_2', 'nbond_3']#['nbond']\n",
    "j_coup_vals = ['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']#'l_type']\n",
    "ang_vals = ['shortest_path_n_bonds','cosinus','dihedral']\n",
    "edge_vals = j_coup_vals + bond_vals + ang_vals\n",
    "\n",
    "# Find amount of training molecules\n",
    "n_train_mols = len(train_mol_names)\n",
    "n_test_mols = len(test_mol_names)\n",
    "\n",
    "# Find dim of edges and nodes\n",
    "bond_dim  = len(bond_vals)\n",
    "j_coup_dim= len(j_coup_vals)\n",
    "ang_dim   = len(ang_vals)\n",
    "node_dim  = len(node_vals)\n",
    "edge_dim  = len(edge_vals) \n",
    "\n",
    "# Additional edge dims for distances \n",
    "add_edge_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_folder =  '../../data/feature'\n",
    "df_data = pd.read_pickle(f'{file_folder}/df_train.gzde', compression='gzip')\n",
    "df_data = df_data.rename(columns={'index':'id'})\n",
    "const_col = ['id','group', 'type', 'scalar_coupling_constant', 'fc', 'sd','pso','dso']\n",
    "atom_feats = []\n",
    "bond_feats = []\n",
    "for col in df_data.drop(columns=const_col).columns.tolist():\n",
    "    if '0' in col:\n",
    "        if col.replace('0','1') in df_data.columns.tolist():\n",
    "            atom_feats.append(col)\n",
    "        else:\n",
    "            bond_feats.append(col)\n",
    "    elif '1' in col:\n",
    "        if col.replace('1','0') in df_data.columns.tolist():\n",
    "            atom_feats.append(col)\n",
    "        else:\n",
    "            bond_feats.append(col)\n",
    "    else:\n",
    "        bond_feats.append(col)\n",
    "        \n",
    "bond2_dim = len(bond_feats)\n",
    "df_data = pd.merge(df_data, train[['id', 'molecule_name']], on='id')\n",
    "train_bond_group2 = df_data.groupby('molecule_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional edge dims for bonds2 \n",
    "add_edge_dim2 = bond2_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-808d3333eadd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_nodes_array\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_train_mols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_in_edges_array\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_train_mols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_dim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0madd_edge_dim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0madd_edge_dim2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_out_edges_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_train_mols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_nodes_array\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_test_mols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_nodes_array     = np.zeros((n_train_mols, max_size, node_dim), dtype=np.float32) \n",
    "train_in_edges_array  = np.zeros((n_train_mols, max_size, max_size, edge_dim + add_edge_dim + add_edge_dim2),dtype=np.float32) \n",
    "train_out_edges_array = np.zeros((n_train_mols, max_size, max_size, 1),dtype=np.float32) \n",
    "\n",
    "test_nodes_array     = np.zeros((n_test_mols, max_size, node_dim), dtype=np.float32) \n",
    "test_in_edges_array  = np.zeros((n_test_mols, max_size, max_size, edge_dim + add_edge_dim),dtype=np.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_arrs(val_group, struct_group, bond_group, ang_group, train_bond_group2, test):\n",
    "    i = 0\n",
    "    for values, structs, bonds, angles, bonds2 in zip(val_group, struct_group, bond_group, ang_group, train_bond_group2):\n",
    "        if (not i%1000):\n",
    "            print(i)\n",
    "\n",
    "        # Calculate distances\n",
    "        distances = np.zeros((max_size, max_size, 1))\n",
    "        coords = structs[1][['x','y','z']].values\n",
    "        dists  = distance_matrix(coords, coords)\n",
    "        distances[:dists.shape[0],:dists.shape[1], 0] = dists \n",
    "        print(distances.shape, dists.shape)\n",
    "        \n",
    "        # Create nodes\n",
    "        mol_info = structs[1][node_vals].values\n",
    "        nodes = np.zeros((max_size, node_dim))\n",
    "        nodes[:mol_info.shape[0], :mol_info.shape[1]] = mol_info\n",
    "        \n",
    "\n",
    "        # Create edges\n",
    "        in_feats = np.zeros((max_size, max_size, j_coup_dim))\n",
    "        ind = values[1][['atom_index_0', 'atom_index_1' ]].values\n",
    "        in_feats[ind[:,0], ind[:,1], 0:j_coup_dim] = values[1][j_coup_vals].values\n",
    "        in_feats[ind[:,1], ind[:,0], 0:j_coup_dim] = in_feats[ind[:,0], ind[:,1], 0:j_coup_dim]\n",
    "        print(values[1].columns)\n",
    "        \n",
    "        \n",
    "        # Create bonds\n",
    "        in_bonds = np.zeros((max_size, max_size, bond_dim))\n",
    "        ind_bonds = bonds[1][['atom_index_0', 'atom_index_1' ]].values\n",
    "        in_bonds[ind_bonds[:,0], ind_bonds[:,1]] = bonds[1][bond_vals].values\n",
    "        in_bonds[ind_bonds[:,1], ind_bonds[:,0]] = in_bonds[ind_bonds[:,0], ind_bonds[:,1]]\n",
    "        \n",
    "        # Create bonds2\n",
    "        in_bonds2 = np.zeros((max_size, max_size, bond2_dim))\n",
    "        ind_bonds = bonds2[1][['atom_index_0', 'atom_index_1' ]].values\n",
    "        in_bonds2[ind_bonds[:,0], ind_bonds[:,1]] = bonds2[1][bond_feats].values\n",
    "        in_bonds2[ind_bonds[:,1], ind_bonds[:,0]] = in_bonds2[ind_bonds[:,0], ind_bonds[:,1]]\n",
    "        \n",
    "        # Create angles\n",
    "        ind_angs = angles[1][['atom_index_0', 'atom_index_1' ]].values\n",
    "        ang_mat  = np.zeros((max_size, max_size, ang_dim))\n",
    "        ang_mat[ind_angs[:,0], ind_angs[:,1]]  = angles[1][ang_vals]\n",
    "        ang_mat[ind_angs[:,1], ind_angs[:,0]]  = ang_mat[ind_angs[:,0], ind_angs[:,1]]\n",
    "        print(angles[1][ang_vals].columns, angles[1][ang_vals].shape)\n",
    "        \n",
    "        \n",
    "        # concat all edge values \n",
    "        in_edges = np.concatenate((in_feats, in_bonds, ang_mat, distances, in_bonds2),axis=2)\n",
    "        print('in_edges shape:', in_edges.shape)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        if not test:           \n",
    "            out_edges = np.zeros((max_size, max_size, 1))\n",
    "            out_edges[ind[:,0], ind[:,1], 0] = values[1]['scalar_coupling_constant' ].values\n",
    "            out_edges[ind[:,1], ind[:,0], 0] = out_edges[ind[:,0], ind[:,1], 0]\n",
    "        \n",
    "\n",
    "            train_nodes_array[i]      = nodes\n",
    "            train_in_edges_array[i]   = in_edges\n",
    "            train_out_edges_array[i]  = out_edges\n",
    "        else:\n",
    "            test_nodes_array[i]      = nodes\n",
    "            test_in_edges_array[i]   = in_edges\n",
    "        i = i + 1\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(29, 29, 1) (5, 5)\n",
      "Index(['id', 'molecule_name', 'atom_index_0', 'atom_index_1', 'type',\n",
      "       'scalar_coupling_constant', '1JHC', '1JHN', '2JHC', '2JHH', '2JHN',\n",
      "       '3JHC', '3JHH', '3JHN'],\n",
      "      dtype='object')\n",
      "Index(['shortest_path_n_bonds', 'cosinus', 'dihedral'], dtype='object') (10, 3)\n",
      "in_edges shape: (29, 29, 244)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (29,29,244) into shape (29,29,16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c87b2064234b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_arrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_struct_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_bond_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_angs_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_bond_group2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-68ab8b09a681>\u001b[0m in \u001b[0;36mmake_arrs\u001b[0;34m(val_group, struct_group, bond_group, ang_group, train_bond_group2, test)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mtrain_nodes_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mtrain_in_edges_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0min_edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mtrain_out_edges_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mout_edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (29,29,244) into shape (29,29,16)"
     ]
    }
   ],
   "source": [
    "make_arrs(train_group, train_struct_group, train_bond_group, train_angs_group, train_bond_group2, test = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_arrs(test_group, test_struct_group, test_bond_group, test_angs_group, test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"nodes_train.npz\" , train_nodes_array)\n",
    "np.savez_compressed(\"in_edges_train.npz\" , train_in_edges_array)\n",
    "np.savez_compressed(\"out_edges_train.npz\" , train_out_edges_array)\n",
    "\n",
    "np.savez_compressed(\"nodes_test.npz\" , test_nodes_array)\n",
    "np.savez_compressed(\"in_edges_test.npz\" , test_in_edges_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
